{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eebb9ce-a474-4231-9609-94b3f01d6465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewheng/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dcc069-cd7b-4850-b2ef-e2bc5b9bce3d",
   "metadata": {},
   "source": [
    "# 1.0 Prepare the frames from clips \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7247920e-3889-4149-969c-398e3a5bf2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This function is already run to download the videos in the local directory named download_videos.\n",
    "\n",
    "def download_youtube_videos():\n",
    "    from pytube import YouTube\n",
    "    import os\n",
    "    import ssl\n",
    "    \n",
    "    # Bypass SSL certificate verification\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    \n",
    "\n",
    "\n",
    "    # retrieve the youtube videos ids\n",
    "    path = './metafiles/mlda_data.json'\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    youtube_ids = []\n",
    "    # we only run 100loops to get 100 videos\n",
    "    for key in iter(data.keys()):\n",
    "        youtube_ids.append(data[key])\n",
    "        #if len(youtube_ids == 100): break\n",
    "    \n",
    "    # now youtube_ids = ['0AC26eIQcdo', '0LQnFOUmdvc', '0F26xJPD1C4', '4kEt_Z--3O0',...]\n",
    "\n",
    "    \n",
    "    \n",
    "    # some youtube contents are age restricted, unable to download\n",
    "    restricted = []\n",
    "\n",
    "    # start to download the youtube videos\n",
    "    for i, yt_id in enumerate(youtube_ids):\n",
    "        youtube_video_url = f'https://www.youtube.com/watch?v={yt_id}'\n",
    "    \n",
    "        try: \n",
    "            # Create a YouTube object\n",
    "            yt = YouTube(youtube_video_url,use_oauth=True,allow_oauth_cache=True)\n",
    "    \n",
    "            # Get the highest resolution stream\n",
    "            stream = yt.streams.get_highest_resolution()\n",
    "    \n",
    "            # Specify the directory where you want to download the video\n",
    "            download_dir = 'download_videos'\n",
    "    \n",
    "            # Create the directory if it doesn't exist\n",
    "            if not os.path.exists(download_dir):\n",
    "                os.makedirs(download_dir)\n",
    "    \n",
    "            # Download the video into the specified directory\n",
    "            filename = stream.download(output_path=download_dir)\n",
    "    \n",
    "            new_filename = os.path.join(download_dir, f'{yt_id}.mp4')  # Change 'new_video_name' to your desired filename\n",
    "            \n",
    "            # Rename the file\n",
    "            os.rename(filename, new_filename)\n",
    "            print(f\"Downloaded {i}, id: {yt_id}\")\n",
    "        except Exception:\n",
    "            print(f\"Restricted {i}, id: {yt_id}\")\n",
    "            restricted.append(yt_id)\n",
    "            continue        \n",
    "        \n",
    "    print(\"restricted: \", restricted)\n",
    "\n",
    "# download_youtube_videos()\n",
    "# Now, the downloaded youtube videos are in the download_videos directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c05b146-9f11-4669-8a9c-5ab71aa29e4c",
   "metadata": {},
   "source": [
    "# 1.1 Cut the clips into frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ce083c6-0f59-4bdc-b09a-e024c1c40835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample frames of clips with frame rate = 10/s\n",
    "def sample_frames(video_path, output_frame_image_dir, output_frame_description_dir, frame_rate, caption_clips, i):\n",
    "    # Open the video file\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_frame_image_dir, exist_ok=True)\n",
    "    os.makedirs(output_frame_description_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize variables\n",
    "    count = 0\n",
    "    frame_num = 0\n",
    "    \n",
    "    # Loop through the video frames\n",
    "    while success:\n",
    "        # Save frame at the specified frame rate\n",
    "        if count % frame_rate == 0:\n",
    "            output_frame_path = os.path.join(output_frame_image_dir, f\"frame_{frame_num}.jpg\")\n",
    "            output_frame_description_path = os.path.join(output_frame_description_dir, f\"frame_{frame_num}.txt\")\n",
    "            cv2.imwrite(output_frame_path, image)  # Save the frame as a JPEG image\n",
    "            with open(output_frame_description_path, 'w') as f:\n",
    "                f.write(caption_clips[i])\n",
    "            frame_num += 1\n",
    "        \n",
    "        # Read the next frame\n",
    "        success, image = vidcap.read()\n",
    "        count += 1\n",
    "\n",
    "    # Release the video capture object\n",
    "    vidcap.release()\n",
    "\n",
    "\n",
    " \n",
    "def sample_all_frames(path_to_clips, caption_clips):\n",
    "\n",
    "    n = len(path_to_clips)\n",
    "    for i in range(n):\n",
    "        video_path =  './video_clips/' + path_to_clips[i]\n",
    "        output_frame_image_dir = './clips_frames/' + path_to_clips[i][:-4]\n",
    "        output_frame_description_dir = './clips_frames_description/' + path_to_clips[i][:-4]\n",
    "        frame_rate = 10  # Sample every 10 frames per second\n",
    "        sample_frames(video_path, output_frame_image_dir, output_frame_description_dir, frame_rate, caption_clips, i)\n",
    "        print(f\"Completed sample frames from clip {i}/{n}\")\n",
    "\n",
    "\n",
    "# Note: below is the functions to sample out all the frames and store it into the clips_frames and clips_frames_description directories respectively.\n",
    "# We comment it out as it is already done running and the frames are stored successfully.\n",
    "\n",
    "# path_to_clips = []\n",
    "# caption_clips = []\n",
    "\n",
    "# with open('./hdvg_results/cut_part0.jsonl', 'r') as f:\n",
    "#     for line in f:\n",
    "#         data = json.loads(line)\n",
    "#         path_to_clips.append(data['clip'])\n",
    "#         caption_clips.append(data['caption'])\n",
    "\n",
    "# make_all_sample_frames(path_to_clips, caption_clips)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c78e96-c3fa-4618-ac4a-d83ef5e9fc80",
   "metadata": {},
   "source": [
    "# 2.0 Defining classes and functions for model and evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac13eccd-525e-415a-8fb7-b40b1461b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm is used to create progress bars in tasks that involve iteration, such as loops\n",
    "# It is used so we can visualize the progress bar when looping iterable\n",
    "try:\n",
    "    from tqdm import tqdm \n",
    "except ImportError:\n",
    "    def tqdm(x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2127479f-4eec-46de-b492-6da7f93fe704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomDataset is a class that inherit from pytorch Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    FLAGS = ['img', 'txt']\n",
    "    def __init__(self, real_path, fake_path,\n",
    "                 real_flag: str = 'img',\n",
    "                 fake_flag: str = 'txt',\n",
    "                 transform = None,\n",
    "                 tokenizer = None) -> None:\n",
    "        super().__init__()\n",
    "        assert real_flag in self.FLAGS and fake_flag in self.FLAGS, \\\n",
    "            'CLIP Score only support modality of {}. However, get {} and {}'.format(\n",
    "                self.FLAGS, real_flag, fake_flag\n",
    "            )\n",
    "        self.real_folder = self._combine_without_prefix(real_path)\n",
    "        self.real_flag = real_flag\n",
    "        self.fake_foler = self._combine_without_prefix(fake_path)\n",
    "        self.fake_flag = fake_flag\n",
    "        self.transform = transform\n",
    "        self.tokenizer = tokenizer\n",
    "        # assert self._check()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.real_folder)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index >= len(self):\n",
    "            raise IndexError\n",
    "        real_path = self.real_folder[index]\n",
    "        fake_path = self.fake_foler[index]\n",
    "        real_data = self._load_modality(real_path, self.real_flag)\n",
    "        fake_data = self._load_modality(fake_path, self.fake_flag)\n",
    "\n",
    "        sample = dict(real=real_data, fake=fake_data)\n",
    "        return sample\n",
    "    \n",
    "    def _load_modality(self, path, modality):\n",
    "        if modality == 'img':\n",
    "            data = self._load_img(path)\n",
    "        elif modality == 'txt':\n",
    "            data = self._load_txt(path)\n",
    "        else:\n",
    "            raise TypeError(\"Got unexpected modality: {}\".format(modality))\n",
    "        return data\n",
    "\n",
    "    def _load_img(self, path):\n",
    "        img = Image.open(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "    \n",
    "    def _load_txt(self, path):\n",
    "        with open(path, 'r') as fp:\n",
    "            data = fp.read()\n",
    "            fp.close()\n",
    "        if self.tokenizer is not None:\n",
    "            data = self.tokenizer(data).squeeze()\n",
    "        return data\n",
    "\n",
    "    def _check(self):\n",
    "        for idx in range(len(self)):\n",
    "            real_name = self.real_folder[idx].split('.')\n",
    "            fake_name = self.fake_folder[idx].split('.')\n",
    "            if fake_name != real_name:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def _combine_without_prefix(self, folder_path, prefix='.'):\n",
    "        folder = []\n",
    "        for name in os.listdir(folder_path):\n",
    "            if name[0] == prefix:\n",
    "                continue\n",
    "            folder.append(osp.join(folder_path, name))\n",
    "        folder.sort()\n",
    "        return folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06626c3-9c48-4366-ad2d-0cbab27775e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the clip score\n",
    "\n",
    "@torch.no_grad()\n",
    "def calculate_clip_score(dataloader, model, real_flag, fake_flag):\n",
    "    score_acc = 0.\n",
    "    sample_num = 0.\n",
    "    logit_scale = model.logit_scale.exp()\n",
    "    for batch_data in tqdm(dataloader):\n",
    "        real = batch_data['real']\n",
    "        real_features = forward_modality(model, real, real_flag)\n",
    "        fake = batch_data['fake']\n",
    "        fake_features = forward_modality(model, fake, fake_flag)\n",
    "        \n",
    "        # normalize features\n",
    "        real_features = real_features / real_features.norm(dim=1, keepdim=True).to(torch.float32)\n",
    "        fake_features = fake_features / fake_features.norm(dim=1, keepdim=True).to(torch.float32)\n",
    "        \n",
    "        # calculate scores\n",
    "        # score = logit_scale * real_features @ fake_features.t()\n",
    "        # score_acc += torch.diag(score).sum()\n",
    "        score = logit_scale * (fake_features * real_features).sum()\n",
    "        score_acc += score\n",
    "        sample_num += real.shape[0]\n",
    "\n",
    "    # Check if sample_num is zero before performing division\n",
    "    if sample_num != 0:\n",
    "        return torch.tensor(score_acc / sample_num)  # Convert to PyTorch tensor\n",
    "    else:\n",
    "        # Return a tensor with a value of 0\n",
    "        return torch.tensor(0.0)\n",
    "\n",
    "    \n",
    "def forward_modality(model, data, flag):\n",
    "    device = next(model.parameters()).device\n",
    "    if flag == 'img':\n",
    "        features = model.encode_image(data.to(device))\n",
    "    elif flag == 'txt':\n",
    "        features = model.encode_text(data.to(device))\n",
    "    else:\n",
    "        raise TypeError\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76b37710-e401-4600-b1ad-54630ad98ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate the quality of image-text based on its CLIP Score\n",
    "\n",
    "def evaluate(model, real_path, fake_path):\n",
    "\n",
    "    # Define evaluation arguments\n",
    "    args = {}\n",
    "    args['batch_size'] = 50\n",
    "    args['clip_model'] = 'ViT-B/32'\n",
    "    args['num_workers'] = None\n",
    "    args['device'] = None\n",
    "    args['real_flag'] = 'img'\n",
    "    args['fake_flag'] = 'txt'\n",
    "    args['real_path'] = real_path\n",
    "    args['fake_path'] = fake_path\n",
    "\n",
    "    # Determine device (GPU or CPU) for model evaluation\n",
    "    if args['device'] is None:\n",
    "        device = torch.device('cuda' if (torch.cuda.is_available()) else 'cpu')\n",
    "    else:\n",
    "        device = torch.device(args['device'])\n",
    "\n",
    "    # Load the CLIP model\n",
    "    print('Loading CLIP model: {}'.format(args['clip_model']))\n",
    "    model, preprocess = clip.load(args['clip_model'], device=device) # model is the actually ML model, preprocess is the\n",
    "\n",
    "    # Prepare the datasets -- CustomDataset is a class inherited from the Dataset class in Pytorch\n",
    "    dataset = CustomDataset(args['real_path'], args['fake_path'], \n",
    "                            args['real_flag'], args['fake_flag'], \n",
    "                            transform=preprocess, tokenizer=clip.tokenize)\n",
    "    \n",
    "    # Create a DataLoader (from Pytorch) to efficiently load and batch data from the dataset\n",
    "    dataloader = DataLoader(dataset, args['batch_size'], num_workers=0, pin_memory=True)\n",
    "\n",
    "    # Calculate the CLIP Score \n",
    "    print('Calculating CLIP Score:')\n",
    "    clip_score = calculate_clip_score(dataloader, model, args['real_flag'], args['fake_flag'])\n",
    "    clip_score = clip_score.cpu().item()\n",
    "    print('CLIP Score: ', clip_score)\n",
    "\n",
    "    return clip_score\n",
    "\n",
    "\n",
    "def evaluate_all(paths_to_frames, paths_to_frames_description):\n",
    "    n = len(paths_to_frames) # n denote the number of clips\n",
    "    m = n//3 # We cut the number of clips to one third as it is too time consuming to evaluate all (about 8 hours)\n",
    "    results = []\n",
    "    for i in range(m):\n",
    "        clip_score = evaluate('ViT-B/32', paths_to_frames[i], paths_to_frames_description[i])\n",
    "        the_clip = paths_to_frames[i].split('/',1)[-1] + '.mp4'\n",
    "        print(\"caption\", clip_text_map[the_clip])\n",
    "        results.append({\"clip\": the_clip, \"caption\": clip_text_map[the_clip], \"score\": clip_score})\n",
    "        # Note: clip_text_map is a global variable define below at ln[9]\n",
    "        print(f\"Evaluated {i+1}/{m}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af4bb5-3a44-43c2-bee4-eceb93a29677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68c4801a-44ae-4c19-a202-2814a28fd4a0",
   "metadata": {},
   "source": [
    "# 3.0 Main flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d95e66-c09d-475f-8c74-78ad89152d50",
   "metadata": {},
   "source": [
    "###  3.1 Get the paths to the folders of frames and the folders of frames description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c2bb4ed-ffa3-4097-a6d0-2d1e687a8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# paths_to_frame is a list of paths to the folders that storing the frames\n",
    "paths_to_frames = []\n",
    "\n",
    "# paths_to_frames_description is a list of paths to the folders that storing the frames descriptions\n",
    "paths_to_frames_description = []\n",
    "\n",
    "\n",
    "# get the root folder that stores the frames and description \n",
    "root_folder1 = ['clips_frames']\n",
    "root_folder2 = ['clips_frames_description']\n",
    "\n",
    "# Iterate through each root folder\n",
    "for root_folder in root_folder1:\n",
    "    folders = [os.path.join(root_folder, folder) for folder in os.listdir(root_folder)]\n",
    "    for subfolder in folders:\n",
    "        subsubfolders = [os.path.join(subfolder, folder) for folder in os.listdir(subfolder)]\n",
    "        for folder in subsubfolders:\n",
    "            paths_to_frames.append(folder)\n",
    "            \n",
    "# Iterate through each root folder\n",
    "for root_folder in root_folder2:\n",
    "    folders = [os.path.join(root_folder, folder) for folder in os.listdir(root_folder)]\n",
    "    for subfolder in folders:\n",
    "        subsubfolders = [os.path.join(subfolder, folder) for folder in os.listdir(subfolder)]\n",
    "        for folder in subsubfolders:\n",
    "            paths_to_frames_description.append(folder) \n",
    "\n",
    "\n",
    "# Now,\n",
    "# paths_to_frame is a list of paths to the folders that storing the frames\n",
    "# paths_to_frames_description is a list of paths to the folders that storing the frames descriptions\n",
    "\n",
    "# Make sure that paths_to_frames and paths_to_frames_description lists are storing paths with same sequence\n",
    "assert [path.split('/',1)[1] for path in paths_to_frames] == [path.split('/',1)[1] for path in paths_to_frames_description]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2818b64-3432-43aa-b355-f20f5812f4a5",
   "metadata": {},
   "source": [
    "### 3.2 Create a python dictionary to store the clip-text map as a python variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14057392-ad65-40c0-b345-aeaf4e82d652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clip-text pair: 7185\n",
      "5 examples of the clip-text pairs: \n",
      "1NRXqc74kQM/1NRXqc74kQM.4_2.mp4 : a piece of paper with the words \"official democratic ballot\" on it\n",
      "1NRXqc74kQM/1NRXqc74kQM.4_0.mp4 : a pile of paper with a voting machine sitting on top of it\n",
      "1NRXqc74kQM/1NRXqc74kQM.4_1.mp4 : a man looking down at his cell phone\n",
      "1NRXqc74kQM/1NRXqc74kQM.0_0.mp4 : a news anchor standing in front of a television screen\n",
      "1NRXqc74kQM/1NRXqc74kQM.0_1.mp4 : a news anchor standing in front of a television screen\n"
     ]
    }
   ],
   "source": [
    "# clip_text_map is a global python dictionary that will be used to retrieve text from clip\n",
    "\n",
    "clip_text_map = {}\n",
    "\n",
    "with open('./hdvg_results/cut_part0.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        clip_text_map[data['clip']] = data['caption']\n",
    "\n",
    "print(f\"Number of clip-text pair: {len(clip_text_map)}\")\n",
    "print(\"5 examples of the clip-text pairs: \")\n",
    "for key, value in itertools.islice(clip_text_map.items(), 5):\n",
    "    print(key, ':', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec9a908-2ce9-4cc1-b75a-198eecc342b9",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate the clip-text pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5437386b-0833-43bd-a3a3-6bfe3309f7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "/var/folders/9k/v3mgfmnx32b02fjpln953dzr0000gn/T/ipykernel_27085/1928693112.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(score_acc / sample_num)  # Convert to PyTorch tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.28797912597656\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 1/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.02834701538086\n",
      "caption the cover of a magazine with a picture of naruto\n",
      "Evaluated 2/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.306488037109375\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 3/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.48442840576172\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 4/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.27205276489258\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 5/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.399532318115234\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 6/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.36326217651367\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 7/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.321956634521484\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 8/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.265098571777344\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 9/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.42487716674805\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 10/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.331111907958984\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 11/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.396915435791016\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 12/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.27668762207031\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 13/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.37305450439453\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 14/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.146453857421875\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 15/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.406925201416016\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 16/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.19631576538086\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 17/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.29835510253906\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 18/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.36421585083008\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 19/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.33509063720703\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 20/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.33108139038086\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 21/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.61528015136719\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 22/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.4100227355957\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 23/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.3792610168457\n",
      "caption the cover of a japanese magazine with a picture of naruto\n",
      "Evaluated 24/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.51097297668457\n",
      "caption a screen shot of a computer program\n",
      "Evaluated 25/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.025924682617188\n",
      "caption a computer screen with the words \"contextual electronics\" on it\n",
      "Evaluated 26/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.235979080200195\n",
      "caption a computer screen with a green object on it\n",
      "Evaluated 27/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.008188247680664\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 28/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.143814086914062\n",
      "caption a screen shot of a computer screen\n",
      "Evaluated 29/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.972782135009766\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 30/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.41962242126465\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 31/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.9539852142334\n",
      "caption an image of a computer screen showing a circuit design\n",
      "Evaluated 32/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.919418334960938\n",
      "caption an image of a computer screen with numbers on it\n",
      "Evaluated 33/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.19159698486328\n",
      "caption a screen shot of a computer screen with a picture on it\n",
      "Evaluated 34/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.425336837768555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a computer screen showing a green circuit board\n",
      "Evaluated 35/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.452661514282227\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 36/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.696245193481445\n",
      "caption a screen shot of a computer program\n",
      "Evaluated 37/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.39943313598633\n",
      "caption a sign that says \"generating gerb files for manufacturing\"\n",
      "Evaluated 38/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.99449920654297\n",
      "caption a computer screen showing a picture of a circuit board\n",
      "Evaluated 39/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.81566619873047\n",
      "caption a screen shot of a computer screen\n",
      "Evaluated 40/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.154272079467773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a screen shot of a computer with a green square on it\n",
      "Evaluated 41/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.88654899597168\n",
      "caption a screen shot of a computer with a green image on it\n",
      "Evaluated 42/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.11006736755371\n",
      "caption a computer screen with a picture on it\n",
      "Evaluated 43/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.06052017211914\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 44/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.19159698486328\n",
      "caption a screen shot of a computer screen with a picture on it\n",
      "Evaluated 45/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.618661880493164\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 46/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.334375381469727\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 47/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.540578842163086\n",
      "caption a picture of a computer screen with text on it\n",
      "Evaluated 48/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.712581634521484\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 49/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.305692672729492\n",
      "caption a screen shot of a computer screen\n",
      "Evaluated 50/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.88482666015625\n",
      "caption a screen shot of a computer screen\n",
      "Evaluated 51/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.05836296081543\n",
      "caption an image of a computer screen showing a circuit diagram\n",
      "Evaluated 52/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.130830764770508\n",
      "caption an image of a computer screen showing a program\n",
      "Evaluated 53/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.799484252929688\n",
      "caption a screen shot of a computer screen\n",
      "Evaluated 54/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.007076263427734\n",
      "caption an image of a computer screen with numbers on it\n",
      "Evaluated 55/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.425336837768555\n",
      "caption a computer screen showing a green circuit board\n",
      "Evaluated 56/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.602304458618164\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 57/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.336610794067383\n",
      "caption a screen shot of a computer program\n",
      "Evaluated 58/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.771751403808594\n",
      "caption a screen shot of a computer program\n",
      "Evaluated 59/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.659605026245117\n",
      "caption a computer screen with a picture on it\n",
      "Evaluated 60/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.883867263793945\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 61/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.12480354309082\n",
      "caption an image of a computer screen showing a computer screen\n",
      "Evaluated 62/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.739194869995117\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 63/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.948835372924805\n",
      "caption a computer screen with a picture of a circuit board\n",
      "Evaluated 64/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.6474666595459\n",
      "caption an image of a computer screen showing a green and yellow object\n",
      "Evaluated 65/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.875423431396484\n",
      "caption an image of a computer screen showing a circuit diagram\n",
      "Evaluated 66/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.997100830078125\n",
      "caption a screen shot of a green circuit board\n",
      "Evaluated 67/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.242759704589844\n",
      "caption a screen shot of a computer program\n",
      "Evaluated 68/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.492958068847656\n",
      "caption an image of a computer screen with a green background\n",
      "Evaluated 69/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.1536808013916\n",
      "caption a screen shot of a computer screen\n",
      "Evaluated 70/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.13035011291504\n",
      "caption a screen shot of a computer screen\n",
      "Evaluated 71/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.466554641723633\n",
      "caption a picture of a computer screen with text on it\n",
      "Evaluated 72/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.252716064453125\n",
      "caption an image of a computer screen showing a circuit design\n",
      "Evaluated 73/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.300668716430664\n",
      "caption a screen shot of a computer screen\n",
      "Evaluated 74/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.424787521362305\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 75/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.102916717529297\n",
      "caption a screen shot of a computer screen\n",
      "Evaluated 76/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.16455078125\n",
      "caption a screen shot of a computer program\n",
      "Evaluated 77/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.433156967163086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a computer screen with a picture of a circuit board on it\n",
      "Evaluated 78/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.53346824645996\n",
      "caption a screen shot of a computer program\n",
      "Evaluated 79/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.12530517578125\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 80/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.868131637573242\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 81/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.601343154907227\n",
      "caption a computer screen with a picture on it\n",
      "Evaluated 82/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.819168090820312\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 83/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.14375114440918\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 84/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.696245193481445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a screen shot of a computer program\n",
      "Evaluated 85/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.289836883544922\n",
      "caption a computer screen with a picture of a car on it\n",
      "Evaluated 86/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.484764099121094\n",
      "caption a computer screen showing an image of a green square\n",
      "Evaluated 87/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.093395233154297\n",
      "caption a screen shot of a computer screen\n",
      "Evaluated 88/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.61014747619629\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 89/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.888710021972656\n",
      "caption a computer screen showing a black square\n",
      "Evaluated 90/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.429704666137695\n",
      "caption an airplane flying through the dark sky\n",
      "Evaluated 91/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.538036346435547\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 92/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.44840621948242\n",
      "caption a sign that says \"generating gerb files for manufacturing\"\n",
      "Evaluated 93/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.545217514038086\n",
      "caption a screen shot of a computer program\n",
      "Evaluated 94/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.625080108642578\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 95/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.398637771606445\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 96/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.66070556640625\n",
      "caption a screen shot of a computer screen\n",
      "Evaluated 97/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.147207260131836\n",
      "caption a computer screen with a picture on it\n",
      "Evaluated 98/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.393552780151367\n",
      "caption an image of a computer screen showing a circuit design\n",
      "Evaluated 99/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.865184783935547\n",
      "caption a computer screen showing a picture of a circuit board\n",
      "Evaluated 100/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.36728858947754\n",
      "caption a screen shot of a computer program\n",
      "Evaluated 101/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.534469604492188\n",
      "caption a computer screen with a picture on it\n",
      "Evaluated 102/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.033445358276367\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 103/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.920053482055664\n",
      "caption an image of a computer screen showing a circuit board\n",
      "Evaluated 104/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.568382263183594\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 105/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.173240661621094\n",
      "caption a man and a woman with headsets on\n",
      "Evaluated 106/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.215837478637695\n",
      "caption a man and a woman are playing a game on a tablet\n",
      "Evaluated 107/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  16.28086280822754\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 108/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.191448211669922\n",
      "caption a man and a woman sitting next to each other\n",
      "Evaluated 109/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.28395652770996\n",
      "caption a man and a woman are playing a game on a tablet\n",
      "Evaluated 110/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.75326919555664\n",
      "caption a man and a woman with headsets on\n",
      "Evaluated 111/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.35044288635254\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 112/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.9947509765625\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 113/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.8067626953125\n",
      "caption a man and a woman sitting in front of a computer\n",
      "Evaluated 114/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.913501739501953\n",
      "caption a man and a woman are looking at a puzzle\n",
      "Evaluated 115/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.428752899169922\n",
      "caption a picture of a man and a woman looking at a tablet\n",
      "Evaluated 116/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.06975746154785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 117/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.68303871154785\n",
      "caption a man and a woman sitting in front of a tablet\n",
      "Evaluated 118/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.69207763671875\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 119/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.075796127319336\n",
      "caption a man and a woman are looking at a tablet\n",
      "Evaluated 120/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.085399627685547\n",
      "caption a man and a woman with headphones on\n",
      "Evaluated 121/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.235462188720703\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 122/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.97846031188965\n",
      "caption a man and a woman on a video game\n",
      "Evaluated 123/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.14556884765625\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 124/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.435091018676758\n",
      "caption a man and a woman playing a video game\n",
      "Evaluated 125/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.689672470092773\n",
      "caption a man and a woman with headsets on in front of a sign\n",
      "Evaluated 126/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.77479362487793\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 127/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.52164077758789\n",
      "caption a man and a woman are playing a game on a tablet\n",
      "Evaluated 128/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.00615882873535\n",
      "caption a man and a woman with headsets talking to each other\n",
      "Evaluated 129/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.78671646118164\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 130/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.57884407043457\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 131/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.805503845214844\n",
      "caption a man and a woman with headphones on\n",
      "Evaluated 132/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.21955108642578\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 133/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.456729888916016\n",
      "caption a man and a woman are playing a game on a tablet\n",
      "Evaluated 134/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a man and a woman are looking at a tablet\n",
      "Evaluated 135/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.008506774902344\n",
      "caption a man and a woman playing a video game\n",
      "Evaluated 136/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.56112289428711\n",
      "caption a man and a woman playing a game on a tablet\n",
      "Evaluated 137/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.968687057495117\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 138/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.258604049682617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a man and a woman sitting next to each other with headsets on\n",
      "Evaluated 139/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.76085090637207\n",
      "caption a man and a woman are playing a video game\n",
      "Evaluated 140/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.605798721313477\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 141/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.10781478881836\n",
      "caption a man and a woman sitting next to each other\n",
      "Evaluated 142/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.908618927001953\n",
      "caption a picture of a man and a woman next to each other\n",
      "Evaluated 143/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.31259536743164\n",
      "caption a man and a woman are looking at a tablet\n",
      "Evaluated 144/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.349153518676758\n",
      "caption a man and a woman sitting in a chair with headphones on\n",
      "Evaluated 145/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.28337287902832\n",
      "caption a man and a woman are playing a video game\n",
      "Evaluated 146/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.625843048095703\n",
      "caption a man and a woman with headsets on looking at a tablet\n",
      "Evaluated 147/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.229150772094727\n",
      "caption a man and a woman sitting next to each other with headphones on\n",
      "Evaluated 148/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.90464210510254\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 149/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.857175827026367\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 150/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.193309783935547\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 151/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.830001831054688\n",
      "caption a man and a woman sitting in front of a computer\n",
      "Evaluated 152/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.058881759643555\n",
      "caption a man and a woman are playing a video game\n",
      "Evaluated 153/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.072925567626953\n",
      "caption a man and a woman sitting in front of a computer\n",
      "Evaluated 154/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  16.812837600708008\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 155/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.717098236083984\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 156/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.457637786865234\n",
      "caption a man and a woman sitting in front of a computer\n",
      "Evaluated 157/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.739614486694336\n",
      "caption a man and a woman sitting in front of a computer\n",
      "Evaluated 158/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.097612380981445\n",
      "caption a video game with a picture of a man on it\n",
      "Evaluated 159/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.941308975219727\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 160/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.423015594482422\n",
      "caption a man and a woman are playing a game on a tablet\n",
      "Evaluated 161/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.757253646850586\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 162/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.960527420043945\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 163/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.70026206970215\n",
      "caption a picture of two people with headphones on\n",
      "Evaluated 164/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.666255950927734\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 165/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.08822250366211\n",
      "caption a man and a woman sitting in front of a tablet\n",
      "Evaluated 166/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.128028869628906\n",
      "caption a man and a woman are playing a video game\n",
      "Evaluated 167/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.00615882873535\n",
      "caption a man and a woman with headsets talking to each other\n",
      "Evaluated 168/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.899295806884766\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 169/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.537193298339844\n",
      "caption a man and a woman are playing a game on a tablet\n",
      "Evaluated 170/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.03401756286621\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 171/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.289905548095703\n",
      "caption a man and a woman are looking at a tablet\n",
      "Evaluated 172/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.260425567626953\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 173/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.450946807861328\n",
      "caption a picture of a man and a woman in front of a computer screen\n",
      "Evaluated 174/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.381061553955078\n",
      "caption a man and a woman sitting next to each other\n",
      "Evaluated 175/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.508150100708008\n",
      "caption a man and a woman sitting next to each other with headsets on\n",
      "Evaluated 176/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.58881950378418\n",
      "caption a man and a woman with headsets and a tablet\n",
      "Evaluated 177/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.566627502441406\n",
      "caption a man and a woman are talking to each other\n",
      "Evaluated 178/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.623315811157227\n",
      "caption a man and a woman playing a game on a tablet\n",
      "Evaluated 179/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.147310256958008\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 180/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.634496688842773\n",
      "caption a man and a woman are looking at a tablet\n",
      "Evaluated 181/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.48618507385254\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 182/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.867624282836914\n",
      "caption a picture of a man and a woman on a video game\n",
      "Evaluated 183/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.602645874023438\n",
      "caption a man and a woman playing a game on a tablet\n",
      "Evaluated 184/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.258604049682617\n",
      "caption a man and a woman sitting next to each other with headsets on\n",
      "Evaluated 185/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.766998291015625\n",
      "caption a man and a woman are talking to each other\n",
      "Evaluated 186/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.363344192504883\n",
      "caption a man and a woman are talking on a video game\n",
      "Evaluated 187/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.13308334350586\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 188/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.147123336791992\n",
      "caption a picture of a man and a woman on a tablet\n",
      "Evaluated 189/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.778217315673828\n",
      "caption a man and a woman sitting next to each other on a video game\n",
      "Evaluated 190/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.232725143432617\n",
      "caption a man and a woman with headphones on\n",
      "Evaluated 191/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.08657455444336\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 192/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.75628662109375\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 193/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.35858917236328\n",
      "caption a picture of a man and a woman looking at a tablet\n",
      "Evaluated 194/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.61306381225586\n",
      "caption a man and a woman sitting in front of a computer\n",
      "Evaluated 195/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.81165313720703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a man and a woman sitting in front of a computer\n",
      "Evaluated 196/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.202709197998047\n",
      "caption a man and a woman sitting in a chair with headsets on\n",
      "Evaluated 197/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.450294494628906\n",
      "caption a man and a woman playing a video game\n",
      "Evaluated 198/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.08822250366211\n",
      "caption a man and a woman sitting in front of a tablet\n",
      "Evaluated 199/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.88223648071289\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 200/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.761999130249023\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 201/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.170856475830078\n",
      "caption a man and a woman are talking on a video game\n",
      "Evaluated 202/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.786361694335938\n",
      "caption a man and a woman playing a game on a tablet\n",
      "Evaluated 203/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.299543380737305\n",
      "caption a man and a woman with headsets on talking to each other\n",
      "Evaluated 204/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.493885040283203\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 205/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.012968063354492\n",
      "caption a picture of a girl and a boy with headphones on\n",
      "Evaluated 206/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.58310890197754\n",
      "caption a man and a woman sitting next to each other with headsets on\n",
      "Evaluated 207/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.97895622253418\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 208/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.49520492553711\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 209/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.876758575439453\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 210/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.36627960205078\n",
      "caption a man and a woman are playing a game on a tablet\n",
      "Evaluated 211/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.790212631225586\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 212/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.004518508911133\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 213/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.797632217407227\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 214/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.7002010345459\n",
      "caption a man and a woman sitting next to each other with headsets on\n",
      "Evaluated 215/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.090084075927734\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 216/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.3223876953125\n",
      "caption a man and a woman with headphones on\n",
      "Evaluated 217/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.64376449584961\n",
      "caption a man and a woman with headsets looking at a tablet\n",
      "Evaluated 218/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.735797882080078\n",
      "caption a man and a woman are playing a game on a tablet\n",
      "Evaluated 219/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.121431350708008\n",
      "caption a man and a woman with headphones on\n",
      "Evaluated 220/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.025775909423828\n",
      "caption a man and a woman are looking at a tablet\n",
      "Evaluated 221/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.15496826171875\n",
      "caption a man and a woman with headphones on\n",
      "Evaluated 222/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.67951202392578\n",
      "caption a man and a woman sitting in front of a computer\n",
      "Evaluated 223/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.982378005981445\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 224/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.258480072021484\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 225/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.861244201660156\n",
      "caption a woman is talking to a man wearing headphones\n",
      "Evaluated 226/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.587846755981445\n",
      "caption a man and a woman sitting next to each other with headsets on\n",
      "Evaluated 227/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.766998291015625\n",
      "caption a man and a woman are talking to each other\n",
      "Evaluated 228/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.040372848510742\n",
      "caption a man and a woman are playing a video game\n",
      "Evaluated 229/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.689594268798828\n",
      "caption a man and a woman with headsets on talking to each other\n",
      "Evaluated 230/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.051055908203125\n",
      "caption a picture of a man and a woman with a tablet\n",
      "Evaluated 231/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.032695770263672\n",
      "caption a man and a woman are playing a video game\n",
      "Evaluated 232/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.80974578857422\n",
      "caption a man and a woman sitting in front of a computer\n",
      "Evaluated 233/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.269962310791016\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 234/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.10062599182129\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 235/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.094585418701172\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 236/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.046796798706055\n",
      "caption a man and a woman with headphones on\n",
      "Evaluated 237/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.176937103271484\n",
      "caption a man and a woman are playing a game on a tablet\n",
      "Evaluated 238/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.911630630493164\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 239/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.65779685974121\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 240/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  16.981990814208984\n",
      "caption a picture of two people with headphones on\n",
      "Evaluated 241/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.21904754638672\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 242/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.527421951293945\n",
      "caption a man and a woman on a video game\n",
      "Evaluated 243/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.129074096679688\n",
      "caption a picture of a one hour later sign\n",
      "Evaluated 244/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.0376091003418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a man and a woman with headsets looking at a tablet\n",
      "Evaluated 245/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.376113891601562\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 246/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.909053802490234\n",
      "caption a man and a woman with headsets on\n",
      "Evaluated 247/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.832061767578125\n",
      "caption a man and a woman sitting in front of a computer\n",
      "Evaluated 248/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.50968360900879\n",
      "caption a man and a woman are playing a video game\n",
      "Evaluated 249/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.498634338378906\n",
      "caption a man and a woman wearing headsets in a room\n",
      "Evaluated 250/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.569931030273438\n",
      "caption a man and a woman are looking at a puzzle\n",
      "Evaluated 251/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.259531021118164\n",
      "caption a man and a woman sitting in front of a computer\n",
      "Evaluated 252/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.315601348876953\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 253/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.810640335083008\n",
      "caption a man and a woman with headsets and a tablet\n",
      "Evaluated 254/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.876758575439453\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 255/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.03682327270508\n",
      "caption a man and a woman wearing headsets in a living room\n",
      "Evaluated 256/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.229705810546875\n",
      "caption a picture of a man and a woman next to each other\n",
      "Evaluated 257/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.74005126953125\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 258/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.697927474975586\n",
      "caption a man and a woman with headsets on\n",
      "Evaluated 259/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.826040267944336\n",
      "caption a picture of a man and a woman with headphones\n",
      "Evaluated 260/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.85462760925293\n",
      "caption a man and a woman playing a video game\n",
      "Evaluated 261/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.17452049255371\n",
      "caption a picture of a man and a woman with headphones on\n",
      "Evaluated 262/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.226421356201172\n",
      "caption a man and a woman are looking at a puzzle\n",
      "Evaluated 263/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.58203887939453\n",
      "caption a man and a woman with headsets and a tablet\n",
      "Evaluated 264/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.475332260131836\n",
      "caption a man and a woman sitting in front of a computer\n",
      "Evaluated 265/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.418169021606445\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 266/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.81585693359375\n",
      "caption a cartoon image of a man with red circles around him\n",
      "Evaluated 267/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.284854888916016\n",
      "caption a man standing on a stage in front of a large screen\n",
      "Evaluated 268/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.729814529418945\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 269/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.25420379638672\n",
      "caption an airplane flying through the dark sky\n",
      "Evaluated 270/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.75275230407715\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 271/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.217605590820312\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 272/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.574174880981445\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 273/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.52104949951172\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 274/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.752220153808594\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 275/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.660659790039062\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 276/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.060535430908203\n",
      "caption a cartoon image of a man with red circles around him\n",
      "Evaluated 277/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.668380737304688\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 278/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.81293487548828\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 279/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.359270095825195\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 280/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.026233673095703\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 281/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.37970542907715\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 282/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.99742317199707\n",
      "caption an open book with music notes on it\n",
      "Evaluated 283/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.423086166381836\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 284/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.665260314941406\n",
      "caption a man standing on a stage in front of a large screen\n",
      "Evaluated 285/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.230480194091797\n",
      "caption a man in a white shirt playing a drum set\n",
      "Evaluated 286/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.66695785522461\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 287/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.9796085357666\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 288/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.90315055847168\n",
      "caption a man playing drums on a stage in front of a large screen\n",
      "Evaluated 289/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.499496459960938\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 290/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.838960647583008\n",
      "caption a man standing on a stage in front of a drum set\n",
      "Evaluated 291/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.72812843322754\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 292/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  38.590293884277344\n",
      "caption a triangle with the words \"competition your best money practice\"\n",
      "Evaluated 293/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.984285354614258\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 294/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.085355758666992\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 295/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.726943969726562\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 296/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.578136444091797\n",
      "caption a man standing on a stage giving a speech\n",
      "Evaluated 297/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.303117752075195\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 298/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.441654205322266\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 299/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.744503021240234\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 300/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.40723991394043\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 301/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.723020553588867\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 302/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.339693069458008\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 303/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.899072647094727\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 304/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.348011016845703\n",
      "caption a picture of a wall with text on it\n",
      "Evaluated 305/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.723438262939453\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 306/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 307/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.619068145751953\n",
      "caption a bunch of colored pencils lined up in a row\n",
      "Evaluated 308/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.249046325683594\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 309/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.335979461669922\n",
      "caption a pair of glasses sitting on top of a table\n",
      "Evaluated 310/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.860984802246094\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 311/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.32513427734375\n",
      "caption a pair of glasses sitting on top of a table\n",
      "Evaluated 312/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.864107131958008\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 313/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.36541748046875\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 314/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.06526184082031\n",
      "caption a triangle with money, practice, and competition on it\n",
      "Evaluated 315/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.460420608520508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 316/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.161685943603516\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 317/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.85700035095215\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 318/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.820241928100586\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 319/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.13817596435547\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 320/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.91032600402832\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 321/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.66777229309082\n",
      "caption a man standing on a stage in front of a large screen\n",
      "Evaluated 322/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.479877471923828\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 323/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.06100082397461\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 324/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.13897132873535\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 325/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.57111930847168\n",
      "caption a cartoon image of a man with red circles around him\n",
      "Evaluated 326/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.553382873535156\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 327/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.444902420043945\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 328/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.013792037963867\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 329/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.467275619506836\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 330/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.884239196777344\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 331/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.080141067504883\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 332/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.67498779296875\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 333/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.510395050048828\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 334/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.256227493286133\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 335/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.582983016967773\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 336/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.197649002075195\n",
      "caption a picture of a wall with words on it\n",
      "Evaluated 337/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.37493896484375\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 338/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.280834197998047\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 339/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.69544219970703\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 340/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.269290924072266\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 341/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.753795623779297\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 342/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.186199188232422\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 343/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.25420379638672\n",
      "caption an airplane flying through the dark sky\n",
      "Evaluated 344/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.02450942993164\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 345/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.895620346069336\n",
      "caption a man standing on a stage in front of a large screen\n",
      "Evaluated 346/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.35136604309082\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 347/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.70255470275879\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 348/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.196855545043945\n",
      "caption a man standing on a stage in front of a drum set\n",
      "Evaluated 349/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.52202796936035\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 350/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.282859802246094\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 351/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.769058227539062\n",
      "caption a business card with the name of a company on it\n",
      "Evaluated 352/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.79355812072754\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 353/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.202716827392578\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 354/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.245080947875977\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 355/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.377634048461914\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 356/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.913293838500977\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 357/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.96822166442871\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 358/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.320310592651367\n",
      "caption a cartoon image of a man with red circles around him\n",
      "Evaluated 359/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.85080337524414\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 360/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.10481834411621\n",
      "caption a person jumping in the air in front of a mural\n",
      "Evaluated 361/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.699251174926758\n",
      "caption a man playing drums on a stage in front of a large screen\n",
      "Evaluated 362/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.170305252075195\n",
      "caption a blurry picture of a person playing drums\n",
      "Evaluated 363/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.27045440673828\n",
      "caption a man standing on a stage with a drum set in the background\n",
      "Evaluated 364/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.860000610351562\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 365/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.576255798339844\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 366/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.886953353881836\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 367/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.67041778564453\n",
      "caption a man in a white shirt playing drums\n",
      "Evaluated 368/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.981887817382812\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 369/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.809188842773438\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 370/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.05706024169922\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 371/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.165834426879883\n",
      "caption an airplane flying through the dark sky\n",
      "Evaluated 372/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.664249420166016\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 373/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.108341217041016\n",
      "caption a cartoon image of a man with red circles around him\n",
      "Evaluated 374/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.737258911132812\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 375/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.285423278808594\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 376/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.670766830444336\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 377/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.19847297668457\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 378/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.0845890045166\n",
      "caption a man standing on a stage in front of a large screen\n",
      "Evaluated 379/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.96239471435547\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 380/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.6920108795166\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 381/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.158042907714844\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 382/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.270376205444336\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 383/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.828184127807617\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 384/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.682531356811523\n",
      "caption a man standing on a stage in front of a large screen\n",
      "Evaluated 385/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.198514938354492\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 386/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.600629806518555\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 387/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.212434768676758\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 388/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.871801376342773\n",
      "caption the title of a book with a picture of a planet and a rocket\n",
      "Evaluated 389/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.856674194335938\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 390/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.91880226135254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 391/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.27475929260254\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 392/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.438800811767578\n",
      "caption a cartoon image of a man with red circles around him\n",
      "Evaluated 393/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.72758674621582\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 394/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.7584171295166\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 395/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.2215633392334\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 396/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.2979679107666\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 397/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.598403930664062\n",
      "caption a cartoon image of a man with red circles around him\n",
      "Evaluated 398/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.994470596313477\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 399/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.282272338867188\n",
      "caption a man standing on a stage in front of a drum set\n",
      "Evaluated 400/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.617162704467773\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 401/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.672758102416992\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 402/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.927936553955078\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 403/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.855255126953125\n",
      "caption a man standing on a stage in front of a drum set\n",
      "Evaluated 404/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.659353256225586\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 405/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.712318420410156\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 406/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.855974197387695\n",
      "caption a man standing on a stage with his arms outstretched\n",
      "Evaluated 407/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.139427185058594\n",
      "caption a pair of glasses sitting on top of a table\n",
      "Evaluated 408/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.701684951782227\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 409/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.114107131958008\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 410/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.039648056030273\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 411/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.726741790771484\n",
      "caption a man standing in front of a drum set\n",
      "Evaluated 412/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.16284942626953\n",
      "caption a man standing on a stage in front of a screen\n",
      "Evaluated 413/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.243932723999023\n",
      "caption a man standing on a stage with a microphone\n",
      "Evaluated 414/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.83924674987793\n",
      "caption a man standing on a stage with a drum in front of him\n",
      "Evaluated 415/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.742685317993164\n",
      "caption a person is using a crochet hook to make something\n",
      "Evaluated 416/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.527042388916016\n",
      "caption a person using a marker to draw on a piece of plastic\n",
      "Evaluated 417/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.21222686767578\n",
      "caption a person is using a tool to make something\n",
      "Evaluated 418/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.035511016845703\n",
      "caption a person putting something on someone else's arm\n",
      "Evaluated 419/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.441307067871094\n",
      "caption a woman is working on a cell phone\n",
      "Evaluated 420/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.241756439208984\n",
      "caption a close up of a person working on something\n",
      "Evaluated 421/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.4080753326416\n",
      "caption a person sitting at a table with a loom\n",
      "Evaluated 422/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.21322250366211\n",
      "caption a person holding a pair of scissors\n",
      "Evaluated 423/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.432058334350586\n",
      "caption a woman sitting at a table with some food\n",
      "Evaluated 424/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.475271224975586\n",
      "caption a close up of a person working on something\n",
      "Evaluated 425/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.57355308532715\n",
      "caption a close up of a person's hand holding something\n",
      "Evaluated 426/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.484542846679688\n",
      "caption a woman sitting at a table with a plastic container\n",
      "Evaluated 427/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.659231185913086\n",
      "caption a woman sitting at a table making doll clothes\n",
      "Evaluated 428/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.590517044067383\n",
      "caption a close up of a person working on something\n",
      "Evaluated 429/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.789464950561523\n",
      "caption a woman sitting at a table with blue beads\n",
      "Evaluated 430/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.094573974609375\n",
      "caption a close up of a toothbrush with blue and white beads on it\n",
      "Evaluated 431/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.1252498626709\n",
      "caption a close up of a person working on something\n",
      "Evaluated 432/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.737834930419922\n",
      "caption a woman is working on a bracelet on a table\n",
      "Evaluated 433/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.557262420654297\n",
      "caption a close up of a person working on something\n",
      "Evaluated 434/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.07309341430664\n",
      "caption a person holding plastic beads in their hand\n",
      "Evaluated 435/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.045955657958984\n",
      "caption a close up of a person working on something\n",
      "Evaluated 436/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.407777786254883\n",
      "caption a person holding up two different colored bracelets\n",
      "Evaluated 437/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.998857498168945\n",
      "caption a woman in a black shirt holding a toothbrush\n",
      "Evaluated 438/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.917510986328125\n",
      "caption a person making a bracelet with beads on it\n",
      "Evaluated 439/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.742328643798828\n",
      "caption a close up of a person's hands working on something\n",
      "Evaluated 440/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.594736099243164\n",
      "caption a person holding a pair of scissors in their hand\n",
      "Evaluated 441/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.368885040283203\n",
      "caption a close up of a person holding something\n",
      "Evaluated 442/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.489112854003906\n",
      "caption a woman sitting at a table working on a craft\n",
      "Evaluated 443/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.669696807861328\n",
      "caption a person is working on a loom at a table\n",
      "Evaluated 444/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.980512619018555\n",
      "caption a woman sitting at a table holding a string\n",
      "Evaluated 445/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.230546951293945\n",
      "caption a woman is sitting at a table making something\n",
      "Evaluated 446/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.49054527282715\n",
      "caption a close up of a person holding a crochet hook\n",
      "Evaluated 447/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.096418380737305\n",
      "caption a close up of a person working on something\n",
      "Evaluated 448/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.350189208984375\n",
      "caption a person using a pen to write on a piece of plastic\n",
      "Evaluated 449/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.006393432617188\n",
      "caption a woman sitting at a table with toys\n",
      "Evaluated 450/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.629011154174805\n",
      "caption a close up of a strand of glass beads\n",
      "Evaluated 451/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.9970645904541\n",
      "caption a close up of a person's hand holding something\n",
      "Evaluated 452/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.07647132873535\n",
      "caption a close up of a toothbrush with blue and white beads on it\n",
      "Evaluated 453/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.000885009765625\n",
      "caption a woman sitting at a table with a plastic container\n",
      "Evaluated 454/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.5174503326416\n",
      "caption a close up of a bunch of plastic bottles\n",
      "Evaluated 455/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.42428207397461\n",
      "caption a pair of hands holding two different colored toys\n",
      "Evaluated 456/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.804410934448242\n",
      "caption a person using a pen to make a bracelet\n",
      "Evaluated 457/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.213058471679688\n",
      "caption a woman is working on a cell phone\n",
      "Evaluated 458/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.029085159301758\n",
      "caption a person using a pen to write on a piece of plastic\n",
      "Evaluated 459/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.685813903808594\n",
      "caption a person using a marker to draw on a piece of plastic\n",
      "Evaluated 460/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.97301483154297\n",
      "caption the logo for howcast is shown on a white background\n",
      "Evaluated 461/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.542814254760742\n",
      "caption a person is putting something together on a table\n",
      "Evaluated 462/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.666296005249023\n",
      "caption a woman sitting at a table making something\n",
      "Evaluated 463/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.445919036865234\n",
      "caption a person sitting at a table with a bunch of stuff on it\n",
      "Evaluated 464/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.143325805664062\n",
      "caption a close up of a person working on something\n",
      "Evaluated 465/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.87017250061035\n",
      "caption a woman sitting at a table with a plastic container\n",
      "Evaluated 466/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.883655548095703\n",
      "caption a close up of a person working on something\n",
      "Evaluated 467/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.500967025756836\n",
      "caption a person sitting at a table with a bunch of stuff on it\n",
      "Evaluated 468/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.270305633544922\n",
      "caption a close up of a person holding a piece of plastic\n",
      "Evaluated 469/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  41.54045867919922\n",
      "caption how to make a jazzy jazz bracelet\n",
      "Evaluated 470/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.40416717529297\n",
      "caption a woman sitting at a table working on a craft\n",
      "Evaluated 471/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.57948875427246\n",
      "caption a close up of a person working on something\n",
      "Evaluated 472/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.347780227661133\n",
      "caption a close up of a person working on something\n",
      "Evaluated 473/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.702877044677734\n",
      "caption a person making a bracelet with a needle and thread\n",
      "Evaluated 474/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.741968154907227\n",
      "caption a bunch of blue and clear plastic bottles on a table\n",
      "Evaluated 475/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.793764114379883\n",
      "caption a person using a pair of scissors to cut a piece of plastic\n",
      "Evaluated 476/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.130538940429688\n",
      "caption a close up of a bunch of blue and silver beads\n",
      "Evaluated 477/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.249881744384766\n",
      "caption a close up of a person working on something\n",
      "Evaluated 478/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.04241180419922\n",
      "caption a close up of a person holding something\n",
      "Evaluated 479/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.475433349609375\n",
      "caption a close up of a persons hand holding some blue nuts\n",
      "Evaluated 480/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.38876724243164\n",
      "caption a woman sitting at a table working on a craft\n",
      "Evaluated 481/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.308706283569336\n",
      "caption a person using a pair of scissors to make a bracelet\n",
      "Evaluated 482/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.31187057495117\n",
      "caption a person is making a bracelet out of beads\n",
      "Evaluated 483/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.98592758178711\n",
      "caption a person holding a piece of plastic with blue and white beads on it\n",
      "Evaluated 484/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.484468460083008\n",
      "caption a pair of hands holding a pair of scissors\n",
      "Evaluated 485/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.468063354492188\n",
      "caption a woman holding a blue toothbrush in her hand\n",
      "Evaluated 486/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.11627769470215\n",
      "caption a close up of a bunch of blue and clear tubes\n",
      "Evaluated 487/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.77853012084961\n",
      "caption a close up of a person working on something\n",
      "Evaluated 488/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.959138870239258\n",
      "caption a woman is using a pair of scissors to cut a piece of string\n",
      "Evaluated 489/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.82716178894043\n",
      "caption a close up of a person working on something\n",
      "Evaluated 490/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.79281234741211\n",
      "caption a person using a glue gun to attach plastic beads to a bracelet\n",
      "Evaluated 491/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.94831085205078\n",
      "caption a person holding a bunch of blue and clear plastic rings\n",
      "Evaluated 492/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.50124740600586\n",
      "caption a woman sitting at a table with a plastic container\n",
      "Evaluated 493/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.794647216796875\n",
      "caption a close up of a person working on something\n",
      "Evaluated 494/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.31386184692383\n",
      "caption a person is putting blue and white rubber bands on a table\n",
      "Evaluated 495/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.31362533569336\n",
      "caption a close up of a person holding a crochet hook\n",
      "Evaluated 496/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.893877029418945\n",
      "caption a close up of a person touching something\n",
      "Evaluated 497/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.753339767456055\n",
      "caption a man with a backpack walking on a dirt road\n",
      "Evaluated 498/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.321147918701172\n",
      "caption donald j trump's tweet\n",
      "Evaluated 499/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.6719913482666\n",
      "caption two large ships in the middle of a large body of water\n",
      "Evaluated 500/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.362369537353516\n",
      "caption a group of people standing in front of the sun\n",
      "Evaluated 501/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.432138442993164\n",
      "caption a black and white advertisement for hbo now and a white and black advertisement for hbo\n",
      "Evaluated 502/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.34990119934082\n",
      "caption two men in suits sitting next to each other\n",
      "Evaluated 503/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  16.64529800415039\n",
      "caption a group of people standing around a podium\n",
      "Evaluated 504/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.311992645263672\n",
      "caption a black background with a white logo on it\n",
      "Evaluated 505/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.72243309020996\n",
      "caption a picture of a check list with the words serving, diagnosed, serve, and transition\n",
      "Evaluated 506/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.66550636291504\n",
      "caption a group of soldiers walking in the sun\n",
      "Evaluated 507/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.325279235839844\n",
      "caption a man in a green shirt standing in front of a brick building\n",
      "Evaluated 508/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.189716339111328\n",
      "caption a woman sitting in front of a laptop computer\n",
      "Evaluated 509/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.66728401184082\n",
      "caption a woman sitting in front of a laptop computer\n",
      "Evaluated 510/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.38007164001465\n",
      "caption a woman in glasses talking to another person\n",
      "Evaluated 511/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.252017974853516\n",
      "caption a woman sitting in front of a laptop computer\n",
      "Evaluated 512/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  37.23151779174805\n",
      "caption a picture of alexandra jaffe with the words vce news\n",
      "Evaluated 513/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.03750228881836\n",
      "caption a tweet from donald trump\n",
      "Evaluated 514/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.40605926513672\n",
      "caption a woman sitting in front of a laptop computer\n",
      "Evaluated 515/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.915983200073242\n",
      "caption a man in glasses standing in front of a brick building\n",
      "Evaluated 516/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.11214828491211\n",
      "caption a man holding a cell phone in front of a white background\n",
      "Evaluated 517/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.77918815612793\n",
      "caption a woman sitting at a table with a laptop\n",
      "Evaluated 518/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.617258071899414\n",
      "caption two men in suits sitting next to each other\n",
      "Evaluated 519/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.809751510620117\n",
      "caption a man with glasses and a green shirt\n",
      "Evaluated 520/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.12415885925293\n",
      "caption a woman in glasses talking to a man\n",
      "Evaluated 521/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.70322036743164\n",
      "caption a group of soldiers walking down the street\n",
      "Evaluated 522/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.291866302490234\n",
      "caption a woman with glasses is using a laptop computer\n",
      "Evaluated 523/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.70758056640625\n",
      "caption a close up of a group of soldiers walking\n",
      "Evaluated 524/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  15.455276489257812\n",
      "caption a group of people holding protest signs in a city\n",
      "Evaluated 525/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.36681365966797\n",
      "caption a man in glasses standing in front of a brick building\n",
      "Evaluated 526/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.274311065673828\n",
      "caption a screen shot of a website with a question mark on it\n",
      "Evaluated 527/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.1289119720459\n",
      "caption a large building with many cars parked in front of it\n",
      "Evaluated 528/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.851709365844727\n",
      "caption a picture of a check list with the words serving, diagnosed, and transition\n",
      "Evaluated 529/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.09438705444336\n",
      "caption a man standing in front of a brick building\n",
      "Evaluated 530/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.150245666503906\n",
      "caption a man wearing glasses and a green shirt\n",
      "Evaluated 531/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  15.494430541992188\n",
      "caption a woman sitting in front of a laptop computer\n",
      "Evaluated 532/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.474205017089844\n",
      "caption a person holding up a sign that says \"support all our troops\"\n",
      "Evaluated 533/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.90106773376465\n",
      "caption a woman sitting in front of a laptop computer\n",
      "Evaluated 534/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.729320526123047\n",
      "caption a screen shot of an article on the white house website\n",
      "Evaluated 535/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.84490394592285\n",
      "caption a woman sitting in front of a laptop computer\n",
      "Evaluated 536/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  13.358161926269531\n",
      "caption a group of people walking in the sun\n",
      "Evaluated 537/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.312641143798828\n",
      "caption a woman with glasses looking at a man\n",
      "Evaluated 538/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.74483871459961\n",
      "caption a woman sitting in front of a laptop computer\n",
      "Evaluated 539/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.353073120117188\n",
      "caption a screen shot of a website with a question about gender dysphoria\n",
      "Evaluated 540/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.351438522338867\n",
      "caption a woman sitting in front of a laptop computer\n",
      "Evaluated 541/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.65865135192871\n",
      "caption a woman sitting in front of a laptop computer\n",
      "Evaluated 542/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.56190299987793\n",
      "caption a man in a green shirt talking to someone\n",
      "Evaluated 543/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  15.130213737487793\n",
      "caption a man in a green shirt standing in front of a brick building\n",
      "Evaluated 544/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.97883415222168\n",
      "caption a man and a woman standing in front of a brick building\n",
      "Evaluated 545/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.419662475585938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a group of people working on computers in an office\n",
      "Evaluated 546/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.097976684570312\n",
      "caption a man wearing glasses and a green shirt\n",
      "Evaluated 547/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.502294540405273\n",
      "caption a man standing in front of a brick building\n",
      "Evaluated 548/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.39495849609375\n",
      "caption a man wearing glasses in front of a brick building\n",
      "Evaluated 549/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.731964111328125\n",
      "caption a picture of a check list with the words \"serving, diagnosed, serve, transition\"\n",
      "Evaluated 550/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.34148597717285\n",
      "caption a picture of a check list with the words serving, diagnosed, and transition\n",
      "Evaluated 551/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.443273544311523\n",
      "caption a large building with a clock on top of it\n",
      "Evaluated 552/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.517410278320312\n",
      "caption a woman sitting in front of a laptop computer\n",
      "Evaluated 553/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.98362159729004\n",
      "caption an image of a memo for the president of the united states\n",
      "Evaluated 554/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.383472442626953\n",
      "caption a man standing in front of a brick building\n",
      "Evaluated 555/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.74244499206543\n",
      "caption a man and a woman standing in front of a brick building\n",
      "Evaluated 556/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.241779327392578\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 557/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.62724494934082\n",
      "caption a girl with headphones on and a boy with headphones on\n",
      "Evaluated 558/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.833864212036133\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 559/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.064838409423828\n",
      "caption a man in a suit is making a funny face\n",
      "Evaluated 560/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.17444610595703\n",
      "caption a man wearing a headset giving a thumbs up\n",
      "Evaluated 561/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.35468292236328\n",
      "caption a young girl sitting in front of a laptop computer\n",
      "Evaluated 562/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.551738739013672\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 563/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.89111328125\n",
      "caption a young girl with headphones and a laptop\n",
      "Evaluated 564/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.63129234313965\n",
      "caption a young girl wearing headphones on a laptop computer\n",
      "Evaluated 565/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.196691513061523\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 566/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.391176223754883\n",
      "caption a collage of a boy with headphones, a boy with headphones, a boy with headphones, a boy with headphones, a boy with headphones, a\n",
      "Evaluated 567/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.041780471801758\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 568/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.290800094604492\n",
      "caption a young boy sitting in front of a laptop computer\n",
      "Evaluated 569/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.765644073486328\n",
      "caption a girl sitting in front of a laptop with headphones on\n",
      "Evaluated 570/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.77167320251465\n",
      "caption a man wearing headphones praying while sitting in a chair\n",
      "Evaluated 571/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.049596786499023\n",
      "caption a young girl sitting in front of a man with headphones\n",
      "Evaluated 572/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.925132751464844\n",
      "caption a young girl with headphones and a laptop\n",
      "Evaluated 573/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.405244827270508\n",
      "caption a young girl sitting in front of a green wall\n",
      "Evaluated 574/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.487926483154297\n",
      "caption a young boy sitting in front of a laptop computer\n",
      "Evaluated 575/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.9299201965332\n",
      "caption a newspaper article about climate change and security\n",
      "Evaluated 576/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.326946258544922\n",
      "caption a young boy sitting at a desk with headphones on\n",
      "Evaluated 577/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.250293731689453\n",
      "caption a man wearing headphones with his eyes closed\n",
      "Evaluated 578/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.45853614807129\n",
      "caption a young girl sitting in front of a computer screen\n",
      "Evaluated 579/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.044544219970703\n",
      "caption a man and a woman sitting in front of a laptop\n",
      "Evaluated 580/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.075136184692383\n",
      "caption a girl sitting at a desk with headphones on\n",
      "Evaluated 581/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.178905487060547\n",
      "caption a man in a white suit walking down a street\n",
      "Evaluated 582/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.686115264892578\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 583/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.68247413635254\n",
      "caption a young boy sitting in front of a laptop computer\n",
      "Evaluated 584/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.775794982910156\n",
      "caption a young boy with headphones and a laptop\n",
      "Evaluated 585/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.077516555786133\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 586/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.41102409362793\n",
      "caption a young boy wearing headphones on a computer screen\n",
      "Evaluated 587/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.588382720947266\n",
      "caption a young girl and a man on a laptop\n",
      "Evaluated 588/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.002872467041016\n",
      "caption a young girl sitting in front of a laptop with headphones on\n",
      "Evaluated 589/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.07253074645996\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 590/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.391780853271484\n",
      "caption a young boy with headphones and a laptop\n",
      "Evaluated 591/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.75377655029297\n",
      "caption a young girl sitting in front of a laptop\n",
      "Evaluated 592/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.48369216918945\n",
      "caption a young girl with headphones and a laptop\n",
      "Evaluated 593/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.51824951171875\n",
      "caption a girl sitting at a table with headphones on\n",
      "Evaluated 594/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.088790893554688\n",
      "caption a young boy sitting at a table with a microphone\n",
      "Evaluated 595/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.730499267578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a young girl sitting at a desk with headphones on\n",
      "Evaluated 596/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.481609344482422\n",
      "caption a young girl with headphones on and a man on a computer\n",
      "Evaluated 597/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.59568214416504\n",
      "caption a man wearing headphones making a face\n",
      "Evaluated 598/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.54500389099121\n",
      "caption a girl sitting in front of a computer screen\n",
      "Evaluated 599/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.150653839111328\n",
      "caption a young girl with headphones and a laptop\n",
      "Evaluated 600/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.594097137451172\n",
      "caption a young girl sitting in front of a computer screen\n",
      "Evaluated 601/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.167367935180664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a young boy wearing headphones on a laptop computer\n",
      "Evaluated 602/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.73360824584961\n",
      "caption a young girl sitting in front of a computer screen\n",
      "Evaluated 603/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.924592971801758\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 604/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.71553611755371\n",
      "caption a young boy wearing headphones while using a laptop computer\n",
      "Evaluated 605/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.142831802368164\n",
      "caption a boy with headphones on and a girl with headphones on\n",
      "Evaluated 606/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.390823364257812\n",
      "caption a picture of a young boy with headphones on\n",
      "Evaluated 607/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.20893669128418\n",
      "caption a young boy sitting at a table with a microphone in front of him\n",
      "Evaluated 608/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.704973220825195\n",
      "caption a young girl with headphones and a laptop\n",
      "Evaluated 609/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.28388595581055\n",
      "caption a young boy with headphones and a laptop\n",
      "Evaluated 610/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.34196662902832\n",
      "caption a young girl with headphones on and a laptop\n",
      "Evaluated 611/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.71728515625\n",
      "caption a young boy sitting in front of a green screen\n",
      "Evaluated 612/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.92876434326172\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 613/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.975996017456055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a boy sitting at a desk with headphones on\n",
      "Evaluated 614/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.73961067199707\n",
      "caption a young girl sitting at a desk with headphones on\n",
      "Evaluated 615/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.017444610595703\n",
      "caption a young girl sitting in front of a computer screen\n",
      "Evaluated 616/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.8221435546875\n",
      "caption a young boy sitting in front of a laptop computer\n",
      "Evaluated 617/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.599985122680664\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 618/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.913360595703125\n",
      "caption a young boy with headphones and a laptop\n",
      "Evaluated 619/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.15058708190918\n",
      "caption a young girl sitting in front of a green wall\n",
      "Evaluated 620/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.850555419921875\n",
      "caption a girl with headphones and a boy with headphones\n",
      "Evaluated 621/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.35931396484375\n",
      "caption a young girl sitting in front of a computer screen\n",
      "Evaluated 622/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.985322952270508\n",
      "caption a young girl with headphones on and a green screen behind her\n",
      "Evaluated 623/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.276824951171875\n",
      "caption a girl with headphones on and a boy with headphones on\n",
      "Evaluated 624/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.730867385864258\n",
      "caption a young girl sitting in front of a laptop\n",
      "Evaluated 625/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.74561882019043\n",
      "caption a young girl sitting in front of a computer screen\n",
      "Evaluated 626/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.07025909423828\n",
      "caption a young girl sitting in front of a laptop computer\n",
      "Evaluated 627/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.238605499267578\n",
      "caption a young boy sitting at a table with a computer screen in front of him\n",
      "Evaluated 628/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.85087776184082\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 629/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.081851959228516\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 630/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.499374389648438\n",
      "caption a boy with headphones on and a man on a laptop\n",
      "Evaluated 631/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.637290954589844\n",
      "caption a man in a suit with headphones on\n",
      "Evaluated 632/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.326946258544922\n",
      "caption a young boy sitting at a desk with headphones on\n",
      "Evaluated 633/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.373077392578125\n",
      "caption a young boy sitting in front of a green screen\n",
      "Evaluated 634/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.2668514251709\n",
      "caption a little girl sitting at a desk with headphones on\n",
      "Evaluated 635/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.127094268798828\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 636/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.513559341430664\n",
      "caption a young girl sitting at a desk with headphones on\n",
      "Evaluated 637/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.63129234313965\n",
      "caption a young girl wearing headphones on a laptop computer\n",
      "Evaluated 638/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.699853897094727\n",
      "caption a young girl sitting at a desk with a laptop in front of her\n",
      "Evaluated 639/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.819799423217773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a young boy with headphones and a laptop\n",
      "Evaluated 640/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.36620330810547\n",
      "caption a young boy sitting in front of a computer screen\n",
      "Evaluated 641/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.319250106811523\n",
      "caption a young girl sitting at a table with her arms outstretched\n",
      "Evaluated 642/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.706817626953125\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 643/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.09787368774414\n",
      "caption a young boy sitting next to a man on a computer\n",
      "Evaluated 644/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.189022064208984\n",
      "caption a picture of a young boy with headphones on\n",
      "Evaluated 645/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.28890609741211\n",
      "caption a young boy sitting in front of a laptop with headphones on\n",
      "Evaluated 646/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.527610778808594\n",
      "caption a little girl holding a pair of headphones in front of a laptop\n",
      "Evaluated 647/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.78190803527832\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 648/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.335119247436523\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 649/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.370338439941406\n",
      "caption a girl with headphones and a man on a laptop\n",
      "Evaluated 650/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.285049438476562\n",
      "caption a boy with headphones on and a girl with headphones on\n",
      "Evaluated 651/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.600305557250977\n",
      "caption a picture of a young boy with headphones on\n",
      "Evaluated 652/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.737205505371094\n",
      "caption a young boy sitting at a desk with headphones on\n",
      "Evaluated 653/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.329538345336914\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 654/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.804475784301758\n",
      "caption a boy sitting in front of a laptop with headphones on\n",
      "Evaluated 655/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.66868019104004\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 656/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.964475631713867\n",
      "caption a girl with headphones on and a boy with headphones on\n",
      "Evaluated 657/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.814638137817383\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 658/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.77054214477539\n",
      "caption a young girl sitting in front of a laptop computer\n",
      "Evaluated 659/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.8221435546875\n",
      "caption a young boy sitting in front of a laptop computer\n",
      "Evaluated 660/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.737333297729492\n",
      "caption a girl sitting at a desk with headphones on and a laptop\n",
      "Evaluated 661/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.21213150024414\n",
      "caption a young girl sitting in front of a laptop with headphones on\n",
      "Evaluated 662/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.751787185668945\n",
      "caption a boy sitting at a table talking on a phone\n",
      "Evaluated 663/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.994462966918945\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 664/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.14647102355957\n",
      "caption a girl with headphones and a laptop\n",
      "Evaluated 665/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.518186569213867\n",
      "caption a young girl sitting in front of a laptop computer\n",
      "Evaluated 666/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.568405151367188\n",
      "caption a young girl sitting in front of a green screen\n",
      "Evaluated 667/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.502460479736328\n",
      "caption a girl sitting in front of a computer screen\n",
      "Evaluated 668/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.923328399658203\n",
      "caption a man in a yellow tank top with headphones on\n",
      "Evaluated 669/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.781770706176758\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 670/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.600502014160156\n",
      "caption a girl with headphones on and a boy with headphones on\n",
      "Evaluated 671/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.443878173828125\n",
      "caption a young girl sitting at a desk with headphones on\n",
      "Evaluated 672/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.474395751953125\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 673/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.646034240722656\n",
      "caption a young girl sitting in front of a green wall\n",
      "Evaluated 674/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.425107955932617\n",
      "caption a young boy sitting at a desk with headphones on\n",
      "Evaluated 675/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.144046783447266\n",
      "caption a young boy with headphones and a laptop\n",
      "Evaluated 676/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.430110931396484\n",
      "caption a young girl with headphones and a laptop\n",
      "Evaluated 677/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.049072265625\n",
      "caption a young boy with headphones and a laptop\n",
      "Evaluated 678/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.571453094482422\n",
      "caption two people sitting at a table with a laptop\n",
      "Evaluated 679/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.28541374206543\n",
      "caption a group of people sitting in front of a laptop\n",
      "Evaluated 680/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.43944549560547\n",
      "caption a man and a woman are on a video chat\n",
      "Evaluated 681/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.28029441833496\n",
      "caption a boy sitting at a desk with headphones on\n",
      "Evaluated 682/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.081083297729492\n",
      "caption a man and a woman are on a video call\n",
      "Evaluated 683/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.324974060058594\n",
      "caption a girl with headphones and a laptop\n",
      "Evaluated 684/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.043752670288086\n",
      "caption a young boy sitting in front of a green wall\n",
      "Evaluated 685/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.159528732299805\n",
      "caption a young girl with headphones on in front of a green screen\n",
      "Evaluated 686/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.987680435180664\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 687/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.727313995361328\n",
      "caption a picture of a young boy with headphones on\n",
      "Evaluated 688/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.04296112060547\n",
      "caption a young boy sitting in front of a laptop with headphones on\n",
      "Evaluated 689/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.73832130432129\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 690/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.834156036376953\n",
      "caption a young boy sitting at a desk with headphones on\n",
      "Evaluated 691/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.545854568481445\n",
      "caption a young boy sitting at a table with headphones on\n",
      "Evaluated 692/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.877147674560547\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 693/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.336626052856445\n",
      "caption a young girl sitting in front of a computer screen\n",
      "Evaluated 694/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.964807510375977\n",
      "caption a girl sitting in front of a laptop with headphones on\n",
      "Evaluated 695/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.619070053100586\n",
      "caption a man wearing headphones with his eyes closed\n",
      "Evaluated 696/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.28702163696289\n",
      "caption a young girl with headphones and a laptop\n",
      "Evaluated 697/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.43851852416992\n",
      "caption a young boy sitting in front of a green screen\n",
      "Evaluated 698/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.76668357849121\n",
      "caption a young girl with headphones and a laptop\n",
      "Evaluated 699/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.758134841918945\n",
      "caption a young boy sitting at a desk with headphones on\n",
      "Evaluated 700/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.67915153503418\n",
      "caption a young girl sitting in front of a computer screen\n",
      "Evaluated 701/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.80908966064453\n",
      "caption a young boy sitting in front of a laptop computer\n",
      "Evaluated 702/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.735116958618164\n",
      "caption a screen shot of a climate change page on a website\n",
      "Evaluated 703/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.35193634033203\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 704/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.612398147583008\n",
      "caption a young boy sitting in front of a computer with headphones on\n",
      "Evaluated 705/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.913360595703125\n",
      "caption a young boy with headphones and a laptop\n",
      "Evaluated 706/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.28541374206543\n",
      "caption a group of people sitting in front of a laptop\n",
      "Evaluated 707/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a young girl sitting in front of a laptop computer\n",
      "Evaluated 708/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.555416107177734\n",
      "caption a girl with headphones and a boy with headphones\n",
      "Evaluated 709/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.922388076782227\n",
      "caption a young boy sitting in front of a computer screen\n",
      "Evaluated 710/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.203142166137695\n",
      "caption a girl with headphones on and a boy with headphones on\n",
      "Evaluated 711/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.33814239501953\n",
      "caption a young girl sitting in front of a laptop with headphones on\n",
      "Evaluated 712/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.19812774658203\n",
      "caption a young girl sitting in front of a laptop with headphones on\n",
      "Evaluated 713/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.072715759277344\n",
      "caption a young boy sitting in front of a laptop with headphones on\n",
      "Evaluated 714/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.918188095092773\n",
      "caption a young girl sitting in front of a computer screen\n",
      "Evaluated 715/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.650318145751953\n",
      "caption a girl with headphones and a smile on her face\n",
      "Evaluated 716/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.80112648010254\n",
      "caption a man and a boy sitting next to each other\n",
      "Evaluated 717/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.932743072509766\n",
      "caption a young girl sitting in front of a green wall\n",
      "Evaluated 718/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.52643394470215\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 719/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.709312438964844\n",
      "caption a young boy sitting at a desk with headphones on\n",
      "Evaluated 720/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.684019088745117\n",
      "caption a boy wearing a green shirt and a man wearing a headset\n",
      "Evaluated 721/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.320158004760742\n",
      "caption a young boy sitting at a desk with headphones on\n",
      "Evaluated 722/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.884204864501953\n",
      "caption a man sitting in a chair on the beach\n",
      "Evaluated 723/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.14647102355957\n",
      "caption a girl with headphones and a laptop\n",
      "Evaluated 724/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.534160614013672\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 725/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.9990234375\n",
      "caption a man and a woman are on a video call\n",
      "Evaluated 726/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a young boy sitting in front of a laptop\n",
      "Evaluated 727/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.57328224182129\n",
      "caption a young boy with headphones and a laptop\n",
      "Evaluated 728/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.29145050048828\n",
      "caption a young girl sitting in front of a laptop with headphones on\n",
      "Evaluated 729/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.534748077392578\n",
      "caption a boy with headphones on and a girl with headphones on\n",
      "Evaluated 730/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.702129364013672\n",
      "caption a boy sitting at a table with headphones on\n",
      "Evaluated 731/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.032915115356445\n",
      "caption a young girl sitting in front of a computer screen\n",
      "Evaluated 732/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.120859146118164\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 733/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.22853660583496\n",
      "caption a young girl sitting in front of a laptop\n",
      "Evaluated 734/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.474328994750977\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 735/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.43959617614746\n",
      "caption a young boy sitting in front of a laptop computer\n",
      "Evaluated 736/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.955989837646484\n",
      "caption a young girl sitting at a desk with headphones on\n",
      "Evaluated 737/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.816890716552734\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 738/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.89908790588379\n",
      "caption a young girl sitting at a table with headphones on\n",
      "Evaluated 739/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.926172256469727\n",
      "caption a girl with headphones and a laptop\n",
      "Evaluated 740/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.82111930847168\n",
      "caption a young boy sitting in front of a laptop computer\n",
      "Evaluated 741/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.035423278808594\n",
      "caption a young boy sitting in front of a computer screen\n",
      "Evaluated 742/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.4907283782959\n",
      "caption a man and a woman talking on a video call\n",
      "Evaluated 743/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.98892593383789\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 744/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.128437042236328\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 745/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.737720489501953\n",
      "caption a girl sitting in front of a laptop computer\n",
      "Evaluated 746/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.218961715698242\n",
      "caption a girl sitting at a desk with headphones on\n",
      "Evaluated 747/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.780471801757812\n",
      "caption a boy sitting at a desk with headphones on\n",
      "Evaluated 748/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.39923095703125\n",
      "caption a young boy sitting in front of a computer screen\n",
      "Evaluated 749/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.1658935546875\n",
      "caption a young girl with headphones and a laptop\n",
      "Evaluated 750/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.330991744995117\n",
      "caption a young girl sitting in front of a laptop computer\n",
      "Evaluated 751/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.448593139648438\n",
      "caption a young boy sitting in front of a computer screen\n",
      "Evaluated 752/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.98113250732422\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 753/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.98667335510254\n",
      "caption a girl with headphones on and a boy with headphones on\n",
      "Evaluated 754/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.865394592285156\n",
      "caption a newspaper article about climate change and security\n",
      "Evaluated 755/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  35.983970642089844\n",
      "caption a man wearing headphones in front of a sign that says kids react to climate change\n",
      "Evaluated 756/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.501453399658203\n",
      "caption a young boy sitting in front of a laptop computer\n",
      "Evaluated 757/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.946247100830078\n",
      "caption a young boy with headphones and a laptop\n",
      "Evaluated 758/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.088741302490234\n",
      "caption a young boy sitting in front of a laptop\n",
      "Evaluated 759/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.427730560302734\n",
      "caption a man wearing headphones in front of a computer screen\n",
      "Evaluated 760/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.600502014160156\n",
      "caption a girl with headphones on and a boy with headphones on\n",
      "Evaluated 761/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.91554832458496\n",
      "caption a young girl with headphones and a green background\n",
      "Evaluated 762/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.93553924560547\n",
      "caption a girl and a boy sitting at a table with a laptop\n",
      "Evaluated 763/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.517704010009766\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 764/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.67026710510254\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 765/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.306467056274414\n",
      "caption a young girl with headphones on talking to a man\n",
      "Evaluated 766/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.213102340698242\n",
      "caption a young boy with headphones and a laptop\n",
      "Evaluated 767/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.00171661376953\n",
      "caption a young girl sitting at a desk with headphones on\n",
      "Evaluated 768/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.48874855041504\n",
      "caption a boy sitting in front of a computer with headphones on\n",
      "Evaluated 769/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.924488067626953\n",
      "caption a young boy sitting in front of a laptop computer\n",
      "Evaluated 770/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.704973220825195\n",
      "caption a young girl with headphones and a laptop\n",
      "Evaluated 771/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.088790893554688\n",
      "caption a young boy sitting at a table with a microphone\n",
      "Evaluated 772/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.29645347595215\n",
      "caption a picture of a young boy with headphones on\n",
      "Evaluated 773/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.608320236206055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a boy sitting at a desk with headphones on\n",
      "Evaluated 774/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.25555419921875\n",
      "caption a young boy sitting at a desk with headphones on\n",
      "Evaluated 775/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.967031478881836\n",
      "caption a girl with headphones on and a boy with headphones on\n",
      "Evaluated 776/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.57790756225586\n",
      "caption a young boy sitting in front of a green screen\n",
      "Evaluated 777/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.791379928588867\n",
      "caption a girl with headphones on and a boy with headphones on\n",
      "Evaluated 778/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.509450912475586\n",
      "caption a girl is talking to a man on a video chat\n",
      "Evaluated 779/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.772741317749023\n",
      "caption a young boy sitting in front of a laptop\n",
      "Evaluated 780/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.325334548950195\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 781/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.383319854736328\n",
      "caption a girl with headphones on and a man with headphones on\n",
      "Evaluated 782/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.01339340209961\n",
      "caption a young girl sitting in front of a computer screen\n",
      "Evaluated 783/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.453086853027344\n",
      "caption a couple of kids sitting in front of a laptop\n",
      "Evaluated 784/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.29145050048828\n",
      "caption a young girl sitting in front of a laptop with headphones on\n",
      "Evaluated 785/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.460412979125977\n",
      "caption a man sitting in a chair with headphones on\n",
      "Evaluated 786/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.07373046875\n",
      "caption a man and a woman sitting at a table in front of a green wall\n",
      "Evaluated 787/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.089563369750977\n",
      "caption a young girl sitting in front of a laptop with headphones on\n",
      "Evaluated 788/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.968280792236328\n",
      "caption a girl sitting at a table making a fist\n",
      "Evaluated 789/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.986082077026367\n",
      "caption a picture of a young boy with headphones on\n",
      "Evaluated 790/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.33814239501953\n",
      "caption a young girl sitting in front of a laptop with headphones on\n",
      "Evaluated 791/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.629175186157227\n",
      "caption a young girl sitting in front of a green wall\n",
      "Evaluated 792/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.424522399902344\n",
      "caption a young girl sitting in front of a computer screen\n",
      "Evaluated 793/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.631715774536133\n",
      "caption a young boy with headphones and a laptop\n",
      "Evaluated 794/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.895790100097656\n",
      "caption a young boy sitting in front of a laptop\n",
      "Evaluated 795/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  36.310733795166016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a young boy wearing headphones on a laptop computer\n",
      "Evaluated 796/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.103973388671875\n",
      "caption a person holding a cell phone in their hand\n",
      "Evaluated 797/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.26758575439453\n",
      "caption a picture of a computer with the word mac on it\n",
      "Evaluated 798/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.142210006713867\n",
      "caption a person holding an iphone on a table\n",
      "Evaluated 799/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.048110961914062\n",
      "caption a cell phone sitting on top of a table\n",
      "Evaluated 800/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.693140029907227\n",
      "caption a person holding an iphone up to their face\n",
      "Evaluated 801/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.55430030822754\n",
      "caption a person holding a cell phone in their hand\n",
      "Evaluated 802/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.068227767944336\n",
      "caption a cell phone sitting on top of a table\n",
      "Evaluated 803/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.06413459777832\n",
      "caption a person holding a cell phone in their hand\n",
      "Evaluated 804/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.276208877563477\n",
      "caption a computer screen with the words 9 to 5 mac com on it\n",
      "Evaluated 805/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.782424926757812\n",
      "caption a person holding up a cell phone on a table\n",
      "Evaluated 806/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.963830947875977\n",
      "caption a person holding a cell phone in their hand\n",
      "Evaluated 807/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.681121826171875\n",
      "caption a black iphone sitting on top of a wooden table\n",
      "Evaluated 808/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.383594512939453\n",
      "caption a person holding a cell phone in their hand\n",
      "Evaluated 809/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.489809036254883\n",
      "caption a person holding a cell phone up to their face\n",
      "Evaluated 810/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.4609432220459\n",
      "caption a person holding a cell phone with a keyboard on it\n",
      "Evaluated 811/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.560895919799805\n",
      "caption a person holding a cell phone up to their face\n",
      "Evaluated 812/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.962039947509766\n",
      "caption a person holding an iphone in their hand\n",
      "Evaluated 813/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.170215606689453\n",
      "caption a person holding up a cell phone in front of a table\n",
      "Evaluated 814/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.84319496154785\n",
      "caption a person holding up an iphone on a table\n",
      "Evaluated 815/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.039045333862305\n",
      "caption a person holding a cell phone in their hand\n",
      "Evaluated 816/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.636838912963867\n",
      "caption a person holding a cell phone in their hands\n",
      "Evaluated 817/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:05<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.90389633178711\n",
      "caption a screen shot of a soccer game\n",
      "Evaluated 818/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.632566452026367\n",
      "caption a soccer game being played on a computer\n",
      "Evaluated 819/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.0966854095459\n",
      "caption a group of people playing soccer on a field\n",
      "Evaluated 820/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.946325302124023\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 821/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.491241455078125\n",
      "caption the word godiva on a black background\n",
      "Evaluated 822/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.528718948364258\n",
      "caption a group of people playing soccer on a field\n",
      "Evaluated 823/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.223390579223633\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 824/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.59735107421875\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 825/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.876815795898438\n",
      "caption an image of a soccer ball on a field\n",
      "Evaluated 826/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.949716567993164\n",
      "caption a man is playing soccer on a field\n",
      "Evaluated 827/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.102825164794922\n",
      "caption a screen shot of a video game with a soccer player\n",
      "Evaluated 828/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.085182189941406\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 829/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.26508140563965\n",
      "caption a group of people playing soccer on a field\n",
      "Evaluated 830/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.225234985351562\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 831/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.678577423095703\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 832/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.430606842041016\n",
      "caption a group of people playing soccer on a field\n",
      "Evaluated 833/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.88313865661621\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 834/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.294816970825195\n",
      "caption a man playing soccer in a video game\n",
      "Evaluated 835/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.453609466552734\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 836/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.64274024963379\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 837/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.476224899291992\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 838/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:05<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.560935974121094\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 839/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  15.2731294631958\n",
      "caption the word godiva on a black background\n",
      "Evaluated 840/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.445283889770508\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 841/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.429107666015625\n",
      "caption a man in a blue uniform is playing soccer\n",
      "Evaluated 842/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.56437873840332\n",
      "caption a group of people playing soccer on a field\n",
      "Evaluated 843/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.314245223999023\n",
      "caption a man in a white uniform is kicking a soccer ball\n",
      "Evaluated 844/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.378807067871094\n",
      "caption a man playing soccer in a video game\n",
      "Evaluated 845/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.887929916381836\n",
      "caption a red button with the word gizvida on it\n",
      "Evaluated 846/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.255767822265625\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 847/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.087610244750977\n",
      "caption a man in a red shirt is about to kick a soccer ball\n",
      "Evaluated 848/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.69517707824707\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 849/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.270063400268555\n",
      "caption a man in a soccer uniform standing on a field\n",
      "Evaluated 850/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.74911880493164\n",
      "caption a man holding a yellow card in front of a crowd\n",
      "Evaluated 851/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:04<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.553359985351562\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 852/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.3485107421875\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 853/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.807815551757812\n",
      "caption a soccer player laying on the ground\n",
      "Evaluated 854/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.425905227661133\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 855/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.225887298583984\n",
      "caption a screen shot of a soccer game\n",
      "Evaluated 856/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.806032180786133\n",
      "caption a red button with a white play button on it\n",
      "Evaluated 857/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.362716674804688\n",
      "caption a group of people playing soccer on a field\n",
      "Evaluated 858/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.83039093017578\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 859/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.42739486694336\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 860/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.64180564880371\n",
      "caption a picture of a military emblem on a computer screen\n",
      "Evaluated 861/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.2757625579834\n",
      "caption a group of people are playing a soccer game\n",
      "Evaluated 862/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.53499412536621\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 863/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.043352127075195\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 864/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.6898193359375\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 865/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.61132049560547\n",
      "caption a soccer player is about to kick the ball\n",
      "Evaluated 866/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.230587005615234\n",
      "caption a street sign in the dark with a red light\n",
      "Evaluated 867/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.446664810180664\n",
      "caption a close up of an ea sports logo\n",
      "Evaluated 868/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.718935012817383\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 869/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.314119338989258\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 870/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.264007568359375\n",
      "caption a screen shot of a soccer game\n",
      "Evaluated 871/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.750925064086914\n",
      "caption a screen shot of a video game with soccer players\n",
      "Evaluated 872/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.085712432861328\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 873/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.355384826660156\n",
      "caption an image of two soccer balls on a field\n",
      "Evaluated 874/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a soccer game is being played on a large field\n",
      "Evaluated 875/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.924415588378906\n",
      "caption a screen shot of a soccer game\n",
      "Evaluated 876/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.158035278320312\n",
      "caption a soccer game is being played in a stadium\n",
      "Evaluated 877/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.28481101989746\n",
      "caption a group of men standing on a soccer field\n",
      "Evaluated 878/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.150711059570312\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 879/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.244434356689453\n",
      "caption a group of men standing on a soccer field\n",
      "Evaluated 880/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.337039947509766\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 881/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a group of people playing soccer on a field\n",
      "Evaluated 882/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.760595321655273\n",
      "caption a man is playing soccer on a field\n",
      "Evaluated 883/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.66034698486328\n",
      "caption a screenshot of a soccer game being played\n",
      "Evaluated 884/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.846534729003906\n",
      "caption two soccer players standing next to each other\n",
      "Evaluated 885/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.046918869018555\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 886/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.159849166870117\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 887/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.67276382446289\n",
      "caption a group of people playing soccer on a field\n",
      "Evaluated 888/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.81606101989746\n",
      "caption a screen shot of a soccer player with his hands in the air\n",
      "Evaluated 889/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:04<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.55191421508789\n",
      "caption a screen shot of a soccer game being played\n",
      "Evaluated 890/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  14.522579193115234\n",
      "caption a person is upside down in front of a fire hydrant\n",
      "Evaluated 891/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.82018280029297\n",
      "caption a close up of a camera attached to a drone\n",
      "Evaluated 892/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.883167266845703\n",
      "caption a drone flying over a hill with a camera attached to it\n",
      "Evaluated 893/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.087282180786133\n",
      "caption a person holding a tablet with a racing game on it\n",
      "Evaluated 894/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption two men in yellow jackets standing in the snow\n",
      "Evaluated 895/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.939552307128906\n",
      "caption a man is holding a bicycle up in the air\n",
      "Evaluated 896/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.069242477416992\n",
      "caption a man holding a surfboard on top of a mountain\n",
      "Evaluated 897/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.757442474365234\n",
      "caption a rally car driving on a dirt road\n",
      "Evaluated 898/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.258399963378906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a white and black drone flying over a snowy landscape\n",
      "Evaluated 899/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.012754440307617\n",
      "caption a car driving on a dirt road with smoke coming out of it\n",
      "Evaluated 900/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.3654842376709\n",
      "caption two cars on a race track in front of a crowd\n",
      "Evaluated 901/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.829999923706055\n",
      "caption a car driving down a snow covered road\n",
      "Evaluated 902/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.691905975341797\n",
      "caption a large group of vehicles parked on a dirt road\n",
      "Evaluated 903/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.688722610473633\n",
      "caption a man standing in front of a crowd of people\n",
      "Evaluated 904/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.420080184936523\n",
      "caption a large group of people standing on top of rocks\n",
      "Evaluated 905/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.391868591308594\n",
      "caption a close up of a person holding a screwdriver\n",
      "Evaluated 906/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.000286102294922\n",
      "caption a rally car driving down a dirt road\n",
      "Evaluated 907/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.380748748779297\n",
      "caption a person using a tablet computer in a dark room\n",
      "Evaluated 908/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.20810890197754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a group of people standing on top of a mountain\n",
      "Evaluated 909/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.684722900390625\n",
      "caption a car driving on the side of a road\n",
      "Evaluated 910/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.803112030029297\n",
      "caption a car driving on a dirt road with a lot of dust\n",
      "Evaluated 911/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.45676612854004\n",
      "caption a man with a hat and a laptop in the desert\n",
      "Evaluated 912/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.693092346191406\n",
      "caption a man in a green vest holding a white box\n",
      "Evaluated 913/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.159698486328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a close up of a drone flying over a field\n",
      "Evaluated 914/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.06458282470703\n",
      "caption a couple of cars racing down a race track\n",
      "Evaluated 915/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.182287216186523\n",
      "caption a close up of a drone flying in the air\n",
      "Evaluated 916/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.648618698120117\n",
      "caption a rally car driving down a muddy road\n",
      "Evaluated 917/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.583602905273438\n",
      "caption a group of people standing on top of a mountain\n",
      "Evaluated 918/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.7714900970459\n",
      "caption a car driving through a tunnel at night\n",
      "Evaluated 919/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.707704544067383\n",
      "caption a rally car driving down a country road\n",
      "Evaluated 920/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.227859497070312\n",
      "caption a man standing in front of a car at night\n",
      "Evaluated 921/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.625385284423828\n",
      "caption a snow covered road with a car going down it\n",
      "Evaluated 922/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.410717010498047\n",
      "caption a group of people walking through a corn field\n",
      "Evaluated 923/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.7366886138916\n",
      "caption a rally car driving down a dirt road next to a large rock\n",
      "Evaluated 924/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.024089813232422\n",
      "caption a car driving down a road near a hill\n",
      "Evaluated 925/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.940099716186523\n",
      "caption a woman sitting in the passenger seat of a car\n",
      "Evaluated 926/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.73534393310547\n",
      "caption a helicopter flying over a tree with the sun in the background\n",
      "Evaluated 927/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.986812591552734\n",
      "caption a rally car driving on a dirt road\n",
      "Evaluated 928/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.382190704345703\n",
      "caption a car driving on a dirt road in the woods\n",
      "Evaluated 929/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a close up of a person putting something in a case\n",
      "Evaluated 930/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.95924949645996\n",
      "caption a car is driving down a road in the woods\n",
      "Evaluated 931/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a man in a yellow vest standing in front of a building\n",
      "Evaluated 932/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.940258026123047\n",
      "caption an image of a black screen with text on it\n",
      "Evaluated 933/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.06080436706543\n",
      "caption a man sitting in the grass working on a drone\n",
      "Evaluated 934/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  35.50600051879883\n",
      "caption a rally car driving through the snow\n",
      "Evaluated 935/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.328248977661133\n",
      "caption a man sitting in the grass next to a case\n",
      "Evaluated 936/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.501842498779297\n",
      "caption a group of people standing on top of a hill\n",
      "Evaluated 937/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  14.768468856811523\n",
      "caption a red fire hydrant in the grass next to a blue car\n",
      "Evaluated 938/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.52302360534668\n",
      "caption a rally car driving on a dirt road\n",
      "Evaluated 939/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.8028450012207\n",
      "caption a person holding a tablet in a field\n",
      "Evaluated 940/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.8219108581543\n",
      "caption a yellow helicopter sitting on top of a grassy hill\n",
      "Evaluated 941/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.28986167907715\n",
      "caption a close up of a person putting something in a case\n",
      "Evaluated 942/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.488693237304688\n",
      "caption a man in a green vest holding something in his hand\n",
      "Evaluated 943/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.435882568359375\n",
      "caption a couple of cars racing down a race track\n",
      "Evaluated 944/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.015037536621094\n",
      "caption a close up of a camera attached to a drone\n",
      "Evaluated 945/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.73926544189453\n",
      "caption a person holding a tablet with a racing game on it\n",
      "Evaluated 946/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.75527572631836\n",
      "caption a man in a green jacket holding a laptop\n",
      "Evaluated 947/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a woman driving a car with her hand on the steering wheel\n",
      "Evaluated 948/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.516624450683594\n",
      "caption a woman standing next to a table with boots on it\n",
      "Evaluated 949/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.136457443237305\n",
      "caption a rally car driving on a dirt road\n",
      "Evaluated 950/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.445941925048828\n",
      "caption the evolution of aerial technology in the world rally championship\n",
      "Evaluated 951/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.023773193359375\n",
      "caption a man in a green shirt flying a kite in a field\n",
      "Evaluated 952/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.67597007751465\n",
      "caption a car is driving down a winding mountain road\n",
      "Evaluated 953/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.427894592285156\n",
      "caption a rally car driving on a snow covered road\n",
      "Evaluated 954/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.816499710083008\n",
      "caption a car driving down a road with a drone flying above it\n",
      "Evaluated 955/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.600149154663086\n",
      "caption a person holding a tablet with a picture on it\n",
      "Evaluated 956/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.66598892211914\n",
      "caption a man standing next to a body of water\n",
      "Evaluated 957/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.28143310546875\n",
      "caption a couple of people standing next to each other in a field\n",
      "Evaluated 958/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.375011444091797\n",
      "caption a man working on a snowmobile in the snow\n",
      "Evaluated 959/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.822423934936523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a man wearing a baseball cap and holding a laptop\n",
      "Evaluated 960/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.545618057250977\n",
      "caption a couple of people standing next to each other\n",
      "Evaluated 961/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.636653900146484\n",
      "caption a man holding a cell phone up to his face\n",
      "Evaluated 962/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.641721725463867\n",
      "caption a group of people watching a car go down a hill\n",
      "Evaluated 963/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  35.50600051879883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a rally car driving through the snow\n",
      "Evaluated 964/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.508901596069336\n",
      "caption a camera attached to a drone flying through the air\n",
      "Evaluated 965/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.495859146118164\n",
      "caption an aerial view of a car driving down a road next to a body of water\n",
      "Evaluated 966/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.871875762939453\n",
      "caption a rally car driving down a dirt road\n",
      "Evaluated 967/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.796768188476562\n",
      "caption a close up of a small device on a table\n",
      "Evaluated 968/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.808944702148438\n",
      "caption a car is going down a hill in the snow\n",
      "Evaluated 969/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.29518699645996\n",
      "caption a rally car driving down a mountain road\n",
      "Evaluated 970/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.85668182373047\n",
      "caption two men standing next to each other on top of a hill\n",
      "Evaluated 971/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.17245101928711\n",
      "caption a group of people standing on top of some rocks\n",
      "Evaluated 972/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.18484115600586\n",
      "caption a drone flying in the air over a field\n",
      "Evaluated 973/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.98771858215332\n",
      "caption a group of people standing in a grassy field\n",
      "Evaluated 974/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.129791259765625\n",
      "caption a man throwing a frisbee in the air\n",
      "Evaluated 975/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.325742721557617\n",
      "caption a blurry picture of a group of people on a hill\n",
      "Evaluated 976/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.90806007385254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a close up of a person putting something in a bag\n",
      "Evaluated 977/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.787622451782227\n",
      "caption a group of people taking pictures with their cell phones\n",
      "Evaluated 978/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.43805694580078\n",
      "caption an aerial view of a drone flying in the snow\n",
      "Evaluated 979/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.150896072387695\n",
      "caption a man sitting in the grass fixing a camera\n",
      "Evaluated 980/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.66511344909668\n",
      "caption a person flying a kite on a cloudy day\n",
      "Evaluated 981/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.516624450683594\n",
      "caption a woman standing next to a table with boots on it\n",
      "Evaluated 982/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.941186904907227\n",
      "caption a person flying a kite in a field\n",
      "Evaluated 983/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.553054809570312\n",
      "caption a group of people standing on top of some rocks\n",
      "Evaluated 984/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.270965576171875\n",
      "caption a person riding a motorcycle on a dirt road\n",
      "Evaluated 985/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.97360610961914\n",
      "caption a group of people standing on top of some rocks\n",
      "Evaluated 986/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.01004409790039\n",
      "caption a car driving on a snow covered road\n",
      "Evaluated 987/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.0384578704834\n",
      "caption a group of people standing on top of a hill\n",
      "Evaluated 988/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.851415634155273\n",
      "caption a man sitting in the grass looking at a drone\n",
      "Evaluated 989/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.502708435058594\n",
      "caption a drone flying over a snow covered slope\n",
      "Evaluated 990/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.0841178894043\n",
      "caption a man in a green vest holding a tablet computer\n",
      "Evaluated 991/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.427894592285156\n",
      "caption a rally car driving on a snow covered road\n",
      "Evaluated 992/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.629796981811523\n",
      "caption a blurry picture of a drone flying in the air\n",
      "Evaluated 993/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.34941864013672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a close up of a person holding a remote control\n",
      "Evaluated 994/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.147220611572266\n",
      "caption a group of men standing next to each other\n",
      "Evaluated 995/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.137100219726562\n",
      "caption a close up of a person holding a camera in the grass\n",
      "Evaluated 996/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.50457763671875\n",
      "caption a car driving on a dirt road in the mountains\n",
      "Evaluated 997/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.594945907592773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a car driving on a dirt road with a lot of dust\n",
      "Evaluated 998/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.501842498779297\n",
      "caption a group of people standing on top of a hill\n",
      "Evaluated 999/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  14.748165130615234\n",
      "caption a dog laying in the grass in front of people\n",
      "Evaluated 1000/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.64362144470215\n",
      "caption a man standing next to a body of water\n",
      "Evaluated 1001/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.193302154541016\n",
      "caption a close up of a camera mounted on a bike\n",
      "Evaluated 1002/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.11225509643555\n",
      "caption an aerial view of a car driving down a road\n",
      "Evaluated 1003/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a man working on a snowmobile in the snow\n",
      "Evaluated 1004/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.373977661132812\n",
      "caption a person riding a motorcycle on a dirt road\n",
      "Evaluated 1005/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.791946411132812\n",
      "caption a small car driving on a road next to a building\n",
      "Evaluated 1006/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.411376953125\n",
      "caption a car driving around a circular track in front of a crowd\n",
      "Evaluated 1007/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a close up of a person holding a device\n",
      "Evaluated 1008/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.693439483642578\n",
      "caption a snow covered road with a car going down it\n",
      "Evaluated 1009/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.16925811767578\n",
      "caption a man and a woman standing next to each other\n",
      "Evaluated 1010/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.136287689208984\n",
      "caption a car driving down a curvy mountain road\n",
      "Evaluated 1011/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.123064041137695\n",
      "caption a close up of a person working on something\n",
      "Evaluated 1012/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.21619415283203\n",
      "caption a car driving on a dirt road under a cloudy sky\n",
      "Evaluated 1013/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.113914489746094\n",
      "caption an aerial view of a drone flying in the snow\n",
      "Evaluated 1014/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.276769638061523\n",
      "caption a group of people walking through a field\n",
      "Evaluated 1015/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.327518463134766\n",
      "caption a car driving down a street at night\n",
      "Evaluated 1016/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.605791091918945\n",
      "caption a close up of the tire of a truck\n",
      "Evaluated 1017/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.595983505249023\n",
      "caption a car driving on a dirt road in the woods\n",
      "Evaluated 1018/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.78873634338379\n",
      "caption a person flying through the air on skis\n",
      "Evaluated 1019/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.697059631347656\n",
      "caption a small car driving on a dirt road\n",
      "Evaluated 1020/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.90806007385254\n",
      "caption a close up of a person putting something in a bag\n",
      "Evaluated 1021/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  15.756778717041016\n",
      "caption a man driving a car with a helmet on\n",
      "Evaluated 1022/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.2226676940918\n",
      "caption a rally car driving on a dirt road\n",
      "Evaluated 1023/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.383302688598633\n",
      "caption a person holding a tablet computer in their hand\n",
      "Evaluated 1024/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.9377384185791\n",
      "caption a dirt road surrounded by rocks and grass\n",
      "Evaluated 1025/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.594945907592773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a car driving on a dirt road with a lot of dust\n",
      "Evaluated 1026/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.016216278076172\n",
      "caption a helicopter flying over a hill with people on it\n",
      "Evaluated 1027/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.75461196899414\n",
      "caption a close up of a person fixing something in the grass\n",
      "Evaluated 1028/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.854219436645508\n",
      "caption a close up of a person holding a device\n",
      "Evaluated 1029/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.084280014038086\n",
      "caption a man holding a cell phone up to his ear\n",
      "Evaluated 1030/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.757442474365234\n",
      "caption a rally car driving on a dirt road\n",
      "Evaluated 1031/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.759693145751953\n",
      "caption a dirt road with a car driving on it\n",
      "Evaluated 1032/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.47838020324707\n",
      "caption a group of people watching a truck go by\n",
      "Evaluated 1033/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.259033203125\n",
      "caption a man in a grey jacket standing in a room\n",
      "Evaluated 1034/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.11225509643555\n",
      "caption an aerial view of a car driving down a road\n",
      "Evaluated 1035/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.839157104492188\n",
      "caption a rally car driving down a dirt road\n",
      "Evaluated 1036/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.95624542236328\n",
      "caption a person standing in the snow next to a dog\n",
      "Evaluated 1037/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.97237205505371\n",
      "caption a black and brown puppy laying on a pink towel\n",
      "Evaluated 1038/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.868083953857422\n",
      "caption a bird flying through the air in the dark\n",
      "Evaluated 1039/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.965002059936523\n",
      "caption a person petting a black and brown puppy\n",
      "Evaluated 1040/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.770179748535156\n",
      "caption a group of people standing in a kitchen\n",
      "Evaluated 1041/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.655290603637695\n",
      "caption a person standing in the snow with a dog\n",
      "Evaluated 1042/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.44746971130371\n",
      "caption a group of people standing in the snow next to a fence\n",
      "Evaluated 1043/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.172901153564453\n",
      "caption a man is massaging another man's head\n",
      "Evaluated 1044/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.3446044921875\n",
      "caption a person petting a black and brown puppy\n",
      "Evaluated 1045/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.869632720947266\n",
      "caption a little girl kissing a black dog on the head\n",
      "Evaluated 1046/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.8017578125\n",
      "caption a person standing next to some cows in the snow\n",
      "Evaluated 1047/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.18297576904297\n",
      "caption a couple of kids standing next to some cows\n",
      "Evaluated 1048/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.716875076293945\n",
      "caption a person petting a black and brown puppy\n",
      "Evaluated 1049/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.29099464416504\n",
      "caption a group of people standing in front of a barn\n",
      "Evaluated 1050/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.11042594909668\n",
      "caption a person petting a small black and brown dog\n",
      "Evaluated 1051/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.936811447143555\n",
      "caption two people and a dog playing in the snow\n",
      "Evaluated 1052/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.621200561523438\n",
      "caption a woman in a park wearing a winter coat\n",
      "Evaluated 1053/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.00015640258789\n",
      "caption a young girl with her eyes closed in the snow\n",
      "Evaluated 1054/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.77894401550293\n",
      "caption a little boy hugging a dog on a bed\n",
      "Evaluated 1055/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.9234561920166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a group of people standing in a kitchen\n",
      "Evaluated 1056/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.173824310302734\n",
      "caption a couple of kids standing next to some cows\n",
      "Evaluated 1057/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.910146713256836\n",
      "caption a person petting a black and brown puppy\n",
      "Evaluated 1058/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.97237205505371\n",
      "caption a black and brown puppy laying on a pink towel\n",
      "Evaluated 1059/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.73160171508789\n",
      "caption a woman playing with a dog in the snow\n",
      "Evaluated 1060/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.04560661315918\n",
      "caption a couple of kids playing with dogs on a couch\n",
      "Evaluated 1061/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.716875076293945\n",
      "caption a person petting a black and brown puppy\n",
      "Evaluated 1062/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.22355079650879\n",
      "caption a woman feeding two llamas at a zoo\n",
      "Evaluated 1063/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.983705520629883\n",
      "caption a little girl petting a black dog\n",
      "Evaluated 1064/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.28842544555664\n",
      "caption a person petting a small black and brown puppy\n",
      "Evaluated 1065/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.185840606689453\n",
      "caption three people standing around a table in a kitchen\n",
      "Evaluated 1066/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.566299438476562\n",
      "caption a black and brown puppy laying on a towel\n",
      "Evaluated 1067/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.120328903198242\n",
      "caption a woman in a coat standing in front of a body of water\n",
      "Evaluated 1068/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.775007247924805\n",
      "caption a group of people and a dog playing in the snow\n",
      "Evaluated 1069/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.854183197021484\n",
      "caption a group of people standing outside of a red house in the snow\n",
      "Evaluated 1070/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.70123863220215\n",
      "caption a woman walking a dog in the snow\n",
      "Evaluated 1071/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.903932571411133\n",
      "caption a black and brown dog laying on a pink blanket\n",
      "Evaluated 1072/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.876516342163086\n",
      "caption a couple of people and a dog in the snow\n",
      "Evaluated 1073/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.066293716430664\n",
      "caption a person bending down to pick up a snowboard\n",
      "Evaluated 1074/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.09945297241211\n",
      "caption a woman reaching up to a cat tree\n",
      "Evaluated 1075/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.185840606689453\n",
      "caption three people standing around a table in a kitchen\n",
      "Evaluated 1076/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.22355079650879\n",
      "caption a woman feeding two llamas at a zoo\n",
      "Evaluated 1077/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.601606369018555\n",
      "caption a young boy laying on a bed with a dog\n",
      "Evaluated 1078/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.666410446166992\n",
      "caption a woman in a coat standing in the snow\n",
      "Evaluated 1079/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.66123390197754\n",
      "caption a group of people looking at a dog on a table\n",
      "Evaluated 1080/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.597593307495117\n",
      "caption three people standing around a table in a kitchen\n",
      "Evaluated 1081/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.341453552246094\n",
      "caption a person petting a small black and brown puppy\n",
      "Evaluated 1082/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.80817985534668\n",
      "caption a gray and white cat laying on a scratching post\n",
      "Evaluated 1083/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.23575210571289\n",
      "caption a dog running in the snow with a frisbee\n",
      "Evaluated 1084/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.987760543823242\n",
      "caption a group of people walking in the snow in front of a house\n",
      "Evaluated 1085/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.86808204650879\n",
      "caption a bird flying through the air in the dark\n",
      "Evaluated 1086/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.908414840698242\n",
      "caption a couple of kids and a dog on a bed\n",
      "Evaluated 1087/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.29323959350586\n",
      "caption a man and a woman in a kitchen looking at a dog\n",
      "Evaluated 1088/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.545795440673828\n",
      "caption a young girl standing in the snow in front of a red house\n",
      "Evaluated 1089/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.1978759765625\n",
      "caption a man in a blue shirt looking at a computer screen\n",
      "Evaluated 1090/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.616775512695312\n",
      "caption three children playing with a dog in a living room\n",
      "Evaluated 1091/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.46711540222168\n",
      "caption a woman petting a small black dog on a table\n",
      "Evaluated 1092/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.95787811279297\n",
      "caption a woman in a coat standing in the snow\n",
      "Evaluated 1093/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.25099563598633\n",
      "caption a person petting a cat on a scratching post\n",
      "Evaluated 1094/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.7512264251709\n",
      "caption three people standing around a table in a kitchen\n",
      "Evaluated 1095/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.462343215942383\n",
      "caption a woman and a little girl standing next to a fence in the snow\n",
      "Evaluated 1096/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.307010650634766\n",
      "caption a young boy laying on a couch with a dog\n",
      "Evaluated 1097/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.54754638671875\n",
      "caption two people playing in the snow with a dog\n",
      "Evaluated 1098/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.207998275756836\n",
      "caption a child is playing in the snow with a frisbee\n",
      "Evaluated 1099/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.621065139770508\n",
      "caption a young girl standing in the snow in front of a red house\n",
      "Evaluated 1100/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.58349609375\n",
      "caption a little boy wearing a hat in the snow\n",
      "Evaluated 1101/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.839847564697266\n",
      "caption a woman and two children playing in the snow\n",
      "Evaluated 1102/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.55278968811035\n",
      "caption a truck is parked on a rocky hillside\n",
      "Evaluated 1103/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.67400550842285\n",
      "caption two men standing next to each other on a dirt road\n",
      "Evaluated 1104/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.517127990722656\n",
      "caption a close up of the underside of a vehicle\n",
      "Evaluated 1105/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.872581481933594\n",
      "caption a view of the underside of a vehicle\n",
      "Evaluated 1106/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.38210678100586\n",
      "caption a close up of the engine of a car\n",
      "Evaluated 1107/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.872238159179688\n",
      "caption the side of a truck with stickers on it\n",
      "Evaluated 1108/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.2399845123291\n",
      "caption the back of a truck with a lot of stuff in it\n",
      "Evaluated 1109/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.893415451049805\n",
      "caption a jeep driving down a rocky mountain road\n",
      "Evaluated 1110/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.899066925048828\n",
      "caption two men standing next to a jeep on a dirt road\n",
      "Evaluated 1111/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.959514617919922\n",
      "caption the engine compartment of a vehicle with lots of wires\n",
      "Evaluated 1112/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.75721549987793\n",
      "caption a cat sitting on the hood of a car\n",
      "Evaluated 1113/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.60599708557129\n",
      "caption a close up of the engine of a car\n",
      "Evaluated 1114/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.20608901977539\n",
      "caption a close up of the front grill of a truck\n",
      "Evaluated 1115/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.49085807800293\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1116/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.952945709228516\n",
      "caption two men standing in front of a truck\n",
      "Evaluated 1117/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.301403045654297\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1118/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.975250244140625\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1119/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.60039710998535\n",
      "caption a close up of a tire on a truck\n",
      "Evaluated 1120/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.249242782592773\n",
      "caption a man pointing to the hood of a truck\n",
      "Evaluated 1121/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.84404182434082\n",
      "caption a close up of a white object on a white background\n",
      "Evaluated 1122/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.733060836791992\n",
      "caption a close up of the underside of a vehicle\n",
      "Evaluated 1123/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.155885696411133\n",
      "caption a close up of the front end of a truck\n",
      "Evaluated 1124/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.22652244567871\n",
      "caption two men standing next to each other in front of a truck\n",
      "Evaluated 1125/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.12690544128418\n",
      "caption two men are standing in front of a truck\n",
      "Evaluated 1126/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.58574676513672\n",
      "caption a close up of the engine of a truck\n",
      "Evaluated 1127/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.377899169921875\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1128/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.48516845703125\n",
      "caption two men standing next to each other in front of a truck\n",
      "Evaluated 1129/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.312740325927734\n",
      "caption a picture of a car with a big engine\n",
      "Evaluated 1130/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.214746475219727\n",
      "caption a close up of a bike with a clamp on it\n",
      "Evaluated 1131/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.58256721496582\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1132/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.614627838134766\n",
      "caption a close up of the engine of a car\n",
      "Evaluated 1133/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.34362030029297\n",
      "caption two men shaking hands in front of a truck\n",
      "Evaluated 1134/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.67438507080078\n",
      "caption two men are standing in front of a jeep\n",
      "Evaluated 1135/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.4639778137207\n",
      "caption a close up of a grill on a car\n",
      "Evaluated 1136/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.829471588134766\n",
      "caption the engine compartment of a pickup truck\n",
      "Evaluated 1137/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.01164245605469\n",
      "caption a close up of the undercarriage of a vehicle\n",
      "Evaluated 1138/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.208908081054688\n",
      "caption a close up view of a metal structure\n",
      "Evaluated 1139/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.255098342895508\n",
      "caption a man putting something on the hood of a car\n",
      "Evaluated 1140/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.61223793029785\n",
      "caption a close up of the underside of a vehicle\n",
      "Evaluated 1141/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.1425724029541\n",
      "caption the back of a truck with a lot of stuff in it\n",
      "Evaluated 1142/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.053611755371094\n",
      "caption a close up view of the underside of a vehicle\n",
      "Evaluated 1143/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.34287452697754\n",
      "caption two men standing next to each other on a dirt road\n",
      "Evaluated 1144/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.65556526184082\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1145/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.236831665039062\n",
      "caption a close up of the rear bumper of a truck\n",
      "Evaluated 1146/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.094404220581055\n",
      "caption a black truck driving down a rocky road\n",
      "Evaluated 1147/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.419435501098633\n",
      "caption a man standing next to a pickup truck\n",
      "Evaluated 1148/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.34529685974121\n",
      "caption a jeep driving down a rocky mountain road\n",
      "Evaluated 1149/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.178678512573242\n",
      "caption a man sitting on top of a vehicle\n",
      "Evaluated 1150/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.706253051757812\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1151/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.55065155029297\n",
      "caption a blue truck driving up a rocky hill\n",
      "Evaluated 1152/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.901243209838867\n",
      "caption a close up of the engine of a car\n",
      "Evaluated 1153/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.20823097229004\n",
      "caption a man sitting in the driver's seat of a truck\n",
      "Evaluated 1154/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.273563385009766\n",
      "caption a close up of the engine of a car\n",
      "Evaluated 1155/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.43214988708496\n",
      "caption a couple of men standing next to a truck\n",
      "Evaluated 1156/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.056089401245117\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1157/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.24635887145996\n",
      "caption a close up of a bunch of different hoses\n",
      "Evaluated 1158/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.60418128967285\n",
      "caption a close up of the engine of a car\n",
      "Evaluated 1159/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.186161041259766\n",
      "caption a close up of a tire on the side of a truck\n",
      "Evaluated 1160/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.579498291015625\n",
      "caption a close up of the engine of a car\n",
      "Evaluated 1161/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.995182037353516\n",
      "caption a close up of the front of a vehicle\n",
      "Evaluated 1162/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.484281539916992\n",
      "caption two men standing next to each other in front of a jeep\n",
      "Evaluated 1163/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.056581497192383\n",
      "caption a close up of the front tire of a truck\n",
      "Evaluated 1164/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.41337013244629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a close up of the front grill of a truck\n",
      "Evaluated 1165/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.17963981628418\n",
      "caption two men standing next to each other in front of a truck\n",
      "Evaluated 1166/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.697134017944336\n",
      "caption two men standing in front of a truck\n",
      "Evaluated 1167/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.968303680419922\n",
      "caption a close up of the engine of a car\n",
      "Evaluated 1168/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.948801040649414\n",
      "caption two men standing next to a jeep on a dirt road\n",
      "Evaluated 1169/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.88167381286621\n",
      "caption a person taking a picture of a car\n",
      "Evaluated 1170/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.30794906616211\n",
      "caption a close up of the underside of a vehicle\n",
      "Evaluated 1171/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.926286697387695\n",
      "caption a person taking a picture of a car\n",
      "Evaluated 1172/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.666744232177734\n",
      "caption two men standing next to each other on a dirt road\n",
      "Evaluated 1173/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.305173873901367\n",
      "caption a black suv driving down a rocky road\n",
      "Evaluated 1174/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.998777389526367\n",
      "caption a bunch of luggage in the back of a truck\n",
      "Evaluated 1175/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.05695915222168\n",
      "caption two men standing in front of a truck\n",
      "Evaluated 1176/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.95403289794922\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1177/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.990144729614258\n",
      "caption two men standing next to each other on the side of a road\n",
      "Evaluated 1178/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.455324172973633\n",
      "caption a close up of a metal grille on a car\n",
      "Evaluated 1179/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.174537658691406\n",
      "caption a black suv driving down a rocky road\n",
      "Evaluated 1180/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.658859252929688\n",
      "caption a man putting a tire in the back of a truck\n",
      "Evaluated 1181/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.01903533935547\n",
      "caption a close up view of the side of a building\n",
      "Evaluated 1182/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.956119537353516\n",
      "caption a steering wheel and dashboard of an old truck\n",
      "Evaluated 1183/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.38733673095703\n",
      "caption a close up of the underside of a vehicle\n",
      "Evaluated 1184/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.416078567504883\n",
      "caption a man in a hat and sunglasses looking under the hood of a car\n",
      "Evaluated 1185/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.625905990600586\n",
      "caption a close up view of the undercarriage of a vehicle\n",
      "Evaluated 1186/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.021116256713867\n",
      "caption the back of a truck with luggage in it\n",
      "Evaluated 1187/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.79764175415039\n",
      "caption a close up of the front grill of a truck\n",
      "Evaluated 1188/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.340713500976562\n",
      "caption a man touching the hood of a car\n",
      "Evaluated 1189/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.821125030517578\n",
      "caption two men standing in front of a truck\n",
      "Evaluated 1190/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.946327209472656\n",
      "caption a close up of the engine of a car\n",
      "Evaluated 1191/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  35.005130767822266\n",
      "caption a close up of a silver and blue truck\n",
      "Evaluated 1192/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.752342224121094\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1193/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.633520126342773\n",
      "caption a close up of the front grill of a truck\n",
      "Evaluated 1194/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.7199821472168\n",
      "caption a blue truck driving through a rocky area\n",
      "Evaluated 1195/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.923446655273438\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1196/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.76601219177246\n",
      "caption a close up of a bunch of metal objects\n",
      "Evaluated 1197/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.804346084594727\n",
      "caption a man sitting in the driver's seat of a truck\n",
      "Evaluated 1198/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.39165687561035\n",
      "caption two men standing in front of a truck\n",
      "Evaluated 1199/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.251232147216797\n",
      "caption a man pointing to the hood of a truck\n",
      "Evaluated 1200/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.7691650390625\n",
      "caption a close up of a bunch of hoses and wires\n",
      "Evaluated 1201/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.372249603271484\n",
      "caption a close up of a warning sign on a winch\n",
      "Evaluated 1202/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.68635368347168\n",
      "caption a close up of a truck tire on a rocky surface\n",
      "Evaluated 1203/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.489351272583008\n",
      "caption a close up of a bunch of metal pipes\n",
      "Evaluated 1204/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.00821304321289\n",
      "caption a man looking under the hood of a car\n",
      "Evaluated 1205/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.054943084716797\n",
      "caption a red and yellow logo on a white background\n",
      "Evaluated 1206/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.592607498168945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a close up of a tire tread\n",
      "Evaluated 1207/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.76324462890625\n",
      "caption a close up of the front of a truck\n",
      "Evaluated 1208/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.220062255859375\n",
      "caption a view of the underside of a vehicle\n",
      "Evaluated 1209/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.27634048461914\n",
      "caption two men standing next to each other on a dirt road\n",
      "Evaluated 1210/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.701969146728516\n",
      "caption two men standing in front of a pickup truck\n",
      "Evaluated 1211/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.639223098754883\n",
      "caption a close up view of a metal structure\n",
      "Evaluated 1212/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.134790420532227\n",
      "caption a truck is parked on the side of a rocky road\n",
      "Evaluated 1213/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.649635314941406\n",
      "caption a bunch of pipes and hoses on a car\n",
      "Evaluated 1214/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.02613067626953\n",
      "caption a close up of a truck on some rocks\n",
      "Evaluated 1215/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.8912353515625\n",
      "caption the back of a truck with a lot of stuff in it\n",
      "Evaluated 1216/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.44301223754883\n",
      "caption a dashboard with gauges and a steering wheel\n",
      "Evaluated 1217/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.108203887939453\n",
      "caption a man standing next to a blue truck\n",
      "Evaluated 1218/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.453353881835938\n",
      "caption a truck is driving down a rocky road\n",
      "Evaluated 1219/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.5804500579834\n",
      "caption a man is reflected in the bumper of a car\n",
      "Evaluated 1220/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.912288665771484\n",
      "caption a close up of a person working on a car\n",
      "Evaluated 1221/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.41598129272461\n",
      "caption a close up of the engine of a car\n",
      "Evaluated 1222/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.73155975341797\n",
      "caption a close up of the front grill of a truck\n",
      "Evaluated 1223/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.51824378967285\n",
      "caption a close up of the front end of a truck\n",
      "Evaluated 1224/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.160438537597656\n",
      "caption two men talking to each other in front of a truck\n",
      "Evaluated 1225/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.02324104309082\n",
      "caption a close up of the front end of a truck\n",
      "Evaluated 1226/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  37.66460037231445\n",
      "caption a close up of a warning sign on a winch\n",
      "Evaluated 1227/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.88056182861328\n",
      "caption the engine of a car is filled with pipes and hoses\n",
      "Evaluated 1228/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.118234634399414\n",
      "caption two men standing in front of a truck\n",
      "Evaluated 1229/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.1256103515625\n",
      "caption a close up of the front grill of a car\n",
      "Evaluated 1230/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.659130096435547\n",
      "caption a close up of a bunch of metal parts\n",
      "Evaluated 1231/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.792810440063477\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1232/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.34824562072754\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1233/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.51557731628418\n",
      "caption a close up of a truck with a sticker on it\n",
      "Evaluated 1234/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.56886100769043\n",
      "caption the engine compartment of a truck is open\n",
      "Evaluated 1235/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.443988800048828\n",
      "caption two men standing in front of a truck\n",
      "Evaluated 1236/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.68568992614746\n",
      "caption a close up of the front grill of a truck\n",
      "Evaluated 1237/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.211027145385742\n",
      "caption a close up of some luggage sitting on the ground\n",
      "Evaluated 1238/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.160526275634766\n",
      "caption two men standing next to a truck on a dirt road\n",
      "Evaluated 1239/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.318042755126953\n",
      "caption a close up of the underside of a vehicle\n",
      "Evaluated 1240/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.879804611206055\n",
      "caption a man and a woman are cooking in a kitchen\n",
      "Evaluated 1241/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.456581115722656\n",
      "caption a man and a woman in a kitchen\n",
      "Evaluated 1242/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.22389030456543\n",
      "caption a white plate with a piece of meat on it\n",
      "Evaluated 1243/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.3092041015625\n",
      "caption a man in a chef hat standing next to a woman\n",
      "Evaluated 1244/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.20782470703125\n",
      "caption a chef cutting a piece of meat on a cutting board\n",
      "Evaluated 1245/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.33661460876465\n",
      "caption a man in a chef hat standing next to a woman\n",
      "Evaluated 1246/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.267724990844727\n",
      "caption a man and a woman in a kitchen\n",
      "Evaluated 1247/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.54317855834961\n",
      "caption a woman standing in front of a stove in a kitchen\n",
      "Evaluated 1248/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.162616729736328\n",
      "caption a woman and a man standing next to each other\n",
      "Evaluated 1249/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.53565216064453\n",
      "caption a chef preparing food on a television screen\n",
      "Evaluated 1250/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.784828186035156\n",
      "caption a man in a chef hat standing next to a woman\n",
      "Evaluated 1251/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.793861389160156\n",
      "caption a close up of a piece of meat on a cutting board\n",
      "Evaluated 1252/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.665855407714844\n",
      "caption a man in a chef hat is standing next to a woman\n",
      "Evaluated 1253/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.379844665527344\n",
      "caption a man and a woman in a kitchen\n",
      "Evaluated 1254/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.885221481323242\n",
      "caption a woman and a man in a kitchen\n",
      "Evaluated 1255/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.31757926940918\n",
      "caption a man in a chef's coat holding a plate with a piece of cake on it\n",
      "Evaluated 1256/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.749217987060547\n",
      "caption a woman and a man in a kitchen\n",
      "Evaluated 1257/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.456581115722656\n",
      "caption a man in a chef hat is talking to a woman\n",
      "Evaluated 1258/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.408733367919922\n",
      "caption a woman and a man in a kitchen\n",
      "Evaluated 1259/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.15593910217285\n",
      "caption onions are cooking in a pan on a stove\n",
      "Evaluated 1260/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.5688533782959\n",
      "caption a man in a chef hat talking to a woman\n",
      "Evaluated 1261/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.131982803344727\n",
      "caption a man and a woman in a kitchen\n",
      "Evaluated 1262/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.97032928466797\n",
      "caption a piece of food in a pan on a red table\n",
      "Evaluated 1263/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.657285690307617\n",
      "caption a person cutting a piece of meat with a knife\n",
      "Evaluated 1264/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.60749053955078\n",
      "caption a man in a chef hat is on the news\n",
      "Evaluated 1265/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.569738388061523\n",
      "caption a man and a woman standing in front of a cake\n",
      "Evaluated 1266/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.00093650817871\n",
      "caption a woman and a man in a kitchen\n",
      "Evaluated 1267/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.512664794921875\n",
      "caption a man in a chef hat standing next to a woman\n",
      "Evaluated 1268/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.44034194946289\n",
      "caption onions are cooking in a pan on a stove\n",
      "Evaluated 1269/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.905920028686523\n",
      "caption a woman and a man in a kitchen\n",
      "Evaluated 1270/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.914854049682617\n",
      "caption a man standing in front of an oven\n",
      "Evaluated 1271/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.11773109436035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a man and a woman in a kitchen\n",
      "Evaluated 1272/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.686737060546875\n",
      "caption a man in a chef's hat standing next to a woman\n",
      "Evaluated 1273/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.22039222717285\n",
      "caption a man in a chef hat and a woman in a yellow shirt\n",
      "Evaluated 1274/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.96941566467285\n",
      "caption a man wearing a chef hat and a woman standing next to him\n",
      "Evaluated 1275/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.078838348388672\n",
      "caption a chef preparing food on a cooking show\n",
      "Evaluated 1276/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.1689510345459\n",
      "caption a close up of a piece of meat on a cutting board\n",
      "Evaluated 1277/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.636817932128906\n",
      "caption a picture of some flowers on a table\n",
      "Evaluated 1278/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.262136459350586\n",
      "caption a man and a woman in a kitchen preparing food\n",
      "Evaluated 1279/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.35610580444336\n",
      "caption a chef and a woman preparing food in a kitchen\n",
      "Evaluated 1280/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.808385848999023\n",
      "caption a chef preparing food on a television screen\n",
      "Evaluated 1281/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.58465003967285\n",
      "caption a woman standing next to a plate of food\n",
      "Evaluated 1282/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.560199737548828\n",
      "caption a chef cutting meat on a cutting board\n",
      "Evaluated 1283/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.219640731811523\n",
      "caption a man and a woman in a kitchen\n",
      "Evaluated 1284/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.039207458496094\n",
      "caption a man in a chef hat standing next to a woman\n",
      "Evaluated 1285/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.538803100585938\n",
      "caption a plate of food sitting on a cutting board\n",
      "Evaluated 1286/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.79746437072754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a chef standing next to a woman in a kitchen\n",
      "Evaluated 1287/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.665027618408203\n",
      "caption a man in a chef hat and a woman in a chef hat\n",
      "Evaluated 1288/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.32152557373047\n",
      "caption a man in a chef hat talking to a woman\n",
      "Evaluated 1289/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.440317153930664\n",
      "caption a man in white gloves holding a piece of meat\n",
      "Evaluated 1290/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.823667526245117\n",
      "caption a man in a chef hat standing next to a woman\n",
      "Evaluated 1291/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.193470001220703\n",
      "caption a person in white gloves holding a piece of meat\n",
      "Evaluated 1292/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.51687240600586\n",
      "caption a computer screen with many different icons on it\n",
      "Evaluated 1293/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.356298446655273\n",
      "caption a computer monitor with a picture of a boat on it\n",
      "Evaluated 1294/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.453166961669922\n",
      "caption a large flat screen television with many apps on it\n",
      "Evaluated 1295/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.907434463500977\n",
      "caption a man is being held by two men on a tv\n",
      "Evaluated 1296/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.35300064086914\n",
      "caption a large television screen displaying a variety of apps\n",
      "Evaluated 1297/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.115863800048828\n",
      "caption a large flat screen television sitting on top of a desk\n",
      "Evaluated 1298/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.79857063293457\n",
      "caption a television screen showing an image of meat being cooked on a grill\n",
      "Evaluated 1299/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.022216796875\n",
      "caption a computer screen showing a list of files\n",
      "Evaluated 1300/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.483997344970703\n",
      "caption a person holding up a black box\n",
      "Evaluated 1301/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.468246459960938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a video game on a television screen\n",
      "Evaluated 1302/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.803075790405273\n",
      "caption a computer screen displaying a number on it\n",
      "Evaluated 1303/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.73220443725586\n",
      "caption a close up of the screen of a tv\n",
      "Evaluated 1304/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.39313316345215\n",
      "caption a video game on a television screen\n",
      "Evaluated 1305/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.703535079956055\n",
      "caption a white wall with a mirror behind it\n",
      "Evaluated 1306/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.40806007385254\n",
      "caption a person holding a video game controller in front of a television\n",
      "Evaluated 1307/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.185874938964844\n",
      "caption a large television screen displaying a variety of apps\n",
      "Evaluated 1308/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.109228134155273\n",
      "caption a person holding a black box with a small antenna sticking out of it\n",
      "Evaluated 1309/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.354984283447266\n",
      "caption a large flat screen television sitting on top of a desk\n",
      "Evaluated 1310/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.993459701538086\n",
      "caption a flat screen television with a picture of a mountain\n",
      "Evaluated 1311/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.158105850219727\n",
      "caption a television screen with a bag hanging from it\n",
      "Evaluated 1312/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.677278518676758\n",
      "caption a person holding a remote control in front of a tv\n",
      "Evaluated 1313/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.268909454345703\n",
      "caption a television screen showing a picture of three men\n",
      "Evaluated 1314/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.37869644165039\n",
      "caption a close up of the screen of a tv\n",
      "Evaluated 1315/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.045347213745117\n",
      "caption a large flat screen television sitting on top of a table\n",
      "Evaluated 1316/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.9345703125\n",
      "caption a close up of a tv screen with a bunch of pictures on it\n",
      "Evaluated 1317/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.790693283081055\n",
      "caption a person holding a video game controller in front of a television\n",
      "Evaluated 1318/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.69004249572754\n",
      "caption a picture of a man on a tv screen\n",
      "Evaluated 1319/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.317590713500977\n",
      "caption a close up of the screen of a tablet computer\n",
      "Evaluated 1320/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.37333106994629\n",
      "caption a screen shot of a video game on a tv\n",
      "Evaluated 1321/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.211454391479492\n",
      "caption a hand holding a black device next to a box\n",
      "Evaluated 1322/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.729360580444336\n",
      "caption a video game is playing on a tv screen\n",
      "Evaluated 1323/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.688356399536133\n",
      "caption a picture of a computer screen with a blue background\n",
      "Evaluated 1324/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.982765197753906\n",
      "caption a video game on a television screen\n",
      "Evaluated 1325/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.2338924407959\n",
      "caption a television screen showing a list of movies and tv shows\n",
      "Evaluated 1326/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.4449348449707\n",
      "caption a computer screen with the word \"crispy road\" on it\n",
      "Evaluated 1327/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.44878387451172\n",
      "caption a dog is playing in the water on a tv\n",
      "Evaluated 1328/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.82021141052246\n",
      "caption a close up of a person holding a device\n",
      "Evaluated 1329/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.756664276123047\n",
      "caption a television with a picture of a girl on it\n",
      "Evaluated 1330/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.28385353088379\n",
      "caption a close up of a laptop computer screen\n",
      "Evaluated 1331/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.831167221069336\n",
      "caption a computer screen with a bunch of apps on it\n",
      "Evaluated 1332/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.622486114501953\n",
      "caption a person holding a video game controller in front of a computer screen\n",
      "Evaluated 1333/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.38823699951172\n",
      "caption a close up of a laptop computer screen\n",
      "Evaluated 1334/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.920129776000977\n",
      "caption a computer screen with a bunch of apps on it\n",
      "Evaluated 1335/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.10972023010254\n",
      "caption a picture of a tv screen with a web browser on it\n",
      "Evaluated 1336/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.785642623901367\n",
      "caption a computer screen displaying a variety of video games\n",
      "Evaluated 1337/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.125150680541992\n",
      "caption a person holding a small black device\n",
      "Evaluated 1338/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.33330535888672\n",
      "caption a tv screen showing a list of movies and tv shows\n",
      "Evaluated 1339/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.442712783813477\n",
      "caption a person holding a small black device\n",
      "Evaluated 1340/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.80651092529297\n",
      "caption a large television screen displaying a variety of icons\n",
      "Evaluated 1341/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.140979766845703\n",
      "caption a person holding a remote control in their hand\n",
      "Evaluated 1342/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.6921329498291\n",
      "caption a cat sitting on top of a tv watching a movie\n",
      "Evaluated 1343/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.417497634887695\n",
      "caption a box that is sitting on top of a table\n",
      "Evaluated 1344/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.311447143554688\n",
      "caption a cat sitting on top of a tv watching a movie\n",
      "Evaluated 1345/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.304555892944336\n",
      "caption a computer screen with a picture of a tile on it\n",
      "Evaluated 1346/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.919105529785156\n",
      "caption a close up of a person holding a remote control\n",
      "Evaluated 1347/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.548336029052734\n",
      "caption a large television screen displaying a file menu\n",
      "Evaluated 1348/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.12109375\n",
      "caption a television screen displaying a variety of apps\n",
      "Evaluated 1349/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.280141830444336\n",
      "caption a close up of a person holding a device\n",
      "Evaluated 1350/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.735191345214844\n",
      "caption a television with a picture of a man on it\n",
      "Evaluated 1351/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.85904884338379\n",
      "caption a close up of a tv with a blue screen\n",
      "Evaluated 1352/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.66874122619629\n",
      "caption a television with a picture of a dog on it\n",
      "Evaluated 1353/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.123220443725586\n",
      "caption a large television screen with a movie playing on it\n",
      "Evaluated 1354/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.04996681213379\n",
      "caption a video game on a television screen\n",
      "Evaluated 1355/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.940818786621094\n",
      "caption a person writing on a piece of paper with a pen\n",
      "Evaluated 1356/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.91365623474121\n",
      "caption a person holding a small black device\n",
      "Evaluated 1357/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.332988739013672\n",
      "caption a television screen displaying a web browser\n",
      "Evaluated 1358/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.741743087768555\n",
      "caption a television screen with a picture of a mountain\n",
      "Evaluated 1359/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.69985008239746\n",
      "caption a person holding a remote control in their hand\n",
      "Evaluated 1360/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.62910270690918\n",
      "caption a person holding up a black box with an antenna sticking out of it\n",
      "Evaluated 1361/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.328458786010742\n",
      "caption a close up of a laptop computer screen\n",
      "Evaluated 1362/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.891294479370117\n",
      "caption a person holding a video camera in front of a computer screen\n",
      "Evaluated 1363/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.142091751098633\n",
      "caption a hand holding a black box on a table\n",
      "Evaluated 1364/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.158105850219727\n",
      "caption a television screen with a bag hanging from it\n",
      "Evaluated 1365/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.071290969848633\n",
      "caption a person playing a video game on a tv\n",
      "Evaluated 1366/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.7696533203125\n",
      "caption a picture of a car driving on a highway\n",
      "Evaluated 1367/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.535907745361328\n",
      "caption a laptop computer sitting on top of a desk\n",
      "Evaluated 1368/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.974592208862305\n",
      "caption a computer screen displaying a web browser\n",
      "Evaluated 1369/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.845041275024414\n",
      "caption a video game with lego characters on the screen\n",
      "Evaluated 1370/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.62152099609375\n",
      "caption a large television screen displaying a variety of apps\n",
      "Evaluated 1371/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.88376808166504\n",
      "caption a tv screen showing a car driving in a parking lot\n",
      "Evaluated 1372/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.240196228027344\n",
      "caption a computer screen showing a list of files\n",
      "Evaluated 1373/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.17224884033203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a man with a beard on a tv screen\n",
      "Evaluated 1374/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.940351486206055\n",
      "caption a person holding a remote control in front of a tv\n",
      "Evaluated 1375/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.700340270996094\n",
      "caption a computer monitor with an aerial view of a body of water\n",
      "Evaluated 1376/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.51687240600586\n",
      "caption a computer screen with many different icons on it\n",
      "Evaluated 1377/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.90372085571289\n",
      "caption a television screen showing a man with a backpack\n",
      "Evaluated 1378/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.20656394958496\n",
      "caption a black screen with numbers on it\n",
      "Evaluated 1379/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.71846389770508\n",
      "caption a video game with lego characters on it\n",
      "Evaluated 1380/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.194820404052734\n",
      "caption a large flat screen television with a variety of apps on it\n",
      "Evaluated 1381/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.516033172607422\n",
      "caption a cell phone displaying a speed test screen\n",
      "Evaluated 1382/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.043088912963867\n",
      "caption a laptop computer sitting on top of a desk\n",
      "Evaluated 1383/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.11418342590332\n",
      "caption a picture of a car driving on a highway\n",
      "Evaluated 1384/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.503469467163086\n",
      "caption a person holding a video game controller in front of a television\n",
      "Evaluated 1385/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.354459762573242\n",
      "caption a television with a picture of knives on it\n",
      "Evaluated 1386/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.35005760192871\n",
      "caption a picture of a video game on a tv\n",
      "Evaluated 1387/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.673667907714844\n",
      "caption a television with a picture of a woman on it\n",
      "Evaluated 1388/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.480300903320312\n",
      "caption a person holding a remote control in front of a tv\n",
      "Evaluated 1389/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.181005477905273\n",
      "caption a large flat screen television with many apps on it\n",
      "Evaluated 1390/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.33209800720215\n",
      "caption a laptop computer sitting on top of a desk\n",
      "Evaluated 1391/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.83531951904297\n",
      "caption a television with a black woman on it\n",
      "Evaluated 1392/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.792387008666992\n",
      "caption a close up of the screen of a computer\n",
      "Evaluated 1393/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.095829010009766\n",
      "caption a television screen displaying a variety of video games\n",
      "Evaluated 1394/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.023487091064453\n",
      "caption a close up of a laptop computer screen\n",
      "Evaluated 1395/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.419292449951172\n",
      "caption a person holding a remote control in their hand\n",
      "Evaluated 1396/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.1562442779541\n",
      "caption a picture of a keyboard and mouse on a computer screen\n",
      "Evaluated 1397/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.820186614990234\n",
      "caption a large flat screen television displaying a variety of icons\n",
      "Evaluated 1398/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.981990814208984\n",
      "caption a large television screen displaying a variety of apps\n",
      "Evaluated 1399/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.48063850402832\n",
      "caption a person holding a small black device\n",
      "Evaluated 1400/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.453847885131836\n",
      "caption a hand holding a black box with a remote\n",
      "Evaluated 1401/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.69985008239746\n",
      "caption a person holding a remote control in their hand\n",
      "Evaluated 1402/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.27449035644531\n",
      "caption the box for the ugoos 6 is sitting on a table\n",
      "Evaluated 1403/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.508460998535156\n",
      "caption a close up of a person holding a remote control\n",
      "Evaluated 1404/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.943349838256836\n",
      "caption a computer screen showing a list of files\n",
      "Evaluated 1405/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.47739601135254\n",
      "caption thank you for watching have a good day\n",
      "Evaluated 1406/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.088871002197266\n",
      "caption a computer screen displaying a web page\n",
      "Evaluated 1407/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.895246505737305\n",
      "caption a computer screen displaying a variety of video games\n",
      "Evaluated 1408/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.07636833190918\n",
      "caption a computer screen with a bunch of apps on it\n",
      "Evaluated 1409/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a computer screen showing a variety of games\n",
      "Evaluated 1410/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.679136276245117\n",
      "caption a television with a dog on the screen\n",
      "Evaluated 1411/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.419540405273438\n",
      "caption a large flat screen television sitting on top of a desk\n",
      "Evaluated 1412/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.2464714050293\n",
      "caption a television showing a group of people walking in front of a mountain\n",
      "Evaluated 1413/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.79289245605469\n",
      "caption a dog is playing in the water on a tv\n",
      "Evaluated 1414/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.476089477539062\n",
      "caption a person playing a video game on a television\n",
      "Evaluated 1415/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.095958709716797\n",
      "caption a person holding a small device in their hands\n",
      "Evaluated 1416/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.672332763671875\n",
      "caption a person holding a black device in their hand\n",
      "Evaluated 1417/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.79585266113281\n",
      "caption a large television screen displaying a variety of apps\n",
      "Evaluated 1418/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.700071334838867\n",
      "caption a computer screen displaying a web browser\n",
      "Evaluated 1419/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.471696853637695\n",
      "caption a picture of a mountain on a tv screen\n",
      "Evaluated 1420/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.298782348632812\n",
      "caption a close up of a black device on a white surface\n",
      "Evaluated 1421/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.34734535217285\n",
      "caption a picture of a video game controller on a tv screen\n",
      "Evaluated 1422/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.308116912841797\n",
      "caption a computer screen with a bunch of apps on it\n",
      "Evaluated 1423/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.05394744873047\n",
      "caption a person's hands reaching out for a remote control\n",
      "Evaluated 1424/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.000959396362305\n",
      "caption a person holding a pair of scissors next to a remote control\n",
      "Evaluated 1425/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.338397979736328\n",
      "caption a person holding a black device in their hands\n",
      "Evaluated 1426/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.288589477539062\n",
      "caption a picture of a keyboard and a controller\n",
      "Evaluated 1427/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.62440490722656\n",
      "caption a large television screen displaying a variety of apps\n",
      "Evaluated 1428/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.181774139404297\n",
      "caption a close up of a person holding a remote control\n",
      "Evaluated 1429/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.425310134887695\n",
      "caption a person holding a black device in their hand\n",
      "Evaluated 1430/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.762205123901367\n",
      "caption a television screen showing a web browser\n",
      "Evaluated 1431/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.998159408569336\n",
      "caption a television with a picture of a child on it\n",
      "Evaluated 1432/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.60921287536621\n",
      "caption a person playing a video game on a tv\n",
      "Evaluated 1433/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.254207611083984\n",
      "caption an airplane flying through the dark sky\n",
      "Evaluated 1434/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.76563262939453\n",
      "caption a cell phone displaying a speed test screen\n",
      "Evaluated 1435/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.940818786621094\n",
      "caption a person writing on a piece of paper with a pen\n",
      "Evaluated 1436/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.357410430908203\n",
      "caption a person playing a video game on a television\n",
      "Evaluated 1437/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.35799789428711\n",
      "caption a close up of a person holding a remote control\n",
      "Evaluated 1438/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.48760414123535\n",
      "caption a television screen displaying a picture of soldiers\n",
      "Evaluated 1439/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.004552841186523\n",
      "caption a television screen showing a woman riding a horse\n",
      "Evaluated 1440/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.174192428588867\n",
      "caption a television screen showing a large crowd of people\n",
      "Evaluated 1441/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.706008911132812\n",
      "caption a person holding a remote control in front of a computer screen\n",
      "Evaluated 1442/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.495431900024414\n",
      "caption a person holding a remote control in front of a television\n",
      "Evaluated 1443/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.61241340637207\n",
      "caption a close up of a computer screen with icons on it\n",
      "Evaluated 1444/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.5864200592041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a cat is watching a soccer game on tv\n",
      "Evaluated 1445/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.69305992126465\n",
      "caption a large flat screen television displaying a variety of apps\n",
      "Evaluated 1446/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.644439697265625\n",
      "caption a hand holding a black box with an antenna sticking out of it\n",
      "Evaluated 1447/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.73967170715332\n",
      "caption a picture of a computer screen with a dark background\n",
      "Evaluated 1448/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.836116790771484\n",
      "caption a computer screen displaying a variety of games\n",
      "Evaluated 1449/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.135879516601562\n",
      "caption a video game on a television screen\n",
      "Evaluated 1450/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.061195373535156\n",
      "caption the screen of a tablet computer in the dark\n",
      "Evaluated 1451/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.491662979125977\n",
      "caption a computer screen showing a variety of games\n",
      "Evaluated 1452/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.88111114501953\n",
      "caption a picture of a computer on a desk\n",
      "Evaluated 1453/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.202255249023438\n",
      "caption a video game on a television screen\n",
      "Evaluated 1454/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.89162254333496\n",
      "caption a television screen showing the top ten best performing televisions\n",
      "Evaluated 1455/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.62484359741211\n",
      "caption two men are fighting on a television screen\n",
      "Evaluated 1456/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.451751708984375\n",
      "caption a laptop computer sitting on top of a desk\n",
      "Evaluated 1457/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.865577697753906\n",
      "caption a large flat screen television with various apps on it\n",
      "Evaluated 1458/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.40559196472168\n",
      "caption a person holding a video game controller in front of a television\n",
      "Evaluated 1459/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.184425354003906\n",
      "caption a man is on the screen of a tv\n",
      "Evaluated 1460/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.741039276123047\n",
      "caption a large flat screen television sitting on top of a desk\n",
      "Evaluated 1461/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.33260154724121\n",
      "caption a computer screen showing a list of files\n",
      "Evaluated 1462/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.710983276367188\n",
      "caption a close up of a television screen\n",
      "Evaluated 1463/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.939294815063477\n",
      "caption a man in a blue shirt with a bandana on his head\n",
      "Evaluated 1464/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.663625717163086\n",
      "caption a video game on a television screen\n",
      "Evaluated 1465/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.058212280273438\n",
      "caption a laptop computer sitting on top of a desk\n",
      "Evaluated 1466/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.380830764770508\n",
      "caption a person is using a remote to control a tv\n",
      "Evaluated 1467/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.260597229003906\n",
      "caption a screen shot of a video game on a tv\n",
      "Evaluated 1468/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.714452743530273\n",
      "caption a computer screen displaying a web browser\n",
      "Evaluated 1469/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.2398738861084\n",
      "caption a close up of the screen of a laptop computer\n",
      "Evaluated 1470/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.908483505249023\n",
      "caption a person playing a video game on a tv\n",
      "Evaluated 1471/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.596269607543945\n",
      "caption a close up of a computer screen with some text on it\n",
      "Evaluated 1472/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.86989974975586\n",
      "caption a television screen showing a video game\n",
      "Evaluated 1473/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.5072021484375\n",
      "caption a close up of a tv screen with a bunch of knives on it\n",
      "Evaluated 1474/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.192218780517578\n",
      "caption a close up of the screen of a computer\n",
      "Evaluated 1475/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.203073501586914\n",
      "caption a laptop computer sitting on top of a desk\n",
      "Evaluated 1476/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.137615203857422\n",
      "caption a large television screen displaying a variety of apps\n",
      "Evaluated 1477/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.27928924560547\n",
      "caption a television screen showing a man walking down a hallway\n",
      "Evaluated 1478/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.291719436645508\n",
      "caption a person holding a video game controller in front of a television\n",
      "Evaluated 1479/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.00438117980957\n",
      "caption a person laying on the floor of a building\n",
      "Evaluated 1480/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.299190521240234\n",
      "caption a screen shot of a website with a button that says \"notifications from tech review\"\n",
      "Evaluated 1481/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.08796501159668\n",
      "caption a person holding a small black device\n",
      "Evaluated 1482/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.02043342590332\n",
      "caption a computer screen with a bunch of apps on it\n",
      "Evaluated 1483/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.06867599487305\n",
      "caption a large television screen displaying a variety of apps\n",
      "Evaluated 1484/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.274311065673828\n",
      "caption a computer screen showing a list of games\n",
      "Evaluated 1485/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.19709777832031\n",
      "caption the box for the uos6 is sitting on a table\n",
      "Evaluated 1486/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.99724578857422\n",
      "caption a person holding a black device in their hand\n",
      "Evaluated 1487/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.975322723388672\n",
      "caption a person is holding a black device\n",
      "Evaluated 1488/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.641504287719727\n",
      "caption a large television screen displaying a variety of apps\n",
      "Evaluated 1489/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.21417999267578\n",
      "caption a picture of a keyboard and mouse on a tv screen\n",
      "Evaluated 1490/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.309328079223633\n",
      "caption a computer screen showing a variety of games\n",
      "Evaluated 1491/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.177501678466797\n",
      "caption a person holding a black device in their hand\n",
      "Evaluated 1492/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.83442497253418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a tv screen showing a list of movies and tv shows\n",
      "Evaluated 1493/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.241540908813477\n",
      "caption a box that is sitting on top of a table\n",
      "Evaluated 1494/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.54604721069336\n",
      "caption a cat playing a video game on a television\n",
      "Evaluated 1495/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.484445571899414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a computer screen showing the launcher application\n",
      "Evaluated 1496/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.652942657470703\n",
      "caption a screen shot of a video game on a tv\n",
      "Evaluated 1497/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.175588607788086\n",
      "caption a television screen showing an aerial view of a road\n",
      "Evaluated 1498/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.35535430908203\n",
      "caption a video game is playing on a television\n",
      "Evaluated 1499/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.972990036010742\n",
      "caption a computer screen showing a game on it\n",
      "Evaluated 1500/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.941041946411133\n",
      "caption a computer screen with a bunch of apps on it\n",
      "Evaluated 1501/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.557741165161133\n",
      "caption a person holding a video game controller in front of a computer screen\n",
      "Evaluated 1502/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.2464714050293\n",
      "caption a television showing a group of people walking in front of a mountain\n",
      "Evaluated 1503/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.637277603149414\n",
      "caption a black background with a smiley face on it\n",
      "Evaluated 1504/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.670530319213867\n",
      "caption a television screen showing an image of meat on a grill\n",
      "Evaluated 1505/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.32310676574707\n",
      "caption a person holding two small black devices\n",
      "Evaluated 1506/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.229961395263672\n",
      "caption a close up of a television screen\n",
      "Evaluated 1507/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.46135711669922\n",
      "caption a picture of a keyboard and a controller\n",
      "Evaluated 1508/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.284982681274414\n",
      "caption a man holding a remote control next to a box\n",
      "Evaluated 1509/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.471712112426758\n",
      "caption a hand holding a black device next to a box\n",
      "Evaluated 1510/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.193204879760742\n",
      "caption a person holding a remote in front of a screen\n",
      "Evaluated 1511/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.101961135864258\n",
      "caption a person holding a small black device\n",
      "Evaluated 1512/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.311279296875\n",
      "caption a television screen displaying a variety of apps\n",
      "Evaluated 1513/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.12383270263672\n",
      "caption a hand holding a box that has a device inside of it\n",
      "Evaluated 1514/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.26618003845215\n",
      "caption a hand holding a black box with a usb port on it\n",
      "Evaluated 1515/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.116737365722656\n",
      "caption thanks for watching have a brilliant day\n",
      "Evaluated 1516/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.1387996673584\n",
      "caption a picture of a man looking at a tv screen\n",
      "Evaluated 1517/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.936527252197266\n",
      "caption a close up of a computer screen with icons on it\n",
      "Evaluated 1518/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.472454071044922\n",
      "caption a computer screen displaying a variety of video games\n",
      "Evaluated 1519/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.735191345214844\n",
      "caption a television with a picture of a man on it\n",
      "Evaluated 1520/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.01727867126465\n",
      "caption a close up of a tv screen with a movie playing on it\n",
      "Evaluated 1521/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.38534164428711\n",
      "caption a video game screen with a cartoon character on it\n",
      "Evaluated 1522/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.89466857910156\n",
      "caption a video game with lego characters on the screen\n",
      "Evaluated 1523/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.225793838500977\n",
      "caption a black box sitting on top of a white surface\n",
      "Evaluated 1524/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.980548858642578\n",
      "caption a large flat screen television sitting on top of a desk\n",
      "Evaluated 1525/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.926082611083984\n",
      "caption a cell phone displaying a speed test screen\n",
      "Evaluated 1526/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.112625122070312\n",
      "caption a large flat screen television sitting on top of a table\n",
      "Evaluated 1527/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.845041275024414\n",
      "caption a video game with lego characters on the screen\n",
      "Evaluated 1528/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.43524742126465\n",
      "caption a person holding a small black device\n",
      "Evaluated 1529/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.403623580932617\n",
      "caption a television screen showing a video game\n",
      "Evaluated 1530/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.943546295166016\n",
      "caption a computer screen displaying a list of music files\n",
      "Evaluated 1531/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.657011032104492\n",
      "caption a black screen with numbers on it\n",
      "Evaluated 1532/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.536094665527344\n",
      "caption a person holding a remote control in front of a tv\n",
      "Evaluated 1533/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.660972595214844\n",
      "caption a large flat screen television sitting on top of a desk\n",
      "Evaluated 1534/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.68723487854004\n",
      "caption a person playing a video game on a tv\n",
      "Evaluated 1535/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.040748596191406\n",
      "caption a man is standing in front of a tall building\n",
      "Evaluated 1536/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.23042869567871\n",
      "caption a person holding a video game controller in front of a television\n",
      "Evaluated 1537/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.03300094604492\n",
      "caption a computer screen displaying an iron fist trailer\n",
      "Evaluated 1538/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.394222259521484\n",
      "caption a large flat screen television sitting on top of a table\n",
      "Evaluated 1539/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.640878677368164\n",
      "caption a television screen displaying a variety of video games\n",
      "Evaluated 1540/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.362529754638672\n",
      "caption a person holding a video game controller in front of a tv\n",
      "Evaluated 1541/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.38147735595703\n",
      "caption a close up of the screen of a tablet computer\n",
      "Evaluated 1542/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.973560333251953\n",
      "caption a computer screen displaying a variety of games\n",
      "Evaluated 1543/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.381105422973633\n",
      "caption a large flat screen television sitting on top of a table\n",
      "Evaluated 1544/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.816238403320312\n",
      "caption a screen shot of a video game\n",
      "Evaluated 1545/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.929889678955078\n",
      "caption the screen of a tablet computer in the dark\n",
      "Evaluated 1546/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.38882827758789\n",
      "caption a person holding up a black box with a small antenna sticking out of it\n",
      "Evaluated 1547/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.701108932495117\n",
      "caption a large flat screen television sitting on top of a desk\n",
      "Evaluated 1548/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.82109832763672\n",
      "caption a tablet computer with a keyboard on it\n",
      "Evaluated 1549/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.417617797851562\n",
      "caption a computer screen showing the launcher application\n",
      "Evaluated 1550/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.614185333251953\n",
      "caption a television screen showing a man walking down a hallway\n",
      "Evaluated 1551/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.19861602783203\n",
      "caption a person holding a remote control in front of a tv\n",
      "Evaluated 1552/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.80705642700195\n",
      "caption a large flat screen television with many different apps on it\n",
      "Evaluated 1553/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.4449348449707\n",
      "caption a computer screen with the word \"crispy road\" on it\n",
      "Evaluated 1554/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.409074783325195\n",
      "caption a hand holding a box with a remote control\n",
      "Evaluated 1555/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.581024169921875\n",
      "caption a person holding a black device next to a box\n",
      "Evaluated 1556/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.686912536621094\n",
      "caption a television screen showing a video game\n",
      "Evaluated 1557/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.889921188354492\n",
      "caption a computer screen displaying a variety of video games\n",
      "Evaluated 1558/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.37873649597168\n",
      "caption a close up of a tv screen with a blue screen\n",
      "Evaluated 1559/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.135862350463867\n",
      "caption a tablet computer displaying a number on the screen\n",
      "Evaluated 1560/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.139190673828125\n",
      "caption a laptop computer sitting on top of a desk\n",
      "Evaluated 1561/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.220144271850586\n",
      "caption a large television screen displaying a variety of apps\n",
      "Evaluated 1562/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.142330169677734\n",
      "caption a person holding a video game controller in front of a television\n",
      "Evaluated 1563/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.942018508911133\n",
      "caption a computer screen showing the launcher application\n",
      "Evaluated 1564/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.0683650970459\n",
      "caption a soccer game is being played on a television\n",
      "Evaluated 1565/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.43360137939453\n",
      "caption a person holding a video camera in front of a computer screen\n",
      "Evaluated 1566/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.40864372253418\n",
      "caption a man watching a soccer game on a tv\n",
      "Evaluated 1567/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.345518112182617\n",
      "caption a black background with a smiley face on it\n",
      "Evaluated 1568/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.608768463134766\n",
      "caption a stop sign in the middle of a road\n",
      "Evaluated 1569/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.92116928100586\n",
      "caption a video game on a television screen\n",
      "Evaluated 1570/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.177501678466797\n",
      "caption a person holding a black device in their hand\n",
      "Evaluated 1571/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.394920349121094\n",
      "caption a television with a picture of clouds on it\n",
      "Evaluated 1572/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a computer screen displaying a variety of video games\n",
      "Evaluated 1573/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.720474243164062\n",
      "caption a television with a picture of a snowy landscape on it\n",
      "Evaluated 1574/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.66808319091797\n",
      "caption a cell phone displaying a speed test screen\n",
      "Evaluated 1575/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.939992904663086\n",
      "caption a person holding up a piece of plastic\n",
      "Evaluated 1576/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.343290328979492\n",
      "caption a cell phone with a begin test button on it\n",
      "Evaluated 1577/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.6342887878418\n",
      "caption a large flat screen television with many apps on it\n",
      "Evaluated 1578/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.788148880004883\n",
      "caption a television screen displaying a variety of icons\n",
      "Evaluated 1579/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.855804443359375\n",
      "caption a close up of a person holding a device\n",
      "Evaluated 1580/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.47127342224121\n",
      "caption a hand holding a black box with an antenna sticking out of it\n",
      "Evaluated 1581/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.265953063964844\n",
      "caption a computer screen with various games on it\n",
      "Evaluated 1582/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.322933197021484\n",
      "caption a close up of a person sleeping on a couch\n",
      "Evaluated 1583/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.96837043762207\n",
      "caption a person holding a remote control next to a box\n",
      "Evaluated 1584/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.122045516967773\n",
      "caption a television with a picture of a puppy on it\n",
      "Evaluated 1585/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.479887008666992\n",
      "caption a video game screen with a cartoon character on it\n",
      "Evaluated 1586/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.92491340637207\n",
      "caption a cat sitting on top of a tv watching a movie\n",
      "Evaluated 1587/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  15.978885650634766\n",
      "caption a cat sitting on top of a television screen\n",
      "Evaluated 1588/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.5504093170166\n",
      "caption a soccer game being played in front of a large crowd\n",
      "Evaluated 1589/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.92382049560547\n",
      "caption a close up of a person holding a device\n",
      "Evaluated 1590/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.318315505981445\n",
      "caption a large flat screen television sitting on top of a table\n",
      "Evaluated 1591/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.237083435058594\n",
      "caption a white box sitting on top of a table\n",
      "Evaluated 1592/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.60071563720703\n",
      "caption a picture of a keyboard and mouse on a computer screen\n",
      "Evaluated 1593/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.53421974182129\n",
      "caption a computer screen with a video playing on it\n",
      "Evaluated 1594/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.78307342529297\n",
      "caption a person holding a remote control and a usb cable\n",
      "Evaluated 1595/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.16669464111328\n",
      "caption a picture of a tv screen with some icons on it\n",
      "Evaluated 1596/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.520883560180664\n",
      "caption a person holding a small electronic device\n",
      "Evaluated 1597/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.2092342376709\n",
      "caption a picture of a keyboard and mouse on a tv screen\n",
      "Evaluated 1598/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.30430793762207\n",
      "caption a cell phone displaying a speedometer on the screen\n",
      "Evaluated 1599/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.185382843017578\n",
      "caption a school bus that has been involved in an accident\n",
      "Evaluated 1600/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.445817947387695\n",
      "caption a group of people standing next to a school bus\n",
      "Evaluated 1601/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.382688522338867\n",
      "caption a large truck driving down a road next to a school bus\n",
      "Evaluated 1602/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.916404724121094\n",
      "caption a man in a yellow jacket standing next to a school bus\n",
      "Evaluated 1603/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.482810974121094\n",
      "caption a large truck driving down a road next to a school bus\n",
      "Evaluated 1604/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.159757614135742\n",
      "caption a school bus that has been involved in an accident\n",
      "Evaluated 1605/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.67591094970703\n",
      "caption a group of people standing around a school bus\n",
      "Evaluated 1606/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.666894912719727\n",
      "caption a school bus is involved in an accident\n",
      "Evaluated 1607/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.0666618347168\n",
      "caption a school bus is involved in an accident on a wet road\n",
      "Evaluated 1608/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.666894912719727\n",
      "caption a school bus is involved in an accident\n",
      "Evaluated 1609/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.926570892333984\n",
      "caption a school bus is involved in an accident\n",
      "Evaluated 1610/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.56031036376953\n",
      "caption a group of people standing around a table\n",
      "Evaluated 1611/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.72613525390625\n",
      "caption a woman is interviewed on a news show\n",
      "Evaluated 1612/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.277881622314453\n",
      "caption two women sitting at a table in front of bookshelves\n",
      "Evaluated 1613/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.739614486694336\n",
      "caption a woman is interviewed on a news show\n",
      "Evaluated 1614/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.41028594970703\n",
      "caption two people are writing on a wall\n",
      "Evaluated 1615/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.86893844604492\n",
      "caption a woman with curly hair and red lipstick\n",
      "Evaluated 1616/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.787044525146484\n",
      "caption a woman wearing a maroon jacket on a news set\n",
      "Evaluated 1617/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  35.36457061767578\n",
      "caption a piece of paper is stuck to the wall of a stairwell\n",
      "Evaluated 1618/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.046512603759766\n",
      "caption a building with a clock on the side of it\n",
      "Evaluated 1619/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.873567581176758\n",
      "caption a police car parked in front of a large building\n",
      "Evaluated 1620/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.777318954467773\n",
      "caption a woman is interviewed on a news show\n",
      "Evaluated 1621/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.206680297851562\n",
      "caption two women sitting at a table talking to each other\n",
      "Evaluated 1622/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.290084838867188\n",
      "caption a woman with curly hair on a news show\n",
      "Evaluated 1623/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.06887435913086\n",
      "caption a woman with her eyes closed sitting in front of a camera\n",
      "Evaluated 1624/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.904571533203125\n",
      "caption two women standing in front of flowers near a yellow tape\n",
      "Evaluated 1625/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.576974868774414\n",
      "caption a woman is interviewed on a news show\n",
      "Evaluated 1626/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.383651733398438\n",
      "caption a close up of a set of stairs\n",
      "Evaluated 1627/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.895709991455078\n",
      "caption two people walking down a hallway in a building\n",
      "Evaluated 1628/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.90623664855957\n",
      "caption a person walking down a set of stairs\n",
      "Evaluated 1629/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.455196380615234\n",
      "caption a couple of women standing next to each other\n",
      "Evaluated 1630/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.762310028076172\n",
      "caption a woman in a red jacket talking to a camera\n",
      "Evaluated 1631/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.652372360229492\n",
      "caption a woman with her eyes closed on a news set\n",
      "Evaluated 1632/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.565101623535156\n",
      "caption a woman in a black shirt talking to a reporter\n",
      "Evaluated 1633/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.844440460205078\n",
      "caption a black background with white text on it\n",
      "Evaluated 1634/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.62373924255371\n",
      "caption a woman is interviewed on a news show\n",
      "Evaluated 1635/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.482006072998047\n",
      "caption a woman standing in front of bookshelves in a library\n",
      "Evaluated 1636/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.13520050048828\n",
      "caption a woman with curly hair on a news show\n",
      "Evaluated 1637/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.89116668701172\n",
      "caption a woman in a police uniform talking to a reporter\n",
      "Evaluated 1638/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.37967872619629\n",
      "caption a bathroom wall with writing on it\n",
      "Evaluated 1639/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.940139770507812\n",
      "caption a woman holding a cell phone while writing on a wall\n",
      "Evaluated 1640/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.33934211730957\n",
      "caption two women sitting at a table talking to each other\n",
      "Evaluated 1641/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.784448623657227\n",
      "caption two women sitting at a table in front of bookshelves\n",
      "Evaluated 1642/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.30897331237793\n",
      "caption two people walking down a hallway in a building\n",
      "Evaluated 1643/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.29017448425293\n",
      "caption a woman sitting in front of a news desk\n",
      "Evaluated 1644/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.448198318481445\n",
      "caption a woman with gray hair sitting on a news set\n",
      "Evaluated 1645/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.07122039794922\n",
      "caption a couple of women standing next to each other\n",
      "Evaluated 1646/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.177791595458984\n",
      "caption a woman is interviewed on a news program\n",
      "Evaluated 1647/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.63114356994629\n",
      "caption a bathroom with a toilet paper roll on the floor\n",
      "Evaluated 1648/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.762859344482422\n",
      "caption a woman with curly hair in front of bookshelves\n",
      "Evaluated 1649/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.971878051757812\n",
      "caption two people sitting at a table talking to each other\n",
      "Evaluated 1650/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.074371337890625\n",
      "caption a woman with curly hair on a news show\n",
      "Evaluated 1651/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.41748046875\n",
      "caption a woman with curly hair on a news show\n",
      "Evaluated 1652/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.618484497070312\n",
      "caption a white wall with writing on it\n",
      "Evaluated 1653/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.52815055847168\n",
      "caption a group of people standing around a bar\n",
      "Evaluated 1654/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.44598388671875\n",
      "caption a blurry picture of a bathroom mirror\n",
      "Evaluated 1655/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.077877044677734\n",
      "caption a woman in a black shirt talking to a camera\n",
      "Evaluated 1656/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.592681884765625\n",
      "caption a picture of a woman on a tv screen\n",
      "Evaluated 1657/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.94651412963867\n",
      "caption the logo for democracy now on a black background\n",
      "Evaluated 1658/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.671283721923828\n",
      "caption a woman in a black shirt talking to a news anchor\n",
      "Evaluated 1659/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.346506118774414\n",
      "caption a woman in a black shirt talking to a camera\n",
      "Evaluated 1660/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.39948844909668\n",
      "caption a woman is interviewed on a news show\n",
      "Evaluated 1661/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.534454345703125\n",
      "caption a bathroom with a sink and a toilet\n",
      "Evaluated 1662/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.832828521728516\n",
      "caption a woman sitting in front of a television screen\n",
      "Evaluated 1663/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.52818489074707\n",
      "caption a woman with curly hair on a news show\n",
      "Evaluated 1664/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.85582160949707\n",
      "caption two women sitting at a table in front of bookshelves\n",
      "Evaluated 1665/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.72786521911621\n",
      "caption two people sitting at a table in front of bookshelves\n",
      "Evaluated 1666/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.381500244140625\n",
      "caption a sign on a door that says \"free no smoke\"\n",
      "Evaluated 1667/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.467178344726562\n",
      "caption two people sitting at a table talking to each other\n",
      "Evaluated 1668/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.17906379699707\n",
      "caption a woman wearing a black shirt in front of bookshelves\n",
      "Evaluated 1669/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.238374710083008\n",
      "caption a woman is looking at something on a table\n",
      "Evaluated 1670/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.487808227539062\n",
      "caption a white board with writing on it\n",
      "Evaluated 1671/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.071001052856445\n",
      "caption a woman sitting in front of a television screen\n",
      "Evaluated 1672/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.401660919189453\n",
      "caption a woman is interviewed on a news show\n",
      "Evaluated 1673/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.85698890686035\n",
      "caption a woman with curly hair on a news show\n",
      "Evaluated 1674/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.99820327758789\n",
      "caption a bathroom with a sign that says \"all gender restroom\"\n",
      "Evaluated 1675/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.320037841796875\n",
      "caption a woman sitting in front of a television screen\n",
      "Evaluated 1676/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.744598388671875\n",
      "caption a picture of a sign on a window\n",
      "Evaluated 1677/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.93523597717285\n",
      "caption a woman with curly hair on a news show\n",
      "Evaluated 1678/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.568632125854492\n",
      "caption a woman is interviewed on a news show\n",
      "Evaluated 1679/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.985822677612305\n",
      "caption a picture of a woman on a television screen\n",
      "Evaluated 1680/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.045705795288086\n",
      "caption a woman in a black shirt talking to a camera\n",
      "Evaluated 1681/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.826257705688477\n",
      "caption two women sitting at a table talking to each other\n",
      "Evaluated 1682/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.844579696655273\n",
      "caption a woman standing in front of some bookshelves\n",
      "Evaluated 1683/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.826326370239258\n",
      "caption a woman sitting in front of bookshelves in front of a tv\n",
      "Evaluated 1684/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.86531639099121\n",
      "caption a woman with curly hair on a news show\n",
      "Evaluated 1685/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.194889068603516\n",
      "caption a woman in a black shirt talking to a camera\n",
      "Evaluated 1686/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.527158737182617\n",
      "caption a woman on a news show talking to someone\n",
      "Evaluated 1687/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.21214485168457\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 1688/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.678253173828125\n",
      "caption a woman wearing a maroon jacket on a news set\n",
      "Evaluated 1689/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.410024642944336\n",
      "caption a woman in a black shirt talking to a camera\n",
      "Evaluated 1690/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.83543586730957\n",
      "caption a woman in a red jacket is on a news set\n",
      "Evaluated 1691/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.078773498535156\n",
      "caption a woman sitting in front of a television screen\n",
      "Evaluated 1692/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.770980834960938\n",
      "caption a woman is interviewed on a news show\n",
      "Evaluated 1693/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.986495971679688\n",
      "caption a woman standing in front of bookshelves in a library\n",
      "Evaluated 1694/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.500595092773438\n",
      "caption a woman is interviewed on a news show\n",
      "Evaluated 1695/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.027137756347656\n",
      "caption two women sitting at a table talking to each other\n",
      "Evaluated 1696/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.683504104614258\n",
      "caption a woman with gray hair sitting in front of a camera\n",
      "Evaluated 1697/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.352313995361328\n",
      "caption a woman in a black shirt sitting in front of bookshelves\n",
      "Evaluated 1698/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.50556945800781\n",
      "caption a woman with curly hair and red lipstick\n",
      "Evaluated 1699/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.394996643066406\n",
      "caption a woman standing in front of bookshelves in a library\n",
      "Evaluated 1700/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.383651733398438\n",
      "caption a close up of a set of stairs\n",
      "Evaluated 1701/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.15632438659668\n",
      "caption a woman is interviewed on a news show\n",
      "Evaluated 1702/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.06293487548828\n",
      "caption a woman in a red jacket and black blouse\n",
      "Evaluated 1703/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.164432525634766\n",
      "caption a woman wearing a black shirt is on the news\n",
      "Evaluated 1704/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.262784957885742\n",
      "caption a woman in a black shirt talking to a camera\n",
      "Evaluated 1705/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.837167739868164\n",
      "caption a woman wearing a black shirt in front of bookshelves\n",
      "Evaluated 1706/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.356975555419922\n",
      "caption a woman is interviewed on a news show\n",
      "Evaluated 1707/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.768037796020508\n",
      "caption a black background with white text on it\n",
      "Evaluated 1708/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.2722225189209\n",
      "caption a woman in a black shirt talking to a reporter\n",
      "Evaluated 1709/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.06719970703125\n",
      "caption a computer screen with a circle in the middle\n",
      "Evaluated 1710/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.89487648010254\n",
      "caption a yellow surfboard on a white background\n",
      "Evaluated 1711/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.628477096557617\n",
      "caption a photo of a man holding a light saber\n",
      "Evaluated 1712/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.153247833251953\n",
      "caption a photo of a man holding a light saber\n",
      "Evaluated 1713/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.75385665893555\n",
      "caption a man holding a light saber in front of a computer screen\n",
      "Evaluated 1714/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.559873580932617\n",
      "caption a man in a black tank top holding a lighted bat\n",
      "Evaluated 1715/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.628679275512695\n",
      "caption a computer screen with a picture of a man on it\n",
      "Evaluated 1716/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.57149887084961\n",
      "caption a man holding a light saber in front of a computer screen\n",
      "Evaluated 1717/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.380273818969727\n",
      "caption a man in a black tank top holding a lighted bat\n",
      "Evaluated 1718/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.753782272338867\n",
      "caption a computer screen with a circle in the middle\n",
      "Evaluated 1719/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.219093322753906\n",
      "caption a man making a funny face in front of a sign\n",
      "Evaluated 1720/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.154560089111328\n",
      "caption a photo of a man in a black tank top\n",
      "Evaluated 1721/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.822843551635742\n",
      "caption a photo of a man with a red light saber\n",
      "Evaluated 1722/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.263761520385742\n",
      "caption a man in a black tank top holding a lighted bat\n",
      "Evaluated 1723/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.76352310180664\n",
      "caption a man in a black tank top holding a lighted bat\n",
      "Evaluated 1724/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.846094131469727\n",
      "caption a man holding a light saber in front of a computer screen\n",
      "Evaluated 1725/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.29880142211914\n",
      "caption a man holding a light saber in front of a computer screen\n",
      "Evaluated 1726/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.751649856567383\n",
      "caption a man in a black tank top holding a red light saber\n",
      "Evaluated 1727/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.360137939453125\n",
      "caption a man holding a light saber in front of a computer screen\n",
      "Evaluated 1728/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.06476593017578\n",
      "caption a photo of a man holding a light saber\n",
      "Evaluated 1729/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.427845001220703\n",
      "caption a man in a black tank top holding a lighted bat\n",
      "Evaluated 1730/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.564939498901367\n",
      "caption a photo of a man in front of a red light\n",
      "Evaluated 1731/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.632198333740234\n",
      "caption a woman in a red shirt standing on a stage\n",
      "Evaluated 1732/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.993762969970703\n",
      "caption a woman in a red shirt talking on a cell phone\n",
      "Evaluated 1733/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.313207626342773\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1734/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.77159881591797\n",
      "caption a woman standing on a stage giving a speech\n",
      "Evaluated 1735/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.805763244628906\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1736/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.626279830932617\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1737/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.5194091796875\n",
      "caption a person standing on a stage in front of a crowd\n",
      "Evaluated 1738/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.699663162231445\n",
      "caption a woman standing in front of a screen with her hands up\n",
      "Evaluated 1739/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.118717193603516\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1740/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.53042984008789\n",
      "caption a group of people sitting in a dark room\n",
      "Evaluated 1741/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.81562042236328\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1742/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.847673416137695\n",
      "caption a group of people sitting in a dark room\n",
      "Evaluated 1743/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.629924774169922\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1744/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.374509811401367\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1745/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.98417091369629\n",
      "caption two women sitting next to each other in a crowd\n",
      "Evaluated 1746/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.63176727294922\n",
      "caption a woman in a red shirt standing on a stage\n",
      "Evaluated 1747/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.688196182250977\n",
      "caption a group of people sitting in a dark room\n",
      "Evaluated 1748/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.580162048339844\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1749/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.398942947387695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1750/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.976642608642578\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1751/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.698884963989258\n",
      "caption a woman standing on a stage in front of a large screen\n",
      "Evaluated 1752/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.784452438354492\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1753/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.989871978759766\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1754/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.507854461669922\n",
      "caption a woman standing on a stage giving a speech\n",
      "Evaluated 1755/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.270736694335938\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1756/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.737045288085938\n",
      "caption a woman in a red shirt standing on a stage\n",
      "Evaluated 1757/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.41733741760254\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1758/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.798059463500977\n",
      "caption a group of people sitting in a crowd\n",
      "Evaluated 1759/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.127016067504883\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1760/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.755945205688477\n",
      "caption a woman in a red shirt standing in front of a screen\n",
      "Evaluated 1761/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.456329345703125\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1762/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.056732177734375\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1763/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.96530532836914\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1764/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.495393753051758\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1765/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.081432342529297\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1766/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.863845825195312\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1767/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.885089874267578\n",
      "caption a woman in a red shirt standing in front of a screen\n",
      "Evaluated 1768/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.658594131469727\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1769/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.019739151000977\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1770/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.357816696166992\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1771/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.99278259277344\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1772/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.47481918334961\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1773/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.410829544067383\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1774/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.157060623168945\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1775/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.11957550048828\n",
      "caption a woman in a red shirt standing on a stage\n",
      "Evaluated 1776/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.493932723999023\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1777/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.139360427856445\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1778/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.164276123046875\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1779/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.73909568786621\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1780/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.352291107177734\n",
      "caption a woman in a red shirt standing on a stage\n",
      "Evaluated 1781/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.007673263549805\n",
      "caption two women sitting next to each other in a crowd\n",
      "Evaluated 1782/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.484554290771484\n",
      "caption a woman in a red shirt standing on a stage\n",
      "Evaluated 1783/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.41201400756836\n",
      "caption a woman in a red shirt standing on a stage\n",
      "Evaluated 1784/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.128387451171875\n",
      "caption a woman in a red shirt standing in front of a screen\n",
      "Evaluated 1785/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.89761734008789\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1786/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.005615234375\n",
      "caption a group of people sitting in a dark room\n",
      "Evaluated 1787/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.065326690673828\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1788/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.33656883239746\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1789/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.360218048095703\n",
      "caption a black background with various logos on it\n",
      "Evaluated 1790/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.761837005615234\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1791/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.77159881591797\n",
      "caption a woman standing on a stage giving a speech\n",
      "Evaluated 1792/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.945783615112305\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1793/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.921594619750977\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1794/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.163339614868164\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1795/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.841062545776367\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1796/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.305219650268555\n",
      "caption a woman standing on a stage with a microphone\n",
      "Evaluated 1797/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.44647789001465\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1798/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.378028869628906\n",
      "caption a person standing on a stage in front of a crowd\n",
      "Evaluated 1799/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.296897888183594\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1800/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.343475341796875\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1801/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.512971878051758\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1802/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.380170822143555\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1803/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.39290237426758\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1804/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.730815887451172\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1805/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.823335647583008\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1806/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.328527450561523\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1807/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.943805694580078\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1808/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.21364974975586\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1809/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.449487686157227\n",
      "caption a woman standing on a stage giving a speech\n",
      "Evaluated 1810/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.585668563842773\n",
      "caption a black background with a red logo on it\n",
      "Evaluated 1811/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.994380950927734\n",
      "caption a woman giving a speech on a stage\n",
      "Evaluated 1812/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.384809494018555\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1813/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.131855010986328\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1814/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.784561157226562\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1815/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.168502807617188\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1816/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.41767883300781\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1817/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.147390365600586\n",
      "caption a woman standing on a stage giving a presentation\n",
      "Evaluated 1818/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.682416915893555\n",
      "caption a woman standing on a stage giving a presentation\n",
      "Evaluated 1819/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.86731719970703\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1820/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.014738082885742\n",
      "caption a woman in a red shirt standing in front of a screen\n",
      "Evaluated 1821/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.00707244873047\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1822/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.02176284790039\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1823/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.90290641784668\n",
      "caption a woman in a red shirt standing in front of a screen\n",
      "Evaluated 1824/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.740129470825195\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1825/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.355966567993164\n",
      "caption a woman in a red shirt standing on a stage\n",
      "Evaluated 1826/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.14378547668457\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1827/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.94903564453125\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1828/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.649667739868164\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1829/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.055362701416016\n",
      "caption a man in a blue shirt sitting next to other people\n",
      "Evaluated 1830/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.13878631591797\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1831/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.663686752319336\n",
      "caption a woman standing on a stage in front of a large screen\n",
      "Evaluated 1832/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.255712509155273\n",
      "caption a woman in a red shirt standing on a stage\n",
      "Evaluated 1833/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.982460021972656\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1834/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.11680793762207\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1835/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.00088119506836\n",
      "caption a woman standing on a stage at a tedx event\n",
      "Evaluated 1836/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.24534034729004\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1837/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.85147476196289\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1838/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.048349380493164\n",
      "caption a woman standing in front of a screen with her hands up\n",
      "Evaluated 1839/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.91578483581543\n",
      "caption a woman standing on a stage giving a speech\n",
      "Evaluated 1840/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.5316104888916\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1841/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.989274978637695\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1842/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.341291427612305\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1843/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.39493942260742\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1844/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.651498794555664\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1845/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.337900161743164\n",
      "caption a woman in a red dress talking on a stage\n",
      "Evaluated 1846/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.078216552734375\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1847/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.650407791137695\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1848/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.99468994140625\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1849/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.1695556640625\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1850/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.325363159179688\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1851/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.47128677368164\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1852/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.319908142089844\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1853/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.09033966064453\n",
      "caption a woman in a red shirt standing on a stage\n",
      "Evaluated 1854/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.633712768554688\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1855/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.559762954711914\n",
      "caption a woman in a red shirt standing in front of a screen\n",
      "Evaluated 1856/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.960079193115234\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1857/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.368562698364258\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1858/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.89972686767578\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1859/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.56704330444336\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1860/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.054122924804688\n",
      "caption a black background with red text on it\n",
      "Evaluated 1861/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.635560989379883\n",
      "caption a black background with red text on it\n",
      "Evaluated 1862/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.99060821533203\n",
      "caption a woman in a red shirt standing in front of a screen\n",
      "Evaluated 1863/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.080787658691406\n",
      "caption a woman standing on a stage giving a presentation\n",
      "Evaluated 1864/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.086917877197266\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1865/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.857994079589844\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1866/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.710844039916992\n",
      "caption a woman standing on a stage giving a speech\n",
      "Evaluated 1867/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.912057876586914\n",
      "caption a woman in a red shirt standing on a stage\n",
      "Evaluated 1868/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.30823516845703\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1869/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.212017059326172\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1870/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.610626220703125\n",
      "caption a man in a blue shirt sitting in a crowd of people\n",
      "Evaluated 1871/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.398778915405273\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1872/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.31206703186035\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1873/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.588953018188477\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1874/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.165006637573242\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1875/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.51670265197754\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1876/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.743253707885742\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1877/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.315439224243164\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1878/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.241374969482422\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1879/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.213533401489258\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1880/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.69193458557129\n",
      "caption a group of people sitting in a dark room\n",
      "Evaluated 1881/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.860305786132812\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1882/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.093076705932617\n",
      "caption a woman standing on a stage with her hands in the air\n",
      "Evaluated 1883/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.60194396972656\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1884/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.151538848876953\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1885/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.936172485351562\n",
      "caption a woman in a red shirt standing in front of a screen\n",
      "Evaluated 1886/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.85658836364746\n",
      "caption a woman in a red shirt standing in front of a screen\n",
      "Evaluated 1887/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.71513557434082\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1888/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.1036376953125\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1889/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.87599182128906\n",
      "caption a woman standing on a stage in front of a tedx sign\n",
      "Evaluated 1890/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.48636817932129\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1891/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.250974655151367\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1892/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.516456604003906\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1893/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.33917236328125\n",
      "caption a woman standing in front of a large screen\n",
      "Evaluated 1894/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.200658798217773\n",
      "caption a woman in a red shirt standing on a stage\n",
      "Evaluated 1895/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.559505462646484\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1896/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.343236923217773\n",
      "caption a woman standing on a stage in front of a crowd\n",
      "Evaluated 1897/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.523483276367188\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1898/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.987756729125977\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1899/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.186115264892578\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1900/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.543495178222656\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1901/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.20698356628418\n",
      "caption a woman in a red shirt talking on a stage\n",
      "Evaluated 1902/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.788347244262695\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 1903/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.434682846069336\n",
      "caption a man sitting at a table with a microphone\n",
      "Evaluated 1904/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.935514450073242\n",
      "caption a man in a suit and tie standing at a desk\n",
      "Evaluated 1905/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.990049362182617\n",
      "caption a group of men standing next to each other on a soccer field\n",
      "Evaluated 1906/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.409082412719727\n",
      "caption a man sitting at a press conference with a soccer ball in front of him\n",
      "Evaluated 1907/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.056848526000977\n",
      "caption a group of people playing soccer on a field\n",
      "Evaluated 1908/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.990388870239258\n",
      "caption a man in a blue shirt talking into a microphone\n",
      "Evaluated 1909/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.190820693969727\n",
      "caption a man with a beard sitting in front of a microphone\n",
      "Evaluated 1910/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.147783279418945\n",
      "caption a man sitting in front of a microphone with a soccer ball\n",
      "Evaluated 1911/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.88147735595703\n",
      "caption a man standing in front of a soccer ball\n",
      "Evaluated 1912/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.0762882232666\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 1913/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.875732421875\n",
      "caption a group of people playing soccer on a field\n",
      "Evaluated 1914/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.912931442260742\n",
      "caption a man with a microphone in front of a soccer ball\n",
      "Evaluated 1915/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.215557098388672\n",
      "caption a group of people playing soccer on a field\n",
      "Evaluated 1916/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.52364158630371\n",
      "caption a man with a beard sitting in front of a microphone\n",
      "Evaluated 1917/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.51630210876465\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 1918/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.33755111694336\n",
      "caption a group of people playing soccer on a field\n",
      "Evaluated 1919/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.34650421142578\n",
      "caption a group of men playing soccer on a field\n",
      "Evaluated 1920/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.557287216186523\n",
      "caption a man with a beard sitting in front of a microphone\n",
      "Evaluated 1921/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.929903030395508\n",
      "caption a man in a suit and tie sitting at a desk\n",
      "Evaluated 1922/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.987415313720703\n",
      "caption a group of people playing soccer on a field\n",
      "Evaluated 1923/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.182861328125\n",
      "caption a woman sitting in front of a slot machine\n",
      "Evaluated 1924/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.990337371826172\n",
      "caption a television screen with a picture of a slot machine\n",
      "Evaluated 1925/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.88568115234375\n",
      "caption a woman is interviewed by a news reporter in front of a casino\n",
      "Evaluated 1926/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.105815887451172\n",
      "caption a display case full of magazines on a counter\n",
      "Evaluated 1927/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.148542404174805\n",
      "caption a woman standing in front of a slot machine\n",
      "Evaluated 1928/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.46318817138672\n",
      "caption a woman standing in front of a man at a store\n",
      "Evaluated 1929/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.545001983642578\n",
      "caption a close up of a woman with blue nails\n",
      "Evaluated 1930/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.39699935913086\n",
      "caption a woman standing in front of a slot machine\n",
      "Evaluated 1931/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.122241973876953\n",
      "caption a man kissing a woman on the cheek in front of a desk\n",
      "Evaluated 1932/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.595563888549805\n",
      "caption a woman playing a slot machine in a casino\n",
      "Evaluated 1933/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.684762954711914\n",
      "caption two women standing in front of a television screen\n",
      "Evaluated 1934/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.13042640686035\n",
      "caption a woman in a blue shirt talking to a reporter\n",
      "Evaluated 1935/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.355222702026367\n",
      "caption a person opening a bag of cheetos\n",
      "Evaluated 1936/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.003662109375\n",
      "caption two women playing slot machines in a casino\n",
      "Evaluated 1937/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.086244583129883\n",
      "caption two women standing at the counter of a store\n",
      "Evaluated 1938/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.92535972595215\n",
      "caption a computer screen with a calendar on it\n",
      "Evaluated 1939/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.52042770385742\n",
      "caption a woman playing a slot machine in a casino\n",
      "Evaluated 1940/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.52042770385742\n",
      "caption a woman playing a slot machine in a casino\n",
      "Evaluated 1941/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.111713409423828\n",
      "caption a television screen with a slot machine on it\n",
      "Evaluated 1942/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.15622901916504\n",
      "caption a television screen with a calendar on it\n",
      "Evaluated 1943/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.43126678466797\n",
      "caption a man wearing glasses and a plaid shirt\n",
      "Evaluated 1944/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.204565048217773\n",
      "caption a group of people playing slot machines in a casino\n",
      "Evaluated 1945/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.80173683166504\n",
      "caption a man and a woman standing in an office\n",
      "Evaluated 1946/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.735275268554688\n",
      "caption a close up of a person typing on a keyboard\n",
      "Evaluated 1947/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.249509811401367\n",
      "caption two women standing next to each other on a news set\n",
      "Evaluated 1948/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.09898376464844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a woman playing a slot machine in a casino\n",
      "Evaluated 1949/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.63519287109375\n",
      "caption two women standing next to each other in front of a tv screen\n",
      "Evaluated 1950/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.35968017578125\n",
      "caption a slot machine with seven winning numbers on it\n",
      "Evaluated 1951/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.518577575683594\n",
      "caption a man wearing glasses and a plaid shirt\n",
      "Evaluated 1952/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.27812194824219\n",
      "caption a woman looking at a slot machine in a casino\n",
      "Evaluated 1953/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.976919174194336\n",
      "caption a man and a woman standing next to a young boy\n",
      "Evaluated 1954/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.11946678161621\n",
      "caption two women standing in front of a television screen\n",
      "Evaluated 1955/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.31166648864746\n",
      "caption a glass display case filled with magazines\n",
      "Evaluated 1956/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.39699935913086\n",
      "caption a woman standing in front of a slot machine\n",
      "Evaluated 1957/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.88568115234375\n",
      "caption a woman is interviewed by a news reporter in front of a casino\n",
      "Evaluated 1958/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.809350967407227\n",
      "caption a man wearing glasses and a plaid shirt\n",
      "Evaluated 1959/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.618080139160156\n",
      "caption a woman in a store looking at candy\n",
      "Evaluated 1960/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.88568115234375\n",
      "caption a woman is interviewed by a news reporter in front of a casino\n",
      "Evaluated 1961/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.0435733795166\n",
      "caption two women standing at the counter of a store\n",
      "Evaluated 1962/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.148542404174805\n",
      "caption a woman standing in front of a slot machine\n",
      "Evaluated 1963/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.32499885559082\n",
      "caption a woman in a leopard print shirt is looking at her phone\n",
      "Evaluated 1964/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.111713409423828\n",
      "caption a television screen with a slot machine on it\n",
      "Evaluated 1965/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.435773849487305\n",
      "caption a calendar with numbers on it\n",
      "Evaluated 1966/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.0682430267334\n",
      "caption a group of people playing slot machines in a casino\n",
      "Evaluated 1967/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a close up of a person's hand on a laptop\n",
      "Evaluated 1968/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.98627281188965\n",
      "caption a woman playing a slot machine at a casino\n",
      "Evaluated 1969/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.003662109375\n",
      "caption two women playing slot machines in a casino\n",
      "Evaluated 1970/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.777639389038086\n",
      "caption a man and a woman standing next to a young boy\n",
      "Evaluated 1971/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.619873046875\n",
      "caption two women playing slot machines in a casino\n",
      "Evaluated 1972/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.46318817138672\n",
      "caption a woman standing in front of a man at a store\n",
      "Evaluated 1973/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.029495239257812\n",
      "caption a woman is touching a button on a stove\n",
      "Evaluated 1974/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.77713394165039\n",
      "caption a woman in a blue dress talking to a woman in a red dress\n",
      "Evaluated 1975/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.6221981048584\n",
      "caption a person with a ring touching a stove top\n",
      "Evaluated 1976/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.42839241027832\n",
      "caption two women standing in front of a television screen\n",
      "Evaluated 1977/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.945009231567383\n",
      "caption a red and black slot machine in a casino\n",
      "Evaluated 1978/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.794158935546875\n",
      "caption a television screen with a slot machine on it\n",
      "Evaluated 1979/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.11946678161621\n",
      "caption two women standing in front of a television screen\n",
      "Evaluated 1980/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.777639389038086\n",
      "caption a man and a woman standing next to a young boy\n",
      "Evaluated 1981/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.016586303710938\n",
      "caption a woman standing in front of a slot machine\n",
      "Evaluated 1982/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.865739822387695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a woman in a leopard print shirt looking at her cell phone\n",
      "Evaluated 1983/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.29813575744629\n",
      "caption a woman standing in front of a slot machine\n",
      "Evaluated 1984/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.0682430267334\n",
      "caption a group of people playing slot machines in a casino\n",
      "Evaluated 1985/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  35.484619140625\n",
      "caption a slot machine is shown on the news\n",
      "Evaluated 1986/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.435773849487305\n",
      "caption a calendar with numbers on it\n",
      "Evaluated 1987/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.0682430267334\n",
      "caption a group of people playing slot machines in a casino\n",
      "Evaluated 1988/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.347030639648438\n",
      "caption a man and a woman sitting in front of a slot machine\n",
      "Evaluated 1989/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.894428253173828\n",
      "caption a woman standing in front of a slot machine\n",
      "Evaluated 1990/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.59143829345703\n",
      "caption a computer screen displaying a news article\n",
      "Evaluated 1991/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.251285552978516\n",
      "caption a man and a woman standing next to a young boy\n",
      "Evaluated 1992/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.543546676635742\n",
      "caption a television screen with a slot machine on it\n",
      "Evaluated 1993/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.16444969177246\n",
      "caption a television screen showing a slot machine\n",
      "Evaluated 1994/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.618080139160156\n",
      "caption a woman in a store looking at candy\n",
      "Evaluated 1995/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.87569236755371\n",
      "caption a woman sitting at a slot machine in a casino\n",
      "Evaluated 1996/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.52375411987305\n",
      "caption a woman talking to a reporter in a store\n",
      "Evaluated 1997/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.27812194824219\n",
      "caption a woman looking at a slot machine in a casino\n",
      "Evaluated 1998/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.541976928710938\n",
      "caption a woman playing a slot machine in a casino\n",
      "Evaluated 1999/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.513525009155273\n",
      "caption a man wearing glasses and a plaid shirt\n",
      "Evaluated 2000/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.6221981048584\n",
      "caption a person with a ring touching a stove top\n",
      "Evaluated 2001/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.910690307617188\n",
      "caption a close up of a person touching a stove top\n",
      "Evaluated 2002/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.83548355102539\n",
      "caption two women standing in front of a now tampa bay sign\n",
      "Evaluated 2003/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.584463119506836\n",
      "caption a woman standing in front of a slot machine\n",
      "Evaluated 2004/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.86599349975586\n",
      "caption two women standing in front of a television screen\n",
      "Evaluated 2005/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.3297004699707\n",
      "caption a woman sitting in front of a slot machine\n",
      "Evaluated 2006/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.945009231567383\n",
      "caption a red and black slot machine in a casino\n",
      "Evaluated 2007/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.556127548217773\n",
      "caption a man and woman kissing in an office\n",
      "Evaluated 2008/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.347030639648438\n",
      "caption a man and a woman sitting in front of a slot machine\n",
      "Evaluated 2009/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.56326675415039\n",
      "caption a woman in a store talking to a reporter\n",
      "Evaluated 2010/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.204565048217773\n",
      "caption a group of people playing slot machines in a casino\n",
      "Evaluated 2011/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.0682430267334\n",
      "caption a group of people playing slot machines in a casino\n",
      "Evaluated 2012/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.387718200683594\n",
      "caption a woman playing a slot machine in a casino\n",
      "Evaluated 2013/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.347030639648438\n",
      "caption a man and a woman sitting in front of a slot machine\n",
      "Evaluated 2014/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.32233428955078\n",
      "caption two women standing in front of a calendar\n",
      "Evaluated 2015/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.59143829345703\n",
      "caption a computer screen displaying a news article\n",
      "Evaluated 2016/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.52042770385742\n",
      "caption a woman playing a slot machine in a casino\n",
      "Evaluated 2017/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.122241973876953\n",
      "caption a man kissing a woman on the cheek in front of a desk\n",
      "Evaluated 2018/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  0.0\n",
      "caption a television screen showing a slot machine\n",
      "Evaluated 2019/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  35.484619140625\n",
      "caption a slot machine is shown on the news\n",
      "Evaluated 2020/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.16444969177246\n",
      "caption a television screen showing a slot machine\n",
      "Evaluated 2021/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.87569236755371\n",
      "caption a woman sitting at a slot machine in a casino\n",
      "Evaluated 2022/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.355222702026367\n",
      "caption a person opening a bag of cheetos\n",
      "Evaluated 2023/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.974437713623047\n",
      "caption a television screen showing a slot machine\n",
      "Evaluated 2024/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.122241973876953\n",
      "caption a man kissing a woman on the cheek in front of a desk\n",
      "Evaluated 2025/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  41.90430450439453\n",
      "caption a video of a slot machine with the words \"feeling lucky\" on it\n",
      "Evaluated 2026/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.80173683166504\n",
      "caption a man and a woman standing in an office\n",
      "Evaluated 2027/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.182861328125\n",
      "caption a woman sitting in front of a slot machine\n",
      "Evaluated 2028/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.12550163269043\n",
      "caption a man wearing glasses and a plaid shirt\n",
      "Evaluated 2029/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.249509811401367\n",
      "caption two women standing next to each other on a news set\n",
      "Evaluated 2030/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.76934051513672\n",
      "caption two women standing in front of a now tampa bay sign\n",
      "Evaluated 2031/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.707725524902344\n",
      "caption a close up of a person's hand on a laptop\n",
      "Evaluated 2032/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.35968017578125\n",
      "caption a slot machine with seven winning numbers on it\n",
      "Evaluated 2033/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.66884422302246\n",
      "caption a car is being worked on in a garage\n",
      "Evaluated 2034/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.104021072387695\n",
      "caption a bunch of wires and tools on the ground\n",
      "Evaluated 2035/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:05<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.692955017089844\n",
      "caption a blurry picture of a person's arm\n",
      "Evaluated 2036/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.41134262084961\n",
      "caption a close up of a hole in a metal object\n",
      "Evaluated 2037/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.245594024658203\n",
      "caption a dog standing next to a red car\n",
      "Evaluated 2038/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.03586769104004\n",
      "caption a close up of the front end of a car\n",
      "Evaluated 2039/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.814023971557617\n",
      "caption a person holding a small piece of metal in a plastic bag\n",
      "Evaluated 2040/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.408159255981445\n",
      "caption the side view of a red car with a hose attached to it\n",
      "Evaluated 2041/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.5548038482666\n",
      "caption a close up of the engine of a truck\n",
      "Evaluated 2042/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.84137535095215\n",
      "caption a person holding a cell phone up to their ear\n",
      "Evaluated 2043/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:06<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.783111572265625\n",
      "caption a room filled with tools and other items\n",
      "Evaluated 2044/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.67188262939453\n",
      "caption the back end of a red truck\n",
      "Evaluated 2045/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:08<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.976390838623047\n",
      "caption a hand is holding a piece of metal\n",
      "Evaluated 2046/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.13885498046875\n",
      "caption a motorcycle is being worked on by a mechanic\n",
      "Evaluated 2047/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.521190643310547\n",
      "caption a red car with a broken bumper on the side of the road\n",
      "Evaluated 2048/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.50571060180664\n",
      "caption a close up of a pair of scissors\n",
      "Evaluated 2049/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.9244384765625\n",
      "caption the front end of a red car is missing\n",
      "Evaluated 2050/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.063255310058594\n",
      "caption a red fire hydrant sitting next to some old tires\n",
      "Evaluated 2051/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.99003982543945\n",
      "caption the inside of a red truck that has been stripped\n",
      "Evaluated 2052/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.192733764648438\n",
      "caption a close up of a motorcycle that is on the ground\n",
      "Evaluated 2053/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.600845336914062\n",
      "caption a pile of luggage sitting on top of a table\n",
      "Evaluated 2054/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.13922882080078\n",
      "caption a truck that is being worked on in a garage\n",
      "Evaluated 2055/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:05<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.636484146118164\n",
      "caption a close up of a person working on a vehicle\n",
      "Evaluated 2056/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.33803939819336\n",
      "caption a vehicle that is being worked on in a garage\n",
      "Evaluated 2057/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.526531219482422\n",
      "caption a close up of a person holding a piece of metal\n",
      "Evaluated 2058/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.341522216796875\n",
      "caption a close up of a rusty metal object\n",
      "Evaluated 2059/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.153470993041992\n",
      "caption a truck is being worked on in a garage\n",
      "Evaluated 2060/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.50160026550293\n",
      "caption a person standing next to a motorcycle\n",
      "Evaluated 2061/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  19.53925895690918\n",
      "caption a fire hydrant sitting in front of a building\n",
      "Evaluated 2062/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.0745849609375\n",
      "caption a close up of a red truck with a chain on it\n",
      "Evaluated 2063/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.97700500488281\n",
      "caption a red car that has been stripped down to the frame\n",
      "Evaluated 2064/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.042028427124023\n",
      "caption a person holding a bag of something in their hand\n",
      "Evaluated 2065/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:05<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.89739990234375\n",
      "caption a pile of wires and electronics sitting on top of a pile of junk\n",
      "Evaluated 2066/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.949129104614258\n",
      "caption a person working on a rusty piece of metal\n",
      "Evaluated 2067/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.710872650146484\n",
      "caption a room with tools and a surfboard on the floor\n",
      "Evaluated 2068/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.30135154724121\n",
      "caption a red cooler sitting on top of a red truck\n",
      "Evaluated 2069/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.314088821411133\n",
      "caption a close up of a bunch of wires in a pile\n",
      "Evaluated 2070/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.970903396606445\n",
      "caption a close up of a person holding a wrench\n",
      "Evaluated 2071/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.968013763427734\n",
      "caption the front end of a red car has been damaged\n",
      "Evaluated 2072/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.001602172851562\n",
      "caption a broken down vehicle sitting in a garage\n",
      "Evaluated 2073/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.452861785888672\n",
      "caption a close up of a person holding a plastic bag\n",
      "Evaluated 2074/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.46566390991211\n",
      "caption a red truck with its front end missing\n",
      "Evaluated 2075/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.58171844482422\n",
      "caption a woman in a pink dress standing in a kitchen\n",
      "Evaluated 2076/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.258773803710938\n",
      "caption a muffin pan filled with muffins on a table\n",
      "Evaluated 2077/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.624208450317383\n",
      "caption a muffin tin on a wooden table\n",
      "Evaluated 2078/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.06549644470215\n",
      "caption a muffin pan and a paint brush next to each other\n",
      "Evaluated 2079/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.067537307739258\n",
      "caption a woman standing in a kitchen holding a large object\n",
      "Evaluated 2080/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.815059661865234\n",
      "caption an electric toothbrush sitting in a glass of milk\n",
      "Evaluated 2081/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.745737075805664\n",
      "caption a person taking a tray of cupcakes out of the oven\n",
      "Evaluated 2082/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.273818969726562\n",
      "caption a muffin tin filled with muffins on a counter\n",
      "Evaluated 2083/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.98630142211914\n",
      "caption a person pouring cream into a glass of milk\n",
      "Evaluated 2084/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.35248374938965\n",
      "caption a muffin tin filled with muffins on a counter\n",
      "Evaluated 2085/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.670743942260742\n",
      "caption a muffin tin filled with ingredients for an apple pie\n",
      "Evaluated 2086/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.82083511352539\n",
      "caption a tray of ingredients on a wooden table\n",
      "Evaluated 2087/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.76043701171875\n",
      "caption a woman in a pink dress holding a box in a kitchen\n",
      "Evaluated 2088/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.143983840942383\n",
      "caption a person holding a spatula over a glass of liquid\n",
      "Evaluated 2089/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.742326736450195\n",
      "caption a woman standing in a kitchen holding a plate\n",
      "Evaluated 2090/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.86794090270996\n",
      "caption a person placing a cupcake in a muffin tin\n",
      "Evaluated 2091/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.310455322265625\n",
      "caption a person cutting up apples on a cutting board\n",
      "Evaluated 2092/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.288572311401367\n",
      "caption a pan filled with food sitting on top of a stove\n",
      "Evaluated 2093/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.7874755859375\n",
      "caption a person cutting a piece of paper on a table\n",
      "Evaluated 2094/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.14977264404297\n",
      "caption a woman in a pink dress standing in a kitchen\n",
      "Evaluated 2095/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.05901336669922\n",
      "caption a woman holding a tray of muffins in a kitchen\n",
      "Evaluated 2096/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.526630401611328\n",
      "caption a woman holding a tray of apples in a kitchen\n",
      "Evaluated 2097/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.34437370300293\n",
      "caption a pastry on a blue and white plate next to a flower\n",
      "Evaluated 2098/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.165620803833008\n",
      "caption a person holding a glass over a piece of paper\n",
      "Evaluated 2099/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.52667999267578\n",
      "caption a person is peeling apples on a cutting board\n",
      "Evaluated 2100/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.20088195800781\n",
      "caption a person putting something in a muffin tin\n",
      "Evaluated 2101/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.584598541259766\n",
      "caption a bowl filled with sliced potatoes on a table\n",
      "Evaluated 2102/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.271352767944336\n",
      "caption a woman in a pink dress standing in a kitchen\n",
      "Evaluated 2103/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.519969940185547\n",
      "caption a person holding a piece of paper on a table\n",
      "Evaluated 2104/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.553539276123047\n",
      "caption a person putting something in a muffin tin\n",
      "Evaluated 2105/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.761632919311523\n",
      "caption a person is making a muffin in a muffin tin\n",
      "Evaluated 2106/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.396408081054688\n",
      "caption a woman holding a tray of apples in a kitchen\n",
      "Evaluated 2107/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.90816116333008\n",
      "caption a hand holding a blender on a counter top\n",
      "Evaluated 2108/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.25832748413086\n",
      "caption a person spooning something into a muffin tin\n",
      "Evaluated 2109/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.040498733520508\n",
      "caption two pieces of butter in a pan on a table\n",
      "Evaluated 2110/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.14240264892578\n",
      "caption a person pouring milk into a glass\n",
      "Evaluated 2111/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.292022705078125\n",
      "caption a man with no shirt standing in front of a wall\n",
      "Evaluated 2112/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.649620056152344\n",
      "caption two pictures of a girl making a peace sign\n",
      "Evaluated 2113/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.538280487060547\n",
      "caption a woman walking down a runway in front of a crowd of people\n",
      "Evaluated 2114/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.74955177307129\n",
      "caption a man in a white robe holding a tennis racket\n",
      "Evaluated 2115/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.859111785888672\n",
      "caption a man with a beard and a woman with a microphone\n",
      "Evaluated 2116/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.919885635375977\n",
      "caption a group of people taking pictures of a man\n",
      "Evaluated 2117/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.21337890625\n",
      "caption a man taking a picture of a woman\n",
      "Evaluated 2118/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.619007110595703\n",
      "caption a model walks down a runway in front of a crowd\n",
      "Evaluated 2119/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.769088745117188\n",
      "caption a man wearing a hat in a locker room\n",
      "Evaluated 2120/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.9288330078125\n",
      "caption a woman in a gold dress standing next to a camera\n",
      "Evaluated 2121/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.67013168334961\n",
      "caption a man and two women posing for a picture\n",
      "Evaluated 2122/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.614660263061523\n",
      "caption a young woman with curly hair holding a microphone\n",
      "Evaluated 2123/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.511335372924805\n",
      "caption a man taking a picture of a woman's face\n",
      "Evaluated 2124/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.652267456054688\n",
      "caption a man wearing a hat in a locker room\n",
      "Evaluated 2125/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.349945068359375\n",
      "caption a close up of a model making a cake\n",
      "Evaluated 2126/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.979890823364258\n",
      "caption a man with a beard and a woman with blonde hair\n",
      "Evaluated 2127/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.511335372924805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a man taking a picture of a woman's face\n",
      "Evaluated 2128/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.151025772094727\n",
      "caption a man wearing a hat in a locker room\n",
      "Evaluated 2129/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.981279373168945\n",
      "caption a man wearing a hat in a locker room\n",
      "Evaluated 2130/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.937725067138672\n",
      "caption a man in a suit standing in front of a tv\n",
      "Evaluated 2131/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.74955177307129\n",
      "caption a man in a white robe holding a tennis racket\n",
      "Evaluated 2132/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.038593292236328\n",
      "caption a picture of a computer screen with text on it\n",
      "Evaluated 2133/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.01388168334961\n",
      "caption a man taking a picture of a woman\n",
      "Evaluated 2134/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.575101852416992\n",
      "caption a man in a suit standing in front of a tv\n",
      "Evaluated 2135/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.18367576599121\n",
      "caption a man standing in front of a television screen\n",
      "Evaluated 2136/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.841415405273438\n",
      "caption a woman in a white dress standing on a red carpet\n",
      "Evaluated 2137/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.357080459594727\n",
      "caption a close up of a young man with a microphone\n",
      "Evaluated 2138/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.69190788269043\n",
      "caption a man in a tuxedo talking to another man in a tuxedo\n",
      "Evaluated 2139/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.378265380859375\n",
      "caption a woman holding up her hand in front of a mirror\n",
      "Evaluated 2140/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.485931396484375\n",
      "caption a man in a white shirt is walking down the runway\n",
      "Evaluated 2141/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.457916259765625\n",
      "caption a group of models walking down a runway\n",
      "Evaluated 2142/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.2637882232666\n",
      "caption a large billboard on the side of a building\n",
      "Evaluated 2143/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.96609115600586\n",
      "caption a man in a suit standing in front of a tv screen\n",
      "Evaluated 2144/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.578828811645508\n",
      "caption a woman on a runway with her hands on her hips\n",
      "Evaluated 2145/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.47470474243164\n",
      "caption a man in a white shirt walking down a runway\n",
      "Evaluated 2146/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.606155395507812\n",
      "caption a man wearing a hat in a locker room\n",
      "Evaluated 2147/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.169910430908203\n",
      "caption a picture of a person in a dark room\n",
      "Evaluated 2148/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.10658073425293\n",
      "caption a woman with blonde hair is smiling\n",
      "Evaluated 2149/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.516836166381836\n",
      "caption a man singing into a microphone on stage\n",
      "Evaluated 2150/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.772729873657227\n",
      "caption a woman in a black robe holding a tablet\n",
      "Evaluated 2151/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.357139587402344\n",
      "caption three women talking to each other in a room\n",
      "Evaluated 2152/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.617795944213867\n",
      "caption a man in a suit standing in front of a tv\n",
      "Evaluated 2153/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.452817916870117\n",
      "caption a model wearing a colorful fur coat on a runway\n",
      "Evaluated 2154/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.71171760559082\n",
      "caption a woman in a black dress standing on a runway\n",
      "Evaluated 2155/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.776790618896484\n",
      "caption a man in a suit standing in front of a tv screen\n",
      "Evaluated 2156/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.666099548339844\n",
      "caption a man walking down a runway in front of a crowd\n",
      "Evaluated 2157/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.728551864624023\n",
      "caption a picture of a television screen with a person in front of it\n",
      "Evaluated 2158/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.29888343811035\n",
      "caption a group of people posing for a picture\n",
      "Evaluated 2159/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.772729873657227\n",
      "caption a woman in a black robe holding a tablet\n",
      "Evaluated 2160/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.305768966674805\n",
      "caption two women are standing next to each other\n",
      "Evaluated 2161/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.433427810668945\n",
      "caption a woman in lingerie standing on a runway\n",
      "Evaluated 2162/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.54474449157715\n",
      "caption a man in a suit standing in front of a tv screen\n",
      "Evaluated 2163/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.9805908203125\n",
      "caption a woman in a black jacket standing next to a man in a suit\n",
      "Evaluated 2164/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.47470474243164\n",
      "caption a man in a white shirt walking down a runway\n",
      "Evaluated 2165/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.70840072631836\n",
      "caption a man and a woman looking at a cell phone\n",
      "Evaluated 2166/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.46691131591797\n",
      "caption a man wearing a hat in a locker room\n",
      "Evaluated 2167/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.52435874938965\n",
      "caption a man and a woman are talking to each other\n",
      "Evaluated 2168/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.5800724029541\n",
      "caption a black and white picture of a cat with false eyelashes and a rhinestone\n",
      "Evaluated 2169/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.914772033691406\n",
      "caption a picture of a cell phone with the words \"prime your kids\" on it\n",
      "Evaluated 2170/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.14999008178711\n",
      "caption a woman's face is made to look like an animal\n",
      "Evaluated 2171/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.120731353759766\n",
      "caption a woman with gold and black makeup on her eye\n",
      "Evaluated 2172/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.485204696655273\n",
      "caption a black and white picture with text on it\n",
      "Evaluated 2173/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.091909408569336\n",
      "caption a woman putting makeup on her eye with a brush\n",
      "Evaluated 2174/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.113555908203125\n",
      "caption a woman holding a makeup product in front of her face\n",
      "Evaluated 2175/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.35271453857422\n",
      "caption a woman with a black top and purple makeup\n",
      "Evaluated 2176/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.043548583984375\n",
      "caption a close up of a woman wearing a scarf\n",
      "Evaluated 2177/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.165817260742188\n",
      "caption a close up of a woman with blue eyes\n",
      "Evaluated 2178/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.87555503845215\n",
      "caption a black and white picture of a cell phone with the word \"eyeliners\" on it\n",
      "Evaluated 2179/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.28142547607422\n",
      "caption a woman's eye with purple and black makeup\n",
      "Evaluated 2180/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.443918228149414\n",
      "caption a woman with purple and gold makeup on her face\n",
      "Evaluated 2181/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.02230453491211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a hand clicking on a subscribe button on a black background\n",
      "Evaluated 2182/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.85657501220703\n",
      "caption a hand pressing a button that says subscribe\n",
      "Evaluated 2183/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.18556785583496\n",
      "caption a woman with purple makeup on her face\n",
      "Evaluated 2184/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.25806999206543\n",
      "caption a close up of a woman with blue eyes\n",
      "Evaluated 2185/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.981475830078125\n",
      "caption a woman is using a marker to draw on her eye\n",
      "Evaluated 2186/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.861278533935547\n",
      "caption a woman using a brush to apply makeup to her eye\n",
      "Evaluated 2187/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.008811950683594\n",
      "caption a woman with purple and gold makeup on her face\n",
      "Evaluated 2188/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.39226531982422\n",
      "caption a woman with gold and purple makeup on her eyes\n",
      "Evaluated 2189/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.518295288085938\n",
      "caption a woman putting makeup on her eye\n",
      "Evaluated 2190/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.79556655883789\n",
      "caption a black and white picture of a cat\n",
      "Evaluated 2191/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.650888442993164\n",
      "caption a black and white picture of a black and white cat with the word \"eyeliners\" on it\n",
      "Evaluated 2192/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.532400131225586\n",
      "caption a black and white picture with the words soft pink lips\n",
      "Evaluated 2193/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.443403244018555\n",
      "caption a picture of a clock with the words \"eyeshadows  pigments\"\n",
      "Evaluated 2194/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.037158966064453\n",
      "caption a woman putting pink powder on her face\n",
      "Evaluated 2195/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.84012222290039\n",
      "caption a woman holding a container of eye shadow\n",
      "Evaluated 2196/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.54721450805664\n",
      "caption a black and white photo with text on it\n",
      "Evaluated 2197/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.674108505249023\n",
      "caption a woman holding a marker to her eye\n",
      "Evaluated 2198/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.21833419799805\n",
      "caption a woman putting mascara on her eye\n",
      "Evaluated 2199/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  5.46855354309082\n",
      "caption a black and white photo of a man playing a guitar\n",
      "Evaluated 2200/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  36.249053955078125\n",
      "caption a black and white photo with text that says \"colorful arabic look\"\n",
      "Evaluated 2201/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.08873176574707\n",
      "caption a woman applying makeup with a pair of scissors\n",
      "Evaluated 2202/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  35.31728744506836\n",
      "caption a woman with gold and purple makeup on her eye\n",
      "Evaluated 2203/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.34375762939453\n",
      "caption a womans eye with purple and black makeup\n",
      "Evaluated 2204/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.874826431274414\n",
      "caption a picture of a clock with the words \"eyeshadows  pigments\"\n",
      "Evaluated 2205/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.894622802734375\n",
      "caption a woman using a brush to apply makeup to her eye\n",
      "Evaluated 2206/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.57018280029297\n",
      "caption a woman putting makeup on her nose\n",
      "Evaluated 2207/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.481882095336914\n",
      "caption a woman with gold and purple makeup on her face\n",
      "Evaluated 2208/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.782506942749023\n",
      "caption a close up of a woman's face with makeup\n",
      "Evaluated 2209/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.70981788635254\n",
      "caption a woman putting on eye shadow with a marker\n",
      "Evaluated 2210/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.595355987548828\n",
      "caption a woman applying makeup to her face with a brush\n",
      "Evaluated 2211/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.692983627319336\n",
      "caption a woman with purple and pink makeup on her face\n",
      "Evaluated 2212/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.213359832763672\n",
      "caption a woman with purple and gold makeup on her face\n",
      "Evaluated 2213/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.17245101928711\n",
      "caption a black and white picture of a plane with the words colorful arabic look\n",
      "Evaluated 2214/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.591821670532227\n",
      "caption a woman brushing her teeth with a makeup brush\n",
      "Evaluated 2215/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.22602081298828\n",
      "caption a woman using a brush to apply makeup to her eyes\n",
      "Evaluated 2216/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.61677360534668\n",
      "caption a black and white photo with text that says \"soft pink cheeks\"\n",
      "Evaluated 2217/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.30948257446289\n",
      "caption a woman using a brush to apply makeup to her eyes\n",
      "Evaluated 2218/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.98739242553711\n",
      "caption a woman putting mascara on her eyelashes\n",
      "Evaluated 2219/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.485746383666992\n",
      "caption a woman holding a pair of scissors to her eye\n",
      "Evaluated 2220/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.869421005249023\n",
      "caption a woman with gold and silver makeup on her face\n",
      "Evaluated 2221/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.345033645629883\n",
      "caption a woman posing with her hand on her head\n",
      "Evaluated 2222/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.041141510009766\n",
      "caption a woman with purple and gold makeup on her face\n",
      "Evaluated 2223/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.80646514892578\n",
      "caption a woman with purple and gold makeup on her face\n",
      "Evaluated 2224/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.302783966064453\n",
      "caption a woman with purple and gold makeup on her face\n",
      "Evaluated 2225/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.770017623901367\n",
      "caption a woman applying makeup with a brush\n",
      "Evaluated 2226/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.113746643066406\n",
      "caption a woman holding a brush up to her eye\n",
      "Evaluated 2227/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.86140060424805\n",
      "caption a woman with gold and black makeup on her eyes\n",
      "Evaluated 2228/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.841054916381836\n",
      "caption a close up of a woman putting on makeup\n",
      "Evaluated 2229/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.953262329101562\n",
      "caption a woman with purple and gold makeup on her eyes\n",
      "Evaluated 2230/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  35.44267654418945\n",
      "caption a woman with gold and black makeup on her eye\n",
      "Evaluated 2231/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  35.81081008911133\n",
      "caption a woman using a brush to apply glitter to her eye\n",
      "Evaluated 2232/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.06304168701172\n",
      "caption a woman applying makeup with a brush\n",
      "Evaluated 2233/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.01521682739258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a black and white picture of a clock with the words \"soft pink checks\"\n",
      "Evaluated 2234/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.439044952392578\n",
      "caption a woman with makeup on holding a lighter\n",
      "Evaluated 2235/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.01048469543457\n",
      "caption a woman holding a pencil to her eye\n",
      "Evaluated 2236/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.36751937866211\n",
      "caption a woman holding a lipstick in her hand\n",
      "Evaluated 2237/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  9.027212142944336\n",
      "caption a black and white picture of a cat\n",
      "Evaluated 2238/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.63945770263672\n",
      "caption a hand clicking on a subscribe button on a black background\n",
      "Evaluated 2239/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.644071578979492\n",
      "caption four pictures of women with different hair colors\n",
      "Evaluated 2240/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.35242462158203\n",
      "caption a close up of a person holding a pair of scissors\n",
      "Evaluated 2241/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.635427474975586\n",
      "caption a close up of a woman's hands and nails\n",
      "Evaluated 2242/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  34.03858947753906\n",
      "caption a person holding a match to their nail\n",
      "Evaluated 2243/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.050256729125977\n",
      "caption a close up of a person holding a toothbrush\n",
      "Evaluated 2244/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.651586532592773\n",
      "caption a person holding a container of nail polish\n",
      "Evaluated 2245/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.618610382080078\n",
      "caption a close up of a woman with long fingernails\n",
      "Evaluated 2246/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.366666793823242\n",
      "caption a close up of a person holding a cell phone\n",
      "Evaluated 2247/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.541824340820312\n",
      "caption a close up of a woman with long fingernails\n",
      "Evaluated 2248/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.747150421142578\n",
      "caption a close up of a person holding a gold nail\n",
      "Evaluated 2249/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.90235137939453\n",
      "caption a person holding a pair of scissors in their hand\n",
      "Evaluated 2250/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.00023078918457\n",
      "caption a woman is putting on her nails\n",
      "Evaluated 2251/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.170730590820312\n",
      "caption a woman holding a pair of scissors in her hand\n",
      "Evaluated 2252/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.51401710510254\n",
      "caption a close up of a womans hand with some nails on it\n",
      "Evaluated 2253/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.12274169921875\n",
      "caption a close up of a woman holding a brush\n",
      "Evaluated 2254/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.567501068115234\n",
      "caption a person cutting a piece of paper with a pair of scissors\n",
      "Evaluated 2255/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.31494903564453\n",
      "caption a person holding a brush over a nail\n",
      "Evaluated 2256/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.572404861450195\n",
      "caption a woman holding a pair of scissors to her finger\n",
      "Evaluated 2257/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.874826431274414\n",
      "caption a close up of a person with long fingernails\n",
      "Evaluated 2258/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.186429977416992\n",
      "caption a close up of a fingernail on a cell phone\n",
      "Evaluated 2259/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.661537170410156\n",
      "caption a woman holding a pair of scissors up to her face\n",
      "Evaluated 2260/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.304384231567383\n",
      "caption a close up of a person holding up a nail\n",
      "Evaluated 2261/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:04<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.38256072998047\n",
      "caption a person cutting a piece of paper with a pair of scissors\n",
      "Evaluated 2262/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:05<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.339115142822266\n",
      "caption a close up of a woman's fingernails\n",
      "Evaluated 2263/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.069196701049805\n",
      "caption a person holding a pair of scissors to their nails\n",
      "Evaluated 2264/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.16823959350586\n",
      "caption a close up of a womans nails with gold and glitter\n",
      "Evaluated 2265/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.911291122436523\n",
      "caption a close up of a woman's hand holding a toothbrush\n",
      "Evaluated 2266/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.159313201904297\n",
      "caption a person that is doing something to their nails\n",
      "Evaluated 2267/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.43071937561035\n",
      "caption a group of women sitting around a table\n",
      "Evaluated 2268/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.688217163085938\n",
      "caption a group of people sitting at a table\n",
      "Evaluated 2269/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.556777954101562\n",
      "caption a woman in a red dress sitting at a table\n",
      "Evaluated 2270/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.912580490112305\n",
      "caption a group of people sitting at a table\n",
      "Evaluated 2271/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.462398529052734\n",
      "caption a woman is holding a box of a romantic massage candle\n",
      "Evaluated 2272/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.617586135864258\n",
      "caption a group of people sitting at a table\n",
      "Evaluated 2273/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.427339553833008\n",
      "caption a group of women sitting at a table\n",
      "Evaluated 2274/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.487611770629883\n",
      "caption a table topped with a variety of beauty products\n",
      "Evaluated 2275/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.082500457763672\n",
      "caption three women sitting at a table with a bunch of stuff on it\n",
      "Evaluated 2276/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.86275863647461\n",
      "caption a woman is holding a necklace with pearls on it\n",
      "Evaluated 2277/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.379878997802734\n",
      "caption a person is holding up a perfume box\n",
      "Evaluated 2278/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.693580627441406\n",
      "caption a person holding up three packets of face masks\n",
      "Evaluated 2279/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.72840690612793\n",
      "caption a woman in a red dress sitting at a table\n",
      "Evaluated 2280/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.403444290161133\n",
      "caption a group of women sitting at a table\n",
      "Evaluated 2281/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.746530532836914\n",
      "caption a woman holding up a valentine's day card\n",
      "Evaluated 2282/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.013713836669922\n",
      "caption a woman holding a valentine's day gift in front of her face\n",
      "Evaluated 2283/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.500154495239258\n",
      "caption a person holding up a bag of chocolate treats\n",
      "Evaluated 2284/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.891265869140625\n",
      "caption a couple of coffee mugs with faces painted on them\n",
      "Evaluated 2285/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.00948143005371\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2286/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.184179306030273\n",
      "caption three women sitting at a table with gifts\n",
      "Evaluated 2287/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.485580444335938\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2288/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.516246795654297\n",
      "caption a couple of coffee mugs sitting on a table\n",
      "Evaluated 2289/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.225425720214844\n",
      "caption a couple of coffee mugs sitting on a table\n",
      "Evaluated 2290/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.767606735229492\n",
      "caption a group of women sitting around a table\n",
      "Evaluated 2291/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.801977157592773\n",
      "caption a close up of a woman with a wine glass\n",
      "Evaluated 2292/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.529817581176758\n",
      "caption a group of women sitting at a table with valentine's day gifts\n",
      "Evaluated 2293/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.720172882080078\n",
      "caption a woman holding up a book of fragrances\n",
      "Evaluated 2294/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.106821060180664\n",
      "caption a woman holding a jar with a face on it\n",
      "Evaluated 2295/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.973487854003906\n",
      "caption a group of people sitting at a table\n",
      "Evaluated 2296/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.258262634277344\n",
      "caption a woman is laughing while sitting next to another woman\n",
      "Evaluated 2297/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.872800827026367\n",
      "caption a woman sitting at a table with a plate of food\n",
      "Evaluated 2298/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.393814086914062\n",
      "caption a woman sitting at a table with a plate of food\n",
      "Evaluated 2299/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  38.99630355834961\n",
      "caption a woman is holding up a fragrance sampler\n",
      "Evaluated 2300/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.92660140991211\n",
      "caption a group of women sitting around a table\n",
      "Evaluated 2301/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.883426666259766\n",
      "caption a group of women sitting at a table\n",
      "Evaluated 2302/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.611167907714844\n",
      "caption a woman is holding a box of a romantic massage candle\n",
      "Evaluated 2303/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.14510154724121\n",
      "caption a group of people sitting at a table\n",
      "Evaluated 2304/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.241838455200195\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2305/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.173171997070312\n",
      "caption a person holding a package of lip balm\n",
      "Evaluated 2306/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.900455474853516\n",
      "caption a group of people sitting at a table\n",
      "Evaluated 2307/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.724679946899414\n",
      "caption a close up of a woman's hand reaching into a bag of products\n",
      "Evaluated 2308/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.780963897705078\n",
      "caption a person is holding up a card with roses on it\n",
      "Evaluated 2309/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.878870010375977\n",
      "caption a close up of a woman with a wine glass\n",
      "Evaluated 2310/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.568918228149414\n",
      "caption a woman sitting at a table holding a piece of paper\n",
      "Evaluated 2311/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.825075149536133\n",
      "caption a person holding up a box of jelly beans\n",
      "Evaluated 2312/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.972667694091797\n",
      "caption a woman holding a box of candy and a bag of chips\n",
      "Evaluated 2313/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  30.047286987304688\n",
      "caption a woman holding up a bottle of perfume\n",
      "Evaluated 2314/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.44187355041504\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2315/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.787254333496094\n",
      "caption a group of women sitting at a table\n",
      "Evaluated 2316/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.00948143005371\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2317/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.819807052612305\n",
      "caption two women and a man sitting at a table with a box of chocolates\n",
      "Evaluated 2318/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.74530029296875\n",
      "caption a woman in a red dress holding a box\n",
      "Evaluated 2319/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.004499435424805\n",
      "caption a woman in a red dress sitting at a table\n",
      "Evaluated 2320/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.744518280029297\n",
      "caption a woman is holding a package of lip balm\n",
      "Evaluated 2321/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.098594665527344\n",
      "caption a group of people sitting at a table\n",
      "Evaluated 2322/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.332143783569336\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2323/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.715606689453125\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2324/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.50187873840332\n",
      "caption a person is holding a card with roses on it\n",
      "Evaluated 2325/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  38.99630355834961\n",
      "caption a woman is holding up a fragrance sampler\n",
      "Evaluated 2326/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.072834014892578\n",
      "caption three women and a man sitting at a table\n",
      "Evaluated 2327/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.038436889648438\n",
      "caption a group of women sitting around a table\n",
      "Evaluated 2328/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.087875366210938\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2329/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.491445541381836\n",
      "caption two women and a man sitting at a table\n",
      "Evaluated 2330/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.58294105529785\n",
      "caption a woman holding a gift wrapped in a cup\n",
      "Evaluated 2331/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.523052215576172\n",
      "caption a person holding a bottle of wine\n",
      "Evaluated 2332/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.192174911499023\n",
      "caption a woman in a red dress sitting at a table\n",
      "Evaluated 2333/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.61407470703125\n",
      "caption a group of people sitting at a table\n",
      "Evaluated 2334/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.373836517333984\n",
      "caption two women and a man sitting at a table\n",
      "Evaluated 2335/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.80173683166504\n",
      "caption a group of people sitting next to each other\n",
      "Evaluated 2336/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.92975616455078\n",
      "caption a group of women sitting around a table\n",
      "Evaluated 2337/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.383453369140625\n",
      "caption a woman sitting at a table with a cake in front of her\n",
      "Evaluated 2338/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.521116256713867\n",
      "caption three women sitting at a table with gifts\n",
      "Evaluated 2339/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.09531021118164\n",
      "caption a woman holding up a bag of chocolate chips\n",
      "Evaluated 2340/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  33.588409423828125\n",
      "caption a person holding a candy box with hearts on it\n",
      "Evaluated 2341/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.905471801757812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption a close up of a woman's hand holding a bottle of lotion\n",
      "Evaluated 2342/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.30583953857422\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2343/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  28.332447052001953\n",
      "caption a person holding up three different face masks\n",
      "Evaluated 2344/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.541828155517578\n",
      "caption a woman in a red dress holding a piece of paper\n",
      "Evaluated 2345/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.076614379882812\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2346/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.359102249145508\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2347/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.35696029663086\n",
      "caption a woman in a red dress talking to someone\n",
      "Evaluated 2348/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.79075813293457\n",
      "caption a woman in a red dress sitting at a table\n",
      "Evaluated 2349/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.532981872558594\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2350/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.938159942626953\n",
      "caption a woman sitting at a table with a present in front of her\n",
      "Evaluated 2351/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.659690856933594\n",
      "caption a group of people sitting at a table\n",
      "Evaluated 2352/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.286344528198242\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2353/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.095191955566406\n",
      "caption a woman in a red dress on a tv show\n",
      "Evaluated 2354/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.153059005737305\n",
      "caption a group of people sitting at a table\n",
      "Evaluated 2355/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.551149368286133\n",
      "caption a group of people sitting around a table\n",
      "Evaluated 2356/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.568918228149414\n",
      "caption a woman sitting at a table holding a piece of paper\n",
      "Evaluated 2357/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.35258674621582\n",
      "caption a group of women sitting at a table\n",
      "Evaluated 2358/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.500154495239258\n",
      "caption a person holding up a bag of chocolate treats\n",
      "Evaluated 2359/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.529817581176758\n",
      "caption a group of women sitting at a table with valentine's day gifts\n",
      "Evaluated 2360/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.341773986816406\n",
      "caption two women and a man sitting at a table\n",
      "Evaluated 2361/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.73043441772461\n",
      "caption a couple of coffee mugs sitting on a table\n",
      "Evaluated 2362/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.342422485351562\n",
      "caption a group of people sitting at a table\n",
      "Evaluated 2363/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.91451644897461\n",
      "caption a woman in a red dress sitting at a table\n",
      "Evaluated 2364/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  27.955928802490234\n",
      "caption a woman holding a gift wrapped in a cup\n",
      "Evaluated 2365/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.491445541381836\n",
      "caption two women and a man sitting at a table\n",
      "Evaluated 2366/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  32.52057647705078\n",
      "caption a woman holding a valentine's day gift wrapped in a heart shape\n",
      "Evaluated 2367/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.100894927978516\n",
      "caption a woman making a peace sign in front of a brick wall\n",
      "Evaluated 2368/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.587263107299805\n",
      "caption a woman standing in front of a brick wall\n",
      "Evaluated 2369/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.34916114807129\n",
      "caption a bunch of pillows sitting on top of each other\n",
      "Evaluated 2370/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.12126350402832\n",
      "caption a woman standing in front of a brick wall\n",
      "Evaluated 2371/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  23.18683624267578\n",
      "caption a woman in a room with a brick wall\n",
      "Evaluated 2372/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.38106346130371\n",
      "caption a bunch of pillows on a bed next to a brick wall\n",
      "Evaluated 2373/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  31.298486709594727\n",
      "caption a sign on a brick wall that says herbs\n",
      "Evaluated 2374/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.864582061767578\n",
      "caption a bunch of pictures hanging on a wall\n",
      "Evaluated 2375/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.780174255371094\n",
      "caption a woman brushing her hair in front of a brick wall\n",
      "Evaluated 2376/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  29.455577850341797\n",
      "caption a bed in a room with a brick wall\n",
      "Evaluated 2377/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.237905502319336\n",
      "caption a woman standing in front of a brick wall\n",
      "Evaluated 2378/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  20.980607986450195\n",
      "caption a woman holding up her hand in front of a brick wall\n",
      "Evaluated 2379/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  24.08008575439453\n",
      "caption a woman in a room with a brick wall\n",
      "Evaluated 2380/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.795412063598633\n",
      "caption a woman standing in front of a brick wall\n",
      "Evaluated 2381/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.83010482788086\n",
      "caption a woman standing in front of a brick wall\n",
      "Evaluated 2382/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.52930450439453\n",
      "caption a woman standing in front of a brick wall\n",
      "Evaluated 2383/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.517398834228516\n",
      "caption a woman standing in front of a brick wall\n",
      "Evaluated 2384/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  26.594762802124023\n",
      "caption a tv mounted on the wall of a room\n",
      "Evaluated 2385/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  16.236547470092773\n",
      "caption a woman standing in front of a brick wall\n",
      "Evaluated 2386/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  21.617393493652344\n",
      "caption a woman holding a wii remote in front of a brick wall\n",
      "Evaluated 2387/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  36.26115798950195\n",
      "caption a kitchen and dining area in a rv\n",
      "Evaluated 2388/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.653528213500977\n",
      "caption a woman standing in front of a brick wall\n",
      "Evaluated 2389/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  25.908905029296875\n",
      "caption a person's hand is touching a pile of pillows\n",
      "Evaluated 2390/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  17.562973022460938\n",
      "caption a woman standing in front of a brick wall\n",
      "Evaluated 2391/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.245058059692383\n",
      "caption a woman making a funny face in front of a brick wall\n",
      "Evaluated 2392/2395\n",
      "Loading CLIP model: ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.059429168701172\n",
      "caption a woman standing in front of a brick wall\n",
      "Evaluated 2393/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  18.675914764404297\n",
      "caption a woman standing in front of a brick wall\n",
      "Evaluated 2394/2395\n",
      "Loading CLIP model: ViT-B/32\n",
      "Calculating CLIP Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:02<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Score:  22.978654861450195\n",
      "caption a woman in a room with a brick wall\n",
      "Evaluated 2395/2395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_all(paths_to_frames, paths_to_frames_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33db359-3735-4489-ae2f-52b6ca2a3c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b58147f8-52c7-4555-9705-980a5160f5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip</th>\n",
       "      <th>caption</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3LbkrnQKCR4/3LbkrnQKCR4.5_0.mp4</td>\n",
       "      <td>the cover of a japanese magazine with a pictur...</td>\n",
       "      <td>33.287979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3LbkrnQKCR4/3LbkrnQKCR4.16_0.mp4</td>\n",
       "      <td>the cover of a magazine with a picture of naruto</td>\n",
       "      <td>32.028347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3LbkrnQKCR4/3LbkrnQKCR4.18_0.mp4</td>\n",
       "      <td>the cover of a japanese magazine with a pictur...</td>\n",
       "      <td>33.306488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3LbkrnQKCR4/3LbkrnQKCR4.1_0.mp4</td>\n",
       "      <td>the cover of a japanese magazine with a pictur...</td>\n",
       "      <td>33.484428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3LbkrnQKCR4/3LbkrnQKCR4.12_0.mp4</td>\n",
       "      <td>the cover of a japanese magazine with a pictur...</td>\n",
       "      <td>33.272053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               clip  \\\n",
       "0   3LbkrnQKCR4/3LbkrnQKCR4.5_0.mp4   \n",
       "1  3LbkrnQKCR4/3LbkrnQKCR4.16_0.mp4   \n",
       "2  3LbkrnQKCR4/3LbkrnQKCR4.18_0.mp4   \n",
       "3   3LbkrnQKCR4/3LbkrnQKCR4.1_0.mp4   \n",
       "4  3LbkrnQKCR4/3LbkrnQKCR4.12_0.mp4   \n",
       "\n",
       "                                             caption      score  \n",
       "0  the cover of a japanese magazine with a pictur...  33.287979  \n",
       "1   the cover of a magazine with a picture of naruto  32.028347  \n",
       "2  the cover of a japanese magazine with a pictur...  33.306488  \n",
       "3  the cover of a japanese magazine with a pictur...  33.484428  \n",
       "4  the cover of a japanese magazine with a pictur...  33.272053  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccca6b5f-7f17-4c4a-9bca-37e9d92881ba",
   "metadata": {},
   "source": [
    "# 4.0 Analysis of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "104d9178-4549-4e35-b831-ea5b558c0bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.881071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.303415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.771573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.072531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.580940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.904305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             score\n",
       "count  2395.000000\n",
       "mean     26.881071\n",
       "std       4.303415\n",
       "min       0.000000\n",
       "25%      24.771573\n",
       "50%      27.072531\n",
       "75%      29.580940\n",
       "max      41.904305"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score of all clips\n",
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75950ae9-5c11-41f0-8fac-53dd94046f1d",
   "metadata": {},
   "source": [
    "### Note: we remove the data that has score = 0. Those videos are corrupted, we set the score to be 0 in the evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4bcf8550-b4b1-4bf6-923e-fe923e754828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2379.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.061860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.708024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.468554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.821177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.104818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.591973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.904305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             score\n",
       "count  2379.000000\n",
       "mean     27.061860\n",
       "std       3.708024\n",
       "min       5.468554\n",
       "25%      24.821177\n",
       "50%      27.104818\n",
       "75%      29.591973\n",
       "max      41.904305"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with 'score' equal to 0\n",
    "results_df = results_df[results_df['score'] >= 0.1]\n",
    "# Reset the index\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12f7f4bd-ea97-455d-b122-f719246d2b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip</th>\n",
       "      <th>caption</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3LbkrnQKCR4/3LbkrnQKCR4.5_0.mp4</td>\n",
       "      <td>the cover of a japanese magazine with a pictur...</td>\n",
       "      <td>33.287979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3LbkrnQKCR4/3LbkrnQKCR4.16_0.mp4</td>\n",
       "      <td>the cover of a magazine with a picture of naruto</td>\n",
       "      <td>32.028347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3LbkrnQKCR4/3LbkrnQKCR4.18_0.mp4</td>\n",
       "      <td>the cover of a japanese magazine with a pictur...</td>\n",
       "      <td>33.306488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3LbkrnQKCR4/3LbkrnQKCR4.1_0.mp4</td>\n",
       "      <td>the cover of a japanese magazine with a pictur...</td>\n",
       "      <td>33.484428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3LbkrnQKCR4/3LbkrnQKCR4.12_0.mp4</td>\n",
       "      <td>the cover of a japanese magazine with a pictur...</td>\n",
       "      <td>33.272053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               clip  \\\n",
       "0   3LbkrnQKCR4/3LbkrnQKCR4.5_0.mp4   \n",
       "1  3LbkrnQKCR4/3LbkrnQKCR4.16_0.mp4   \n",
       "2  3LbkrnQKCR4/3LbkrnQKCR4.18_0.mp4   \n",
       "3   3LbkrnQKCR4/3LbkrnQKCR4.1_0.mp4   \n",
       "4  3LbkrnQKCR4/3LbkrnQKCR4.12_0.mp4   \n",
       "\n",
       "                                             caption      score  \n",
       "0  the cover of a japanese magazine with a pictur...  33.287979  \n",
       "1   the cover of a magazine with a picture of naruto  32.028347  \n",
       "2  the cover of a japanese magazine with a pictur...  33.306488  \n",
       "3  the cover of a japanese magazine with a pictur...  33.484428  \n",
       "4  the cover of a japanese magazine with a pictur...  33.272053  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "076c5a47-0ff0-495a-8674-7efdbed030f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for simple data analysis\n",
    "\n",
    "# select the top 5% CLIP score clips \n",
    "# one video can have at most 10 clips to be selected as the top 5%\n",
    "def diversity_rank(results_df):\n",
    "    results_rank = results_df.sort_values(by='score', ascending=False)\n",
    "    \n",
    "    success_videos = {}\n",
    "    max_clip_per_video = 10\n",
    "    max_successor = len(results_df)//20 \n",
    "    # successor are the top 5% \n",
    "    successor = 0\n",
    "    successor_index = []\n",
    "    \n",
    "    # Loop through the DataFrame rows\n",
    "    for index, row in results_rank.iterrows():\n",
    "        video_origin = row['clip'].split(\"/\",1)[0]\n",
    "        \n",
    "        if successor >= max_successor:\n",
    "            break\n",
    "            \n",
    "        if video_origin in success_videos:\n",
    "            if success_videos[video_origin] < max_clip_per_video:\n",
    "                success_videos[video_origin] += 1\n",
    "                successor += 1\n",
    "                successor_index.append(index)\n",
    "                \n",
    "        else:\n",
    "            success_videos[video_origin] = 0\n",
    "            success_videos[video_origin] += 1\n",
    "            successor +=1\n",
    "            successor_index.append(index)\n",
    "             \n",
    "    print(\"success_video_origin: \", success_videos)\n",
    "    return successor_index\n",
    "\n",
    "# select the top 5% CLIP score clips (purely based on CLIP score)\n",
    "def normal_rank(results_df):\n",
    "    results_rank = results_df.sort_values(by='score', ascending=False)\n",
    "    n = len(results_df)//20  \n",
    "    # successor are the top 5% \n",
    "    return results_rank.index[:n]\n",
    "\n",
    "\n",
    "# plot the histogram of the score (based on the 'score' attribute in the dataframe)\n",
    "def plot_histogram(df):\n",
    "    # Convert 'score' column to numeric\n",
    "    df['score'] = pd.to_numeric(df['score'], errors='coerce')\n",
    "\n",
    "    # Remove rows with NaN values in 'score' column\n",
    "    df = df.dropna(subset=['score'])\n",
    "\n",
    "    # Plot histogram\n",
    "    sns.histplot(df['score'], bins=int(np.sqrt(len(df))), kde=True)\n",
    "\n",
    "    # Calculate mean, standard deviation, median, and 95th percentile\n",
    "    mean = np.mean(df['score'])\n",
    "    std_dev = np.std(df['score'])\n",
    "    median = np.median(df['score'])\n",
    "    percentile_95 = np.percentile(df['score'], 95)\n",
    "\n",
    "    # Add labels\n",
    "    plt.axvline(mean, color='red', linestyle='--', label=f'Mean: {mean:.2f}')\n",
    "    plt.axvline(mean + std_dev, color='green', linestyle='--', label=f'Standard Deviation: {std_dev:.2f}')\n",
    "    plt.axvline(median, color='purple', linestyle='--', label=f'Median: {median:.2f}')\n",
    "    plt.axvline(percentile_95, color='orange', linestyle='--', label=f'95th Percentile: {percentile_95:.2f}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "558ddeaf-e011-40f8-8f3e-504e8c9ab645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_video_origin:  {'1BMgKPeURxc': 10, '4Wno4d7RCag': 7, '3bO6hVtV1mE': 5, '3ntE0lNL5j8': 2, '0_nsWSNeHQs': 7, '3eCjDT0t52Y': 2, '4L1ryud2rhQ': 9, '4fb2THzyrT0': 1, '2jfO_1sH9Nk': 10, '0XGnU4ir5gs': 10, '0ctt78uct4Q': 4, '1plNsDN54kI': 2, '3KcWsnOQQsI': 10, '-bmS0RumV9U': 5, '3HjFIOo2-mQ': 10, '4y1Dzb-IJjM': 2, '4sLAa2cnfhQ': 2, '3LbkrnQKCR4': 10, '3skPQLfdIpo': 2, '4PnY2IUQ2Tg': 3, '3UHjEh8J8EI': 1, '2iUPQgewznM': 2, '4kymPBK-F3g': 1, '4ZiwuL0K7KU': 1}\n"
     ]
    }
   ],
   "source": [
    "result_rank = results_df.sort_values(by='score', ascending=False)\n",
    "result_rank_diversify = diversity_rank(results_df) \n",
    "result_rank_normal = normal_rank(results_df)\n",
    "\n",
    "# The success_video_origin is printed from the diversity_rank(), it shows that one video can have at most 10 clips to be selected as the top 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd83e0c-f9d2-4620-948a-307000ccaf34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b399ab-1132-4fc7-ab80-493c7ef160f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bff1065-8b4a-4149-9ae3-cb8d957ed73a",
   "metadata": {},
   "source": [
    "# 4.1 Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f60e0e6-cef0-40cb-a73d-bd17c26a09df",
   "metadata": {},
   "source": [
    "### Highest CLIP score clip-text pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3e12e133-3575-4451-b7a9-bdac0133dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rank = results_df.sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "25ebc583-b557-471f-85ee-ea4d7c94538a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip</th>\n",
       "      <th>caption</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>1BMgKPeURxc/1BMgKPeURxc.4_7.mp4</td>\n",
       "      <td>a video of a slot machine with the words \"feel...</td>\n",
       "      <td>41.904305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>4Wno4d7RCag/4Wno4d7RCag.0_1.mp4</td>\n",
       "      <td>how to make a jazzy jazz bracelet</td>\n",
       "      <td>41.540459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>3bO6hVtV1mE/3bO6hVtV1mE.5_3.mp4</td>\n",
       "      <td>a woman is holding up a fragrance sampler</td>\n",
       "      <td>38.996304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>3bO6hVtV1mE/3bO6hVtV1mE.6_1.mp4</td>\n",
       "      <td>a woman is holding up a fragrance sampler</td>\n",
       "      <td>38.996304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>3ntE0lNL5j8/3ntE0lNL5j8.76_0.mp4</td>\n",
       "      <td>a triangle with the words \"competition your be...</td>\n",
       "      <td>38.590294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  clip  \\\n",
       "2009   1BMgKPeURxc/1BMgKPeURxc.4_7.mp4   \n",
       "467    4Wno4d7RCag/4Wno4d7RCag.0_1.mp4   \n",
       "2283   3bO6hVtV1mE/3bO6hVtV1mE.5_3.mp4   \n",
       "2309   3bO6hVtV1mE/3bO6hVtV1mE.6_1.mp4   \n",
       "291   3ntE0lNL5j8/3ntE0lNL5j8.76_0.mp4   \n",
       "\n",
       "                                                caption      score  \n",
       "2009  a video of a slot machine with the words \"feel...  41.904305  \n",
       "467                   how to make a jazzy jazz bracelet  41.540459  \n",
       "2283          a woman is holding up a fragrance sampler  38.996304  \n",
       "2309          a woman is holding up a fragrance sampler  38.996304  \n",
       "291   a triangle with the words \"competition your be...  38.590294  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_rank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b3ade3-ea19-4f73-a3f3-1329b54658a9",
   "metadata": {},
   "source": [
    "### Lowest CLIP score clip-text pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "efc309fc-ca91-4c32-a7f2-83b8ce9859c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip</th>\n",
       "      <th>caption</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0XGnU4ir5gs/0XGnU4ir5gs.5_5.mp4</td>\n",
       "      <td>a dog laying in the grass in front of people</td>\n",
       "      <td>14.748165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0XGnU4ir5gs/0XGnU4ir5gs.5_7.mp4</td>\n",
       "      <td>a person is upside down in front of a fire hyd...</td>\n",
       "      <td>14.522579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>3eCjDT0t52Y/3eCjDT0t52Y.9_1.mp4</td>\n",
       "      <td>a group of people walking in the sun</td>\n",
       "      <td>13.358162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>2jfO_1sH9Nk/2jfO_1sH9Nk.1_1.mp4</td>\n",
       "      <td>a black and white picture of a cat</td>\n",
       "      <td>9.027212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>2jfO_1sH9Nk/2jfO_1sH9Nk.21_2.mp4</td>\n",
       "      <td>a black and white photo of a man playing a guitar</td>\n",
       "      <td>5.468554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  clip  \\\n",
       "989    0XGnU4ir5gs/0XGnU4ir5gs.5_5.mp4   \n",
       "884    0XGnU4ir5gs/0XGnU4ir5gs.5_7.mp4   \n",
       "534    3eCjDT0t52Y/3eCjDT0t52Y.9_1.mp4   \n",
       "2221   2jfO_1sH9Nk/2jfO_1sH9Nk.1_1.mp4   \n",
       "2183  2jfO_1sH9Nk/2jfO_1sH9Nk.21_2.mp4   \n",
       "\n",
       "                                                caption      score  \n",
       "989        a dog laying in the grass in front of people  14.748165  \n",
       "884   a person is upside down in front of a fire hyd...  14.522579  \n",
       "534                a group of people walking in the sun  13.358162  \n",
       "2221                 a black and white picture of a cat   9.027212  \n",
       "2183  a black and white photo of a man playing a guitar   5.468554  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_rank.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853673f-1923-45ff-af16-204ba07bf7aa",
   "metadata": {},
   "source": [
    "### Analysis on the score of all clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c31304b-8ae1-4500-8c01-2366b42fbe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewheng/anaconda3/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histogram(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7083044b-131f-463d-a55e-5baa0080d9cc",
   "metadata": {},
   "source": [
    "### View the top highest 5% CLIP score clips (diversify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e036f6ca-6423-4173-a8dc-e90558e6f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5percent_diversify = results_df.iloc[result_rank_diversify]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0446db62-c89b-45cc-a924-09256e036cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.138943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.629470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>32.463978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.175454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.716135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.426768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.904305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score\n",
       "count  118.000000\n",
       "mean    34.138943\n",
       "std      1.629470\n",
       "min     32.463978\n",
       "25%     33.175454\n",
       "50%     33.716135\n",
       "75%     34.426768\n",
       "max     41.904305"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5percent_diversify.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "acc13bca-9889-4c6e-9d84-a41dc4500696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9k/v3mgfmnx32b02fjpln953dzr0000gn/T/ipykernel_27085/2965220696.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['score'] = pd.to_numeric(df['score'], errors='coerce')\n",
      "/Users/matthewheng/anaconda3/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histogram(top5percent_diversify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0445e8-2671-4804-a6fb-cf4bee2e345f",
   "metadata": {},
   "source": [
    "### View the top higest 5% CLIP score clips (normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d6ebf7a-f4ef-4da5-a521-f88926d7052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5percent_normal = results_df.iloc[result_rank_normal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d2c89754-c5c4-4aa5-8bb4-10020b9ef354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.234958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.555078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>32.992783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.331089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.716135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.426768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.904305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            score\n",
       "count  118.000000\n",
       "mean    34.234958\n",
       "std      1.555078\n",
       "min     32.992783\n",
       "25%     33.331089\n",
       "50%     33.716135\n",
       "75%     34.426768\n",
       "max     41.904305"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5percent_normal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ec2d12d3-343c-469b-b66b-f2a10826e339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9k/v3mgfmnx32b02fjpln953dzr0000gn/T/ipykernel_27085/2965220696.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['score'] = pd.to_numeric(df['score'], errors='coerce')\n",
      "/Users/matthewheng/anaconda3/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histogram(top5percent_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd3e95-cf05-4be7-b99e-0af6a7160613",
   "metadata": {},
   "source": [
    "# 5.0 Save the final output the results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e20ed645-6ba7-4941-a0e7-24084efe0c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5percent_diversify_file = './results/top5percent_diversify.jsonl'\n",
    "top5percent_normal_file = './results/top5percent_normal_file.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8eedd50c-dc51-4852-9823-c46ccda19fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(top5percent_diversify_file, 'w') as f:\n",
    "    top5percent_diversify.to_json(f, orient='records', lines=True)\n",
    "\n",
    "with open(top5percent_normal_file, 'w') as f:\n",
    "    top5percent_normal.to_json(f, orient='records', lines=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
